{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/matery/source/css/gitment.css","path":"css/gitment.css","modified":0,"renderable":1},{"_id":"themes/matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":0,"renderable":1},{"_id":"themes/matery/source/css/matery.css","path":"css/matery.css","modified":0,"renderable":1},{"_id":"themes/matery/source/css/my.css","path":"css/my.css","modified":0,"renderable":1},{"_id":"themes/matery/source/js/matery.js","path":"js/matery.js","modified":0,"renderable":1},{"_id":"themes/matery/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/matery/source/medias/reward/alipay.png","path":"medias/reward/alipay.png","modified":0,"renderable":1},{"_id":"themes/matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/background/canvas-nest.js","path":"libs/background/canvas-nest.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/background/ribbon-dynamic.js","path":"libs/background/ribbon-dynamic.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/background/ribbon-refresh.min.js","path":"libs/background/ribbon-refresh.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/background/ribbon.min.js","path":"libs/background/ribbon.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/instantpage/instantpage.js","path":"libs/instantpage/instantpage.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/jquery/jquery.min.js","path":"libs/jquery/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.eot","path":"libs/awesome/webfonts/fa-regular-400.eot","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.ttf","path":"libs/awesome/webfonts/fa-regular-400.ttf","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.woff","path":"libs/awesome/webfonts/fa-regular-400.woff","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.woff2","path":"libs/awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.woff2","path":"libs/awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.woff","path":"libs/awesome/webfonts/fa-solid-900.woff","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.woff2","path":"libs/awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/css/all.css","path":"libs/awesome/css/all.css","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.ttf","path":"libs/awesome/webfonts/fa-brands-400.ttf","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.woff","path":"libs/awesome/webfonts/fa-brands-400.woff","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.eot","path":"libs/awesome/webfonts/fa-brands-400.eot","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.svg","path":"libs/awesome/webfonts/fa-regular-400.svg","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.eot","path":"libs/awesome/webfonts/fa-solid-900.eot","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.ttf","path":"libs/awesome/webfonts/fa-solid-900.ttf","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.svg","path":"libs/awesome/webfonts/fa-brands-400.svg","modified":0,"renderable":1},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.svg","path":"libs/awesome/webfonts/fa-solid-900.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"6f821e9ab75e29fdffecc2457e108d79834be3ab","modified":1589714966000},{"_id":"themes/matery/.gitignore","hash":"727607929a51db7ea10968f547c26041eee9cfff","modified":1589714966000},{"_id":"themes/matery/LICENSE","hash":"7df059597099bb7dcf25d2a9aedfaf4465f72d8d","modified":1589714966000},{"_id":"themes/matery/README.md","hash":"14e087a7d13de010f4912fcdc3d36bc0091b70c1","modified":1589714966000},{"_id":"themes/matery/README_CN.md","hash":"90547af29a466cda933e77b81a9b9cbd842df0b9","modified":1589714966000},{"_id":"themes/matery/_config.yml","hash":"7481a60e781fb8f4e83322da00437ed288f59057","modified":1589714966000},{"_id":"source/_data/friends.json","hash":"910f6da94df1bea8f0edafbb013351183d76fd54","modified":1589714966000},{"_id":"source/_data/musics.json","hash":"934bf548a850390b3def6071166d3cedcdf25f46","modified":1589714966000},{"_id":"source/_posts/HBase-shell-基本操作.md","hash":"109b35ea37ccd6ccf76233217158bf247e8903c5","modified":1589721833744},{"_id":"source/_posts/Todo-List.md","hash":"b91dfe556b29f385579a3b9f1448cdd741decda3","modified":1589722201750},{"_id":"source/_posts/Hadoop-HA-搭建.md","hash":"212193274ef0304ee4e56b8347e5133d28bdacb5","modified":1589721954597},{"_id":"source/_posts/Zookeeper-Hadoop-HBase搭建.md","hash":"7212143c4f21a2a8b79b6e5cb63f84d078c9c7e1","modified":1589722249420},{"_id":"source/_posts/ubuntu1604-搭建Hadoop集群.md","hash":"14f9162ec2931e190ed46f41b95c28ee9dcd7c26","modified":1589722372233},{"_id":"source/_posts/ubuntu1604-设置静态IP.md","hash":"b364564b285c1387378401fb67f08b88952a2f67","modified":1589722445166},{"_id":"source/_posts/【文献翻译】基于深度学习的文本分类：全面回顾.md","hash":"945d21a831a877ae39a4459a67a3d3da4788f181","modified":1589722549363},{"_id":"source/_posts/个人可持续性发展.md","hash":"89b05c8eb8d400835bd1cf1e40a43eaf566c30ad","modified":1589720613948},{"_id":"source/_posts/【求甚解】怎样评价一个模型的泛化能力.md","hash":"0a2bed2f64a8ceff68f82c2c6d30e80b41cc44f6","modified":1589722521710},{"_id":"source/_posts/胶囊网络.md","hash":"83ab821c87c7335129bae59f038f3a802fad00b5","modified":1589721967367},{"_id":"source/_posts/了不起的盖茨比.md","hash":"348d9e718742a2779a3d537161300aabfede48e9","modified":1589714966000},{"_id":"source/about/index.md","hash":"a060001f4a5d506a7e201c0190378eefa6e5763d","modified":1589714966000},{"_id":"source/archives/index.md","hash":"30a0e3a59be650ae34d7bb86ac7da53e21e9cf5b","modified":1589714966000},{"_id":"source/contact/index.md","hash":"e0ff8427153f2938a551fad5f2582bca33641407","modified":1589714966000},{"_id":"source/friends/index.md","hash":"9c75191be6deb004e4c8f3e6a9722b81d63dced9","modified":1589714966000},{"_id":"source/tags/index.md","hash":"fe3d7ecc91b81b062a6a60c06859dc24b9d704ac","modified":1589714966000},{"_id":"source/categories/index.md","hash":"f0c10666a2c373409bac5ce68ba343b63c7281c2","modified":1589714966000},{"_id":"themes/matery/languages/zh-CN.yml","hash":"315de4f99b95ec08ae79394c92022abc634c47ec","modified":1589714966000},{"_id":"themes/matery/languages/default.yml","hash":"17aca10aa3a627e84071f4c411f2b76c3161d076","modified":1589714966000},{"_id":"themes/matery/layout/about.ejs","hash":"ee639d0310867976b3e5fb9f92c215a17a433703","modified":1589714966000},{"_id":"themes/matery/layout/archive.ejs","hash":"7fe7b9028b0da9c84715c3583b6b4172c2342ac8","modified":1589714966000},{"_id":"themes/matery/layout/categories.ejs","hash":"8e54665cc25d7c333da7d9f312987190be6215da","modified":1589714966000},{"_id":"themes/matery/layout/index.ejs","hash":"5a15bc8312e3ba265692a604e7ec5db0a9e3b779","modified":1589714966000},{"_id":"themes/matery/layout/category.ejs","hash":"720d02e5fc37d154b60590bb7f64a2a4651c02db","modified":1589714966000},{"_id":"themes/matery/layout/post.ejs","hash":"14695375ba83ef0d8a8940891243a32906a20800","modified":1589714966000},{"_id":"themes/matery/layout/layout.ejs","hash":"cda1921ec208dfe4f3445e93ab11421657b3d564","modified":1589714966000},{"_id":"themes/matery/layout/tag.ejs","hash":"0c0194cf006fab2dccf4f788075e51cd06637df4","modified":1589714966000},{"_id":"themes/matery/layout/tags.ejs","hash":"cf9517aa6a0111355121f44615d6923e312283c7","modified":1589714966000},{"_id":"themes/matery/layout/contact.ejs","hash":"2747bfcf3cbf832ec7cc118ca4da557d42f98e69","modified":1589714966000},{"_id":"themes/matery/layout/friends.ejs","hash":"4cb216b2a650ad5d2942047a65d0883a188c2abb","modified":1589714966000},{"_id":"themes/matery/layout/_partial/back-top.ejs","hash":"47ee36a042bb6d52bbe1d0f329637e8ffcf1d0aa","modified":1589714966000},{"_id":"themes/matery/layout/_partial/baidu-push.ejs","hash":"2cebcc5ea3614d7f76ec36670e68050cbe611202","modified":1589714966000},{"_id":"themes/matery/layout/_partial/baidu-analytics.ejs","hash":"3bbcdb474ca1dcad514bdc4b7763e17c55df04fd","modified":1589714966000},{"_id":"themes/matery/layout/_partial/bg-cover-content.ejs","hash":"7fbddbf26f64510b290b052a70deb3cfee57cac0","modified":1589714966000},{"_id":"themes/matery/layout/_partial/bg-cover.ejs","hash":"02191109712f61c0e487b8f0b8466597181a9004","modified":1589714966000},{"_id":"themes/matery/layout/_partial/disqus.ejs","hash":"a0f53d1a9b579d52e52ccad8c6e330bf3b89547e","modified":1589714966000},{"_id":"themes/matery/layout/_partial/gitalk.ejs","hash":"ce7e330165e0db604e0a1845bc460ef35772c656","modified":1589714966000},{"_id":"themes/matery/layout/_partial/footer.ejs","hash":"76226ad09fa9cb5a0cd09b8549322935d50d97cd","modified":1589714966000},{"_id":"themes/matery/layout/_partial/github-link.ejs","hash":"3aeb581bd78ab8e15b858e4c44c03bcf92f20b9e","modified":1589714966000},{"_id":"themes/matery/layout/_partial/gitment.ejs","hash":"2628a7a0238f4b35a26cdea36b0e0bf05431ea80","modified":1589714966000},{"_id":"themes/matery/layout/_partial/google-analytics.ejs","hash":"5f4992205617da5f8cc5863c62b5ec46e414e2fb","modified":1589714966000},{"_id":"themes/matery/layout/_partial/header.ejs","hash":"e253c813b3ee5ed924700a95133741802e58adc5","modified":1589714966000},{"_id":"themes/matery/layout/_partial/head.ejs","hash":"bfef8b961956e6956677b7b14e4c93adb6642613","modified":1589714966000},{"_id":"themes/matery/layout/_partial/index-cover.ejs","hash":"ed47a9800a5ac0b3b703630373175f89ae8435fe","modified":1589714966000},{"_id":"themes/matery/layout/_partial/livere.ejs","hash":"9c3401b42ea7f26410a5593bae93ada7e57b43be","modified":1589714966000},{"_id":"themes/matery/layout/_partial/mobile-nav.ejs","hash":"dec2fed861d429063662c2bc90f2708e58fbbad9","modified":1589714966000},{"_id":"themes/matery/layout/_partial/paging.ejs","hash":"e2df12cf92a82b1a7a7add2eac1db1d954bc5511","modified":1589714966000},{"_id":"themes/matery/layout/_partial/navigation.ejs","hash":"5ff6fdfe973619120a9eda4505bbff4545e39ff0","modified":1589714966000},{"_id":"themes/matery/layout/_partial/post-cover.ejs","hash":"68738493f40e22ff82891e3aecaa2746c8470cd0","modified":1589714966000},{"_id":"themes/matery/layout/_partial/post-detail-toc.ejs","hash":"e64819596a61293f9880ee16feaa3c1677d228b8","modified":1589714966000},{"_id":"themes/matery/layout/_partial/post-detail.ejs","hash":"2d20e5dcf172c1e6b5853d8c24b0670fafe48dbf","modified":1589714966000},{"_id":"themes/matery/layout/_partial/prev-next.ejs","hash":"35b6b4a0200c10be6ae9d9558367718290476f84","modified":1589714966000},{"_id":"themes/matery/layout/_partial/post-statis.ejs","hash":"04889f9031743c6b081d02fa4027b0dbfcc45ecf","modified":1589714966000},{"_id":"themes/matery/layout/_partial/reprint-statement.ejs","hash":"01f5eef82bbcb9d432631dbb78dd51d4d4b3b8b5","modified":1589714966000},{"_id":"themes/matery/layout/_partial/reward.ejs","hash":"39b570b9446a7897063fdd6d538ad476fd84f17f","modified":1589714966000},{"_id":"themes/matery/layout/_partial/search.ejs","hash":"b72ae1de86cc6828b7ff1570d02b784167ef0fff","modified":1589714966000},{"_id":"themes/matery/layout/_partial/social-link.ejs","hash":"6f871bd3a70f720e4e451f1f4f625cbc6d8994a4","modified":1589714966000},{"_id":"themes/matery/layout/_partial/share.ejs","hash":"36fb0d22d50a9d348fc72ea0fb6c071f2c25b95b","modified":1589714966000},{"_id":"themes/matery/layout/_partial/valine.ejs","hash":"25bb67cf1c7dc297088f0bdd9a30a05231aeb5d0","modified":1589714966000},{"_id":"themes/matery/layout/_widget/category-cloud.ejs","hash":"424ef5db791264a79c1f3338e7c43a2f445cb2ab","modified":1589714966000},{"_id":"themes/matery/layout/_widget/category-radar.ejs","hash":"383a4501d42df2dadb254f2ae6facc1886605497","modified":1589714966000},{"_id":"themes/matery/layout/_widget/music.ejs","hash":"7618b3ed63d714ba67281a93870fe947aa11fa14","modified":1589714966000},{"_id":"themes/matery/layout/_widget/dream.ejs","hash":"ba83115ce66f4328601e567aa30f50d1410b9bfa","modified":1589714966000},{"_id":"themes/matery/layout/_widget/my-gallery.ejs","hash":"de2e0abc085b721318f35c0b5d4891230be36529","modified":1589714966000},{"_id":"themes/matery/layout/_widget/my-skills.ejs","hash":"89a0092df72d23093128f2fbbdc8ca7f83ebcfd9","modified":1589714966000},{"_id":"themes/matery/layout/_widget/my-projects.ejs","hash":"dbd8df5146bd6e873535e24f09dd7cf04e17a4e4","modified":1589714966000},{"_id":"themes/matery/layout/_widget/post-calendar.ejs","hash":"3fa9ceb2a28929b14002d59e2d96cc4bac39eb7b","modified":1589714966000},{"_id":"themes/matery/layout/_widget/post-charts.ejs","hash":"bff6033f89daa925e2d44c28b1dd4d21fb773dd8","modified":1589714966000},{"_id":"themes/matery/layout/_widget/recommend.ejs","hash":"7412060c10f4493a17b5c02cfc343fac106ab927","modified":1589714966000},{"_id":"themes/matery/layout/_widget/tag-cloud.ejs","hash":"fc42b72cddc231f7485cdc1fd6852b66be6add26","modified":1589714966000},{"_id":"themes/matery/layout/_widget/tag-wordcloud.ejs","hash":"70fc118bcc8705f47580e3c190bb486d94982032","modified":1589714966000},{"_id":"themes/matery/layout/_widget/video.ejs","hash":"d752c9f54300a9d762433ac4a00de3cc7e79d584","modified":1589714966000},{"_id":"themes/matery/source/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1589714966000},{"_id":"themes/matery/source/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1589714966000},{"_id":"themes/matery/source/css/matery.css","hash":"9af007b47df7be7713a74ce670336b5b60d770d5","modified":1589714966000},{"_id":"themes/matery/source/css/my.css","hash":"10577fbc30f241b126d1b51b1f56136ecba86b19","modified":1589714966000},{"_id":"themes/matery/source/js/matery.js","hash":"07ed4f743a497d7850b3fdda2a5d9beccc5a8fb5","modified":1589714966000},{"_id":"themes/matery/source/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1589714966000},{"_id":"themes/matery/source/medias/reward/alipay.png","hash":"52065fd3ea5d7ccad3e3e555cbd92ca3a9f46caf","modified":1589714966000},{"_id":"themes/matery/source/medias/reward/wechat.png","hash":"24983b1b51c78d0ee6963fce32754d6042e7ac09","modified":1589714966000},{"_id":"themes/matery/source/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1589714966000},{"_id":"themes/matery/source/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1589714966000},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1589714966000},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1589714966000},{"_id":"themes/matery/source/libs/background/canvas-nest.js","hash":"65333d0dbb9c1173a1b13031b230161fc42c8b2f","modified":1589714966000},{"_id":"themes/matery/source/libs/background/ribbon-dynamic.js","hash":"052b80c29e6bc585aa28d4504b743bdbac220a88","modified":1589714966000},{"_id":"themes/matery/source/libs/background/ribbon-refresh.min.js","hash":"6d98692b2cad8c746a562db18b170b35c24402f4","modified":1589714966000},{"_id":"themes/matery/source/libs/background/ribbon.min.js","hash":"6a99d494c030388f96f6086a7aaa0f03f3fe532e","modified":1589714966000},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1589714966000},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","hash":"6d39a766af62e625f177c4d5cf3adc35eed71e61","modified":1589714966000},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","hash":"bac88b4d4e3679732d29bd037c34f089cf27cf05","modified":1589714966000},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","hash":"201e8cd761b4be557247bdaf1ebc7c11c83194f6","modified":1589714966000},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1589714966000},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","hash":"940ded3ea12c2fe1ab0820d2831ec405f3f1fe9f","modified":1589714966000},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1589714966000},{"_id":"themes/matery/source/libs/instantpage/instantpage.js","hash":"83ce8919b1a69b2f1809ffaf99b52a8627e650e9","modified":1589714966000},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1589714966000},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1589714966000},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1589714966000},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1589714966000},{"_id":"themes/matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1589714966000},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1589714966000},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1589714966000},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1589714966000},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1589714966000},{"_id":"themes/matery/source/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1589714966000},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1589714966000},{"_id":"themes/matery/source/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1589714966000},{"_id":"themes/matery/source/libs/jquery/jquery.min.js","hash":"2115753ca5fb7032aec498db7bb5dca624dbe6be","modified":1589714966000},{"_id":"themes/matery/source/libs/valine/Valine.min.js","hash":"6cbdbf91e1f046dd41267a5ff0691a1fccba99df","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.eot","hash":"439c8afd3373acb4a73135a34e220464a89cd5e2","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.ttf","hash":"0f4bd02942a54a6b3200d9078adff88c2812e751","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.woff","hash":"59439d3ad31d856d78ec3e2bd9f1eafa2c7a581c","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.woff2","hash":"f6f653b4ea8fc487bdb590d39d5a726258a55f40","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1589714966000},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","hash":"30351cf15f5f2325275d7e0754afdef011f4b830","modified":1589714966000},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1589714966000},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1589714966000},{"_id":"themes/matery/source/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1589714966000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1589714966000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","hash":"f0a1b849868a6bf351ff98dc3924a4e7254eb88b","modified":1589714966000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1589714966000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1589714966000},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","hash":"41367dcb857e02e3c417ebe68a554ce1d4430806","modified":1589714966000},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","hash":"a3090a02786dcd4efc6355c1c1dc978add8d6827","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.woff2","hash":"a46bd47ff0a90b812aafafda587d095cdb844271","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.woff","hash":"92803b8753ceda573c6906774677c5a7081d2fbb","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.woff2","hash":"9c081b88b106c6c04ecb895ba7ba7d3dcb3b55ac","modified":1589714966000},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","hash":"8fefe38f28804f90116bdcb74a0875c9de9f3b7d","modified":1589714966000},{"_id":"themes/matery/source/libs/valine/av-min.js","hash":"541efb9edc1ce425cbe3897cfc25803211fe6a05","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/css/all.css","hash":"ecc41e32ad2696877a1656749841f3b5543bbe3d","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.ttf","hash":"91cbeeaceb644a971241c08362898599d6d968ce","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.woff","hash":"18838f5260317da3c5ed29bf844ac8a4f7ad0529","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.eot","hash":"22f9e7d5226408eb2d0a11e118257a3ca22b8670","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-regular-400.svg","hash":"229afff648cbd17de80176e0feb969c7f514be7e","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.eot","hash":"cab8e84ae5682d1d556e234df9c790985888def8","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.ttf","hash":"9521ed12274c2cbc910cea77657116fcf6545da3","modified":1589714966000},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-brands-400.svg","hash":"25612c76ded31c497effe46454d8d2bb36fb99d6","modified":1589714966000},{"_id":"themes/matery/source/libs/awesome/webfonts/fa-solid-900.svg","hash":"2c026711e4dd6b6d805cc19c0e4a572e6239a05b","modified":1589714966000},{"_id":"public/atom.xml","hash":"793180eb367f31f79974934109769db72f630ada","modified":1589722566034},{"_id":"public/about/index.html","hash":"d171908b8cffe439aeff082e72fcb255cab7fe93","modified":1589722566034},{"_id":"public/archives/index.html","hash":"d9683a9cbc633455108267ba4b92c46f7a0f9156","modified":1589722566034},{"_id":"public/contact/index.html","hash":"b715fcff57c20ea579022f83d630c374450f2bfe","modified":1589722566034},{"_id":"public/friends/index.html","hash":"a414592678d9024f31bbd99f2c2c3aa3151fd83d","modified":1589722566034},{"_id":"public/tags/index.html","hash":"947e642c3517dd846c50b07e05e5bb4d70cc1913","modified":1589722566034},{"_id":"public/categories/index.html","hash":"b3254eb26a881841e88591620c957b64506244ea","modified":1589722566034},{"_id":"public/2020/05/09/hbase-shell-ji-ben-cao-zuo/index.html","hash":"6a0d052b1883b57221411fd1fca718a26dd497ce","modified":1589722566034},{"_id":"public/2020/05/07/zookeeper-hadoop-hbase-da-jian/index.html","hash":"a8db150838932cde84539ad712136417f842a7ff","modified":1589722566034},{"_id":"public/2020/05/06/hadoop-ha-da-jian/index.html","hash":"f9b0c3f98e80cd2648e3d2575ef458cf05477635","modified":1589722566034},{"_id":"public/2020/05/03/qiu-shen-jie-zen-yang-ping-jie-yi-ge-mo-xing-de-fan-hua-neng-li/index.html","hash":"31b94a182ba6c2821b3a57308d3d1d9c8a848e0b","modified":1589722566034},{"_id":"public/2020/05/01/xiao-nang-wang-luo/index.html","hash":"7c935b381d104f6aa742709d5991d83d9996ced2","modified":1589722566034},{"_id":"public/2020/04/30/ubuntu1604-da-jian-hadoop-ji-qun/index.html","hash":"3557f4d5de30dddcdd8751f935e9585f63b438c8","modified":1589722566034},{"_id":"public/2020/04/30/ubuntu1604-she-zhi-jing-tai-ip/index.html","hash":"243700c3def73b87f540bb5311a241609d666318","modified":1589722566034},{"_id":"public/2020/04/30/todo-list/index.html","hash":"3e6dd104b2c32c553a7ac5b4cca167c1cf31ae78","modified":1589722566034},{"_id":"public/2020/04/27/wen-xian-fan-yi-ji-yu-shen-du-xue-xi-de-wen-ben-fen-lei-quan-mian-hui-gu/index.html","hash":"3503fa83db7e45e27f4c8fcd0d60486f430da823","modified":1589722566034},{"_id":"public/2020/04/21/ge-ren-ke-chi-xu-xing-fa-zhan/index.html","hash":"3837940b18d42a38983c26a65131ea1784d8d8d0","modified":1589722566034},{"_id":"public/2020/04/11/liao-bu-qi-de-gai-ci-bi/index.html","hash":"5614571babeac60f9cbcbc3b2a68d219ebda967e","modified":1589722566034},{"_id":"public/archives/2020/index.html","hash":"a27d20a8044d4e3dfb529cf1ca91b530f57a0fbf","modified":1589722566034},{"_id":"public/archives/2020/04/index.html","hash":"883f92aed5a93f493c49b745e3a3bdc0867b0a19","modified":1589722566034},{"_id":"public/archives/2020/05/index.html","hash":"592f6777d5b26ff115c28922476abc89d68ccf06","modified":1589722566034},{"_id":"public/categories/大数据/index.html","hash":"bcd4890c8a7b624920d02468b59956854bd0e250","modified":1589722566034},{"_id":"public/categories/待完成/index.html","hash":"cee36d0e70558d4effeeaa3d109bc2580bb036c5","modified":1589722566034},{"_id":"public/categories/Linux/index.html","hash":"d4f7ac977275e1779701c41842d2b02d30a7c503","modified":1589722566034},{"_id":"public/categories/杂/index.html","hash":"9ed5724ed9e68009413e5392707bd01a802c03b5","modified":1589722566034},{"_id":"public/categories/求甚解/index.html","hash":"de178fb1bffa139971b0b91eff252703609547de","modified":1589722566034},{"_id":"public/categories/文献翻译/index.html","hash":"a6c08e4ca0949f554b7089f74c02e9084f91cf3b","modified":1589722566034},{"_id":"public/categories/深度学习/index.html","hash":"7098abf46dd5845e0986b771cf02ebe553ffb2ef","modified":1589722566034},{"_id":"public/categories/影评/index.html","hash":"9332cd053ab7a918d4d7b666048f1fa78656e451","modified":1589722566034},{"_id":"public/index.html","hash":"69f7589b03ee08cf7edf1fb34c003a211945b6d9","modified":1589722566034},{"_id":"public/tags/hbsse/index.html","hash":"0f43e5f1a13fb72b75768eeec4675f7c84c5418e","modified":1589722566034},{"_id":"public/tags/大数据/index.html","hash":"de58ed6d0a11bfaaa95111bba2b15ec53cce6017","modified":1589722566034},{"_id":"public/tags/todo-list/index.html","hash":"6355310d8b9659aeb335d5e5d2e8fa7a252974d2","modified":1589722566034},{"_id":"public/tags/hadoop/index.html","hash":"eb141d9ae1b70f74f041c654757bbf22ee4e851b","modified":1589722566034},{"_id":"public/tags/zookeeper/index.html","hash":"b9af424679e818f398c6dab491c8efe1eb58767c","modified":1589722566034},{"_id":"public/tags/hbase/index.html","hash":"21141365c7a40c8d79ad197b8b142fe5be78f280","modified":1589722566034},{"_id":"public/tags/高可用/index.html","hash":"1d739232f4ac5b5288135c2c6ef7c71e36bb6d0d","modified":1589722566034},{"_id":"public/tags/HA/index.html","hash":"dbe5b80c93993138dc8ea33b87f34835db0bb66c","modified":1589722566034},{"_id":"public/tags/IP/index.html","hash":"be555e2dc183ea741fcf1533c00b21d800d026be","modified":1589722566034},{"_id":"public/tags/静态IP/index.html","hash":"f46fc38231c5c480cc120aa252fbfe2707e0654a","modified":1589722566034},{"_id":"public/tags/Ubuntu/index.html","hash":"83174e96b83be95005c66c62624919613a9f8102","modified":1589722566034},{"_id":"public/tags/可持续性发展/index.html","hash":"16db3829f9e192242c5955376482b87da047a056","modified":1589722566034},{"_id":"public/tags/求甚解/index.html","hash":"6525090124906ff8503e492ed871c18c2e598bd5","modified":1589722566034},{"_id":"public/tags/文本分类/index.html","hash":"0433345540ca5f97b8b32e25786312189cf4cd21","modified":1589722566034},{"_id":"public/tags/综述/index.html","hash":"1e30831c41725d7ab441cf485aa3021927b25be6","modified":1589722566034},{"_id":"public/tags/文献翻译/index.html","hash":"ea6e860db6d7e72f8c2d8870d80f09312d07c65b","modified":1589722566034},{"_id":"public/tags/胶囊网络/index.html","hash":"48971cc23579a0db772149882d4ed5e0273e7671","modified":1589722566034},{"_id":"public/tags/Capsule-Networks/index.html","hash":"b84e8f04a8e486fef7ca8c4aac0681ad9d4d7f54","modified":1589722566034},{"_id":"public/tags/影评/index.html","hash":"3d4828ebf0d3bfb96c29327e945de9ce9440d7bb","modified":1589722566034},{"_id":"public/tags/集群/index.html","hash":"ff9367987984eeb4f4c7a1a448177cfd4a57d37d","modified":1589722566034},{"_id":"public/CNAME","hash":"6f821e9ab75e29fdffecc2457e108d79834be3ab","modified":1589722566034},{"_id":"public/medias/reward/wechat.png","hash":"24983b1b51c78d0ee6963fce32754d6042e7ac09","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-regular-400.eot","hash":"439c8afd3373acb4a73135a34e220464a89cd5e2","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-regular-400.ttf","hash":"0f4bd02942a54a6b3200d9078adff88c2812e751","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-regular-400.woff","hash":"59439d3ad31d856d78ec3e2bd9f1eafa2c7a581c","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-regular-400.woff2","hash":"f6f653b4ea8fc487bdb590d39d5a726258a55f40","modified":1589722566034},{"_id":"public/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1589722566034},{"_id":"public/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1589722566034},{"_id":"public/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1589722566034},{"_id":"public/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1589722566034},{"_id":"public/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1589722566034},{"_id":"public/libs/lightGallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1589722566034},{"_id":"public/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1589722566034},{"_id":"public/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1589722566034},{"_id":"public/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1589722566034},{"_id":"public/libs/share/fonts/iconfont.svg","hash":"f0a1b849868a6bf351ff98dc3924a4e7254eb88b","modified":1589722566034},{"_id":"public/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1589722566034},{"_id":"public/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1589722566034},{"_id":"public/medias/reward/alipay.png","hash":"52065fd3ea5d7ccad3e3e555cbd92ca3a9f46caf","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-brands-400.woff2","hash":"a46bd47ff0a90b812aafafda587d095cdb844271","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-solid-900.woff","hash":"92803b8753ceda573c6906774677c5a7081d2fbb","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-solid-900.woff2","hash":"9c081b88b106c6c04ecb895ba7ba7d3dcb3b55ac","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-brands-400.ttf","hash":"91cbeeaceb644a971241c08362898599d6d968ce","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-brands-400.eot","hash":"22f9e7d5226408eb2d0a11e118257a3ca22b8670","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-brands-400.woff","hash":"18838f5260317da3c5ed29bf844ac8a4f7ad0529","modified":1589722566034},{"_id":"public/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1589722566034},{"_id":"public/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1589722566034},{"_id":"public/css/matery.css","hash":"9af007b47df7be7713a74ce670336b5b60d770d5","modified":1589722566034},{"_id":"public/css/my.css","hash":"10577fbc30f241b126d1b51b1f56136ecba86b19","modified":1589722566034},{"_id":"public/js/matery.js","hash":"07ed4f743a497d7850b3fdda2a5d9beccc5a8fb5","modified":1589722566034},{"_id":"public/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1589722566034},{"_id":"public/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1589722566034},{"_id":"public/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1589722566034},{"_id":"public/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1589722566034},{"_id":"public/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1589722566034},{"_id":"public/libs/background/canvas-nest.js","hash":"65333d0dbb9c1173a1b13031b230161fc42c8b2f","modified":1589722566034},{"_id":"public/libs/background/ribbon-dynamic.js","hash":"052b80c29e6bc585aa28d4504b743bdbac220a88","modified":1589722566034},{"_id":"public/libs/background/ribbon-refresh.min.js","hash":"6d98692b2cad8c746a562db18b170b35c24402f4","modified":1589722566034},{"_id":"public/libs/background/ribbon.min.js","hash":"6a99d494c030388f96f6086a7aaa0f03f3fe532e","modified":1589722566034},{"_id":"public/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1589722566034},{"_id":"public/libs/codeBlock/codeCopy.js","hash":"6d39a766af62e625f177c4d5cf3adc35eed71e61","modified":1589722566034},{"_id":"public/libs/codeBlock/codeLang.js","hash":"bac88b4d4e3679732d29bd037c34f089cf27cf05","modified":1589722566034},{"_id":"public/libs/codeBlock/codeShrink.js","hash":"201e8cd761b4be557247bdaf1ebc7c11c83194f6","modified":1589722566034},{"_id":"public/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1589722566034},{"_id":"public/libs/gitalk/gitalk.css","hash":"940ded3ea12c2fe1ab0820d2831ec405f3f1fe9f","modified":1589722566034},{"_id":"public/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1589722566034},{"_id":"public/libs/instantpage/instantpage.js","hash":"83ce8919b1a69b2f1809ffaf99b52a8627e650e9","modified":1589722566034},{"_id":"public/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1589722566034},{"_id":"public/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1589722566034},{"_id":"public/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1589722566034},{"_id":"public/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1589722566034},{"_id":"public/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1589722566034},{"_id":"public/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1589722566034},{"_id":"public/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1589722566034},{"_id":"public/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1589722566034},{"_id":"public/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1589722566034},{"_id":"public/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1589722566034},{"_id":"public/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1589722566034},{"_id":"public/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1589722566034},{"_id":"public/libs/jquery/jquery.min.js","hash":"2115753ca5fb7032aec498db7bb5dca624dbe6be","modified":1589722566034},{"_id":"public/libs/valine/Valine.min.js","hash":"6cbdbf91e1f046dd41267a5ff0691a1fccba99df","modified":1589722566034},{"_id":"public/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1589722566034},{"_id":"public/libs/materialize/materialize.min.css","hash":"30351cf15f5f2325275d7e0754afdef011f4b830","modified":1589722566034},{"_id":"public/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1589722566034},{"_id":"public/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1589722566034},{"_id":"public/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1589722566034},{"_id":"public/libs/share/js/jquery.share.min.js","hash":"41367dcb857e02e3c417ebe68a554ce1d4430806","modified":1589722566034},{"_id":"public/libs/share/js/social-share.min.js","hash":"a3090a02786dcd4efc6355c1c1dc978add8d6827","modified":1589722566034},{"_id":"public/libs/gitalk/gitalk.min.js","hash":"8fefe38f28804f90116bdcb74a0875c9de9f3b7d","modified":1589722566034},{"_id":"public/libs/valine/av-min.js","hash":"541efb9edc1ce425cbe3897cfc25803211fe6a05","modified":1589722566034},{"_id":"public/libs/awesome/css/all.css","hash":"ecc41e32ad2696877a1656749841f3b5543bbe3d","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-regular-400.svg","hash":"229afff648cbd17de80176e0feb969c7f514be7e","modified":1589722566034},{"_id":"public/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-solid-900.eot","hash":"cab8e84ae5682d1d556e234df9c790985888def8","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-solid-900.ttf","hash":"9521ed12274c2cbc910cea77657116fcf6545da3","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-brands-400.svg","hash":"25612c76ded31c497effe46454d8d2bb36fb99d6","modified":1589722566034},{"_id":"public/libs/awesome/webfonts/fa-solid-900.svg","hash":"2c026711e4dd6b6d805cc19c0e4a572e6239a05b","modified":1589722566034}],"Category":[{"name":"大数据","_id":"ckab3rqxf0004gswj95aicjcj"},{"name":"待完成","_id":"ckab3rqxw000bgswjcwshgehe"},{"name":"Linux","_id":"ckab3rqy8000pgswj9wx10bkp"},{"name":"杂","_id":"ckab3rqyd000wgswj1lqsc51g"},{"name":"求甚解","_id":"ckab3rqye000zgswjfxtld10t"},{"name":"文献翻译","_id":"ckab3rqyg0013gswjegrab8cp"},{"name":"深度学习","_id":"ckab3rqyh0016gswj0ws8c2so"},{"name":"影评","_id":"ckab3rqyi001bgswjafha9j3i"}],"Data":[{"_id":"friends","data":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}]},{"_id":"musics","data":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}],"Page":[{"title":"about","date":"2019-09-03T08:41:10.000Z","type":"about","layout":"about","_content":"\n\n# 在读研究生\n* <b>硕士 软件工程专业</b>\n西南交通大学\n预计2022年6月毕业\n\n\n# 联系方式\n* <b>Telegram</b>\nhttps://t.me/zhishuang\n* <b>电子邮箱</b>\nzhishuang.rao@gmail.com","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-09-03 16:41:10\ntype: \"about\"\nlayout: \"about\"\n---\n\n\n# 在读研究生\n* <b>硕士 软件工程专业</b>\n西南交通大学\n预计2022年6月毕业\n\n\n# 联系方式\n* <b>Telegram</b>\nhttps://t.me/zhishuang\n* <b>电子邮箱</b>\nzhishuang.rao@gmail.com","updated":"2020-05-17T11:29:26.000Z","path":"about/index.html","comments":1,"_id":"ckab3rqxa0001gswjdamddqby","content":"<h1 id=\"在读研究生\"><a href=\"#在读研究生\" class=\"headerlink\" title=\"在读研究生\"></a>在读研究生</h1><ul>\n<li><b>硕士 软件工程专业</b><br>西南交通大学<br>预计2022年6月毕业</li>\n</ul>\n<h1 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h1><ul>\n<li><b>Telegram</b><br><a href=\"https://t.me/zhishuang\" target=\"_blank\" rel=\"noopener\">https://t.me/zhishuang</a></li>\n<li><b>电子邮箱</b><br><a href=\"mailto:zhishuang.rao@gmail.com\">zhishuang.rao@gmail.com</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"在读研究生\"><a href=\"#在读研究生\" class=\"headerlink\" title=\"在读研究生\"></a>在读研究生</h1><ul>\n<li><b>硕士 软件工程专业</b><br>西南交通大学<br>预计2022年6月毕业</li>\n</ul>\n<h1 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h1><ul>\n<li><b>Telegram</b><br><a href=\"https://t.me/zhishuang\" target=\"_blank\" rel=\"noopener\">https://t.me/zhishuang</a></li>\n<li><b>电子邮箱</b><br><a href=\"mailto:zhishuang.rao@gmail.com\">zhishuang.rao@gmail.com</a></li>\n</ul>\n"},{"title":"archives","date":"2019-07-19T08:39:20.000Z","type":"archives","layout":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-07-19 16:39:20\ntype: \"archives\"\nlayout: \"archives\"\n---","updated":"2020-05-17T11:29:26.000Z","path":"archives/index.html","comments":1,"_id":"ckab3rqxe0003gswj7xiuarzj","content":"","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"contact","date":"2019-09-03T09:17:02.000Z","type":"contact","layout":"contact","_content":"\n大家有任何问题，都可以在下面给我留言。\n或者加我QQ：1032979481\n我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。\n**当然不介意小改改加我哦~~**","source":"contact/index.md","raw":"---\ntitle: contact\ndate: 2019-09-03 17:17:02\ntype: \"contact\"\nlayout: \"contact\"\n---\n\n大家有任何问题，都可以在下面给我留言。\n或者加我QQ：1032979481\n我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。\n**当然不介意小改改加我哦~~**","updated":"2020-05-17T11:29:26.000Z","path":"contact/index.html","comments":1,"_id":"ckab3rqxk0007gswjeb8k9xhe","content":"<p>大家有任何问题，都可以在下面给我留言。<br>或者加我QQ：1032979481<br>我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。<br><strong>当然不介意小改改加我哦~~</strong></p>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>大家有任何问题，都可以在下面给我留言。<br>或者加我QQ：1032979481<br>我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。<br><strong>当然不介意小改改加我哦~~</strong></p>\n"},{"title":"friends","date":"2019-07-19T08:42:10.000Z","type":"friends","layout":"friends","_content":"\n**感谢所有支持和打赏过我的人，希望今后也能和大家一起学习进步。**","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2019-07-19 16:42:10\ntype: \"friends\"\nlayout: \"friends\"\n---\n\n**感谢所有支持和打赏过我的人，希望今后也能和大家一起学习进步。**","updated":"2020-05-17T11:29:26.000Z","path":"friends/index.html","comments":1,"_id":"ckab3rqxn0009gswje1u3dvn6","content":"<p><strong>感谢所有支持和打赏过我的人，希望今后也能和大家一起学习进步。</strong></p>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p><strong>感谢所有支持和打赏过我的人，希望今后也能和大家一起学习进步。</strong></p>\n"},{"title":"tags","date":"2019-07-19T08:40:27.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-07-19 16:40:27\ntype: \"tags\"\nlayout: \"tags\"\n---","updated":"2020-05-17T11:29:26.000Z","path":"tags/index.html","comments":1,"_id":"ckab3rqxw000dgswj7isq5uzl","content":"","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"categories","date":"2020-03-28T12:42:14.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2020-03-28 20:42:14\ntype: \"categories\"\nlayout: \"categories\"\n---\n","updated":"2020-05-17T11:29:26.000Z","path":"categories/index.html","comments":1,"_id":"ckab3rqxz000fgswjat6o82sj","content":"","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""}],"Post":[{"title":"HBase shell 基本操作","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-05-09T06:46:32.000Z","password":null,"summary":null,"img":null,"keywords":"hbase 大数据","_content":"\n* 创建表：\n\t* `create 'student','info'`\n\n* 插入数据到表：\n\t* `put 'student','1001','info:sex','male’`\n\t* `put 'student','1001','info:age','18'`\n\n* 扫描查看表数据\n\t* `scan 'student'`\n\t* `scan 'student',{STARTROW => '1001', STOPROW => '1001'}`\n\t* `scan 'student',{STARTROW => '1001'}`\n\n* 更新指定字段的数据\n\t* `put 'student','1001','info:name','Nick'`\n\t* `put 'student','1001','info:age','100'`\n\n* 查看“指定行”或“指定列族:列”的数据\n\t* `get 'student','1001'`\n\t* `get 'student','1001','info:name'`\n\n* 删除数据\n\t* 删除某 rowkey 的全部数据：`deleteall 'student','1001'`\n\t* 删除某 rowkey 的某一列数据：`delete 'student','1001','info:sex'`\n\n* 清空表数据\n\t* `truncate 'student'`\n\n* 删除表\n\t* `disable 'student'`\n\t* `drop 'student'`","source":"_posts/HBase-shell-基本操作.md","raw":"---\ntitle: HBase shell 基本操作\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-05-09 14:46:32\npassword:\nsummary:\ncategories: 大数据\nimg:\nkeywords: hbase 大数据\ntags: \n\t- hbsse \n\t- 大数据\n---\n\n* 创建表：\n\t* `create 'student','info'`\n\n* 插入数据到表：\n\t* `put 'student','1001','info:sex','male’`\n\t* `put 'student','1001','info:age','18'`\n\n* 扫描查看表数据\n\t* `scan 'student'`\n\t* `scan 'student',{STARTROW => '1001', STOPROW => '1001'}`\n\t* `scan 'student',{STARTROW => '1001'}`\n\n* 更新指定字段的数据\n\t* `put 'student','1001','info:name','Nick'`\n\t* `put 'student','1001','info:age','100'`\n\n* 查看“指定行”或“指定列族:列”的数据\n\t* `get 'student','1001'`\n\t* `get 'student','1001','info:name'`\n\n* 删除数据\n\t* 删除某 rowkey 的全部数据：`deleteall 'student','1001'`\n\t* 删除某 rowkey 的某一列数据：`delete 'student','1001','info:sex'`\n\n* 清空表数据\n\t* `truncate 'student'`\n\n* 删除表\n\t* `disable 'student'`\n\t* `drop 'student'`","slug":"HBase-shell-基本操作","published":1,"updated":"2020-05-17T13:23:53.744Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqx20000gswj8f9n8nma","content":"<ul>\n<li><p>创建表：</p>\n<ul>\n<li><code>create &#39;student&#39;,&#39;info&#39;</code></li>\n</ul>\n</li>\n<li><p>插入数据到表：</p>\n<ul>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:sex&#39;,&#39;male’</code></li>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;18&#39;</code></li>\n</ul>\n</li>\n<li><p>扫描查看表数据</p>\n<ul>\n<li><code>scan &#39;student&#39;</code></li>\n<li><code>scan &#39;student&#39;,{STARTROW =&gt; &#39;1001&#39;, STOPROW =&gt; &#39;1001&#39;}</code></li>\n<li><code>scan &#39;student&#39;,{STARTROW =&gt; &#39;1001&#39;}</code></li>\n</ul>\n</li>\n<li><p>更新指定字段的数据</p>\n<ul>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;,&#39;Nick&#39;</code></li>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;100&#39;</code></li>\n</ul>\n</li>\n<li><p>查看“指定行”或“指定列族:列”的数据</p>\n<ul>\n<li><code>get &#39;student&#39;,&#39;1001&#39;</code></li>\n<li><code>get &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;</code></li>\n</ul>\n</li>\n<li><p>删除数据</p>\n<ul>\n<li>删除某 rowkey 的全部数据：<code>deleteall &#39;student&#39;,&#39;1001&#39;</code></li>\n<li>删除某 rowkey 的某一列数据：<code>delete &#39;student&#39;,&#39;1001&#39;,&#39;info:sex&#39;</code></li>\n</ul>\n</li>\n<li><p>清空表数据</p>\n<ul>\n<li><code>truncate &#39;student&#39;</code></li>\n</ul>\n</li>\n<li><p>删除表</p>\n<ul>\n<li><code>disable &#39;student&#39;</code></li>\n<li><code>drop &#39;student&#39;</code></li>\n</ul>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<ul>\n<li><p>创建表：</p>\n<ul>\n<li><code>create &#39;student&#39;,&#39;info&#39;</code></li>\n</ul>\n</li>\n<li><p>插入数据到表：</p>\n<ul>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:sex&#39;,&#39;male’</code></li>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;18&#39;</code></li>\n</ul>\n</li>\n<li><p>扫描查看表数据</p>\n<ul>\n<li><code>scan &#39;student&#39;</code></li>\n<li><code>scan &#39;student&#39;,{STARTROW =&gt; &#39;1001&#39;, STOPROW =&gt; &#39;1001&#39;}</code></li>\n<li><code>scan &#39;student&#39;,{STARTROW =&gt; &#39;1001&#39;}</code></li>\n</ul>\n</li>\n<li><p>更新指定字段的数据</p>\n<ul>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;,&#39;Nick&#39;</code></li>\n<li><code>put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;100&#39;</code></li>\n</ul>\n</li>\n<li><p>查看“指定行”或“指定列族:列”的数据</p>\n<ul>\n<li><code>get &#39;student&#39;,&#39;1001&#39;</code></li>\n<li><code>get &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;</code></li>\n</ul>\n</li>\n<li><p>删除数据</p>\n<ul>\n<li>删除某 rowkey 的全部数据：<code>deleteall &#39;student&#39;,&#39;1001&#39;</code></li>\n<li>删除某 rowkey 的某一列数据：<code>delete &#39;student&#39;,&#39;1001&#39;,&#39;info:sex&#39;</code></li>\n</ul>\n</li>\n<li><p>清空表数据</p>\n<ul>\n<li><code>truncate &#39;student&#39;</code></li>\n</ul>\n</li>\n<li><p>删除表</p>\n<ul>\n<li><code>disable &#39;student&#39;</code></li>\n<li><code>drop &#39;student&#39;</code></li>\n</ul>\n</li>\n</ul>\n"},{"title":"Todo-List","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-04-30T06:46:32.000Z","password":null,"summary":null,"img":null,"keywords":"todo list","_content":"\n* 前馈网络架构梳理\n\t* MLP（Multi-Layer Perceptrons）\n\t* DAN（Deep unordered composition rivals syntactic methods for text classification）\n\t* fastText（Fasttext. zip: Compressing text classification models）\n\t* doc2vec（Distributed representations of sentences and documents）\n* RNN架构梳理\n\t* vanilla RNN\n\t* LSTM\n\t* GRU\n\t* Tree-LSTM\n\t* chain-structured LSTM（Long short-term memory over recursive structures）\n\t* Graph-LSTM\n\t* Long short-term memory-networks for machine reading\n\t* MT-LSTM（Multi-timescale long short-term memory neural network for modelling sentences and documents）\n\t* TopicRNN（Topicrnn: A recurrent neural network with long-range semantic dependency）\n* CNN架构梳理\n\t* TextCNN（Convolutional neural networks for sentence classification）\n\t* Character-level CNNs（Character-level convolutional networks for text classification）\n\t* VDCNN（Very deep convolutional networks for text classification）\n\t* TreeCNN（Natural language inference by tree-based convolution and heuristic matching）\n\t* GCN\n* 胶囊网络\n\t* Investigating capsule networks with dynamic routing for text classification\n\t* Investigating the transferring capability of capsule networks for text classification\n\t* Towards scalable and reliable capsule networks for challenging NLP applications\n\t* Text classification using capsules\n\t* Stacked Capsule Autoencoders（升级版胶囊网络）\n* 基于注意力机制的模型\n\t* \n\n* 自监督学习 解耦表示 半监督学习","source":"_posts/Todo-List.md","raw":"---\ntitle: Todo-List\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-04-30 14:46:32\npassword:\nsummary:\ncategories: 待完成\nimg:\nkeywords: todo list\ntags: \n\t- todo list\n---\n\n* 前馈网络架构梳理\n\t* MLP（Multi-Layer Perceptrons）\n\t* DAN（Deep unordered composition rivals syntactic methods for text classification）\n\t* fastText（Fasttext. zip: Compressing text classification models）\n\t* doc2vec（Distributed representations of sentences and documents）\n* RNN架构梳理\n\t* vanilla RNN\n\t* LSTM\n\t* GRU\n\t* Tree-LSTM\n\t* chain-structured LSTM（Long short-term memory over recursive structures）\n\t* Graph-LSTM\n\t* Long short-term memory-networks for machine reading\n\t* MT-LSTM（Multi-timescale long short-term memory neural network for modelling sentences and documents）\n\t* TopicRNN（Topicrnn: A recurrent neural network with long-range semantic dependency）\n* CNN架构梳理\n\t* TextCNN（Convolutional neural networks for sentence classification）\n\t* Character-level CNNs（Character-level convolutional networks for text classification）\n\t* VDCNN（Very deep convolutional networks for text classification）\n\t* TreeCNN（Natural language inference by tree-based convolution and heuristic matching）\n\t* GCN\n* 胶囊网络\n\t* Investigating capsule networks with dynamic routing for text classification\n\t* Investigating the transferring capability of capsule networks for text classification\n\t* Towards scalable and reliable capsule networks for challenging NLP applications\n\t* Text classification using capsules\n\t* Stacked Capsule Autoencoders（升级版胶囊网络）\n* 基于注意力机制的模型\n\t* \n\n* 自监督学习 解耦表示 半监督学习","slug":"Todo-List","published":1,"updated":"2020-05-17T13:30:01.750Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqxc0002gswj3z0r6abj","content":"<ul>\n<li><p>前馈网络架构梳理</p>\n<ul>\n<li>MLP（Multi-Layer Perceptrons）</li>\n<li>DAN（Deep unordered composition rivals syntactic methods for text classification）</li>\n<li>fastText（Fasttext. zip: Compressing text classification models）</li>\n<li>doc2vec（Distributed representations of sentences and documents）</li>\n</ul>\n</li>\n<li><p>RNN架构梳理</p>\n<ul>\n<li>vanilla RNN</li>\n<li>LSTM</li>\n<li>GRU</li>\n<li>Tree-LSTM</li>\n<li>chain-structured LSTM（Long short-term memory over recursive structures）</li>\n<li>Graph-LSTM</li>\n<li>Long short-term memory-networks for machine reading</li>\n<li>MT-LSTM（Multi-timescale long short-term memory neural network for modelling sentences and documents）</li>\n<li>TopicRNN（Topicrnn: A recurrent neural network with long-range semantic dependency）</li>\n</ul>\n</li>\n<li><p>CNN架构梳理</p>\n<ul>\n<li>TextCNN（Convolutional neural networks for sentence classification）</li>\n<li>Character-level CNNs（Character-level convolutional networks for text classification）</li>\n<li>VDCNN（Very deep convolutional networks for text classification）</li>\n<li>TreeCNN（Natural language inference by tree-based convolution and heuristic matching）</li>\n<li>GCN</li>\n</ul>\n</li>\n<li><p>胶囊网络</p>\n<ul>\n<li>Investigating capsule networks with dynamic routing for text classification</li>\n<li>Investigating the transferring capability of capsule networks for text classification</li>\n<li>Towards scalable and reliable capsule networks for challenging NLP applications</li>\n<li>Text classification using capsules</li>\n<li>Stacked Capsule Autoencoders（升级版胶囊网络）</li>\n</ul>\n</li>\n<li><p>基于注意力机制的模型</p>\n<ul>\n<li></li>\n</ul>\n</li>\n<li><p>自监督学习 解耦表示 半监督学习</p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<ul>\n<li><p>前馈网络架构梳理</p>\n<ul>\n<li>MLP（Multi-Layer Perceptrons）</li>\n<li>DAN（Deep unordered composition rivals syntactic methods for text classification）</li>\n<li>fastText（Fasttext. zip: Compressing text classification models）</li>\n<li>doc2vec（Distributed representations of sentences and documents）</li>\n</ul>\n</li>\n<li><p>RNN架构梳理</p>\n<ul>\n<li>vanilla RNN</li>\n<li>LSTM</li>\n<li>GRU</li>\n<li>Tree-LSTM</li>\n<li>chain-structured LSTM（Long short-term memory over recursive structures）</li>\n<li>Graph-LSTM</li>\n<li>Long short-term memory-networks for machine reading</li>\n<li>MT-LSTM（Multi-timescale long short-term memory neural network for modelling sentences and documents）</li>\n<li>TopicRNN（Topicrnn: A recurrent neural network with long-range semantic dependency）</li>\n</ul>\n</li>\n<li><p>CNN架构梳理</p>\n<ul>\n<li>TextCNN（Convolutional neural networks for sentence classification）</li>\n<li>Character-level CNNs（Character-level convolutional networks for text classification）</li>\n<li>VDCNN（Very deep convolutional networks for text classification）</li>\n<li>TreeCNN（Natural language inference by tree-based convolution and heuristic matching）</li>\n<li>GCN</li>\n</ul>\n</li>\n<li><p>胶囊网络</p>\n<ul>\n<li>Investigating capsule networks with dynamic routing for text classification</li>\n<li>Investigating the transferring capability of capsule networks for text classification</li>\n<li>Towards scalable and reliable capsule networks for challenging NLP applications</li>\n<li>Text classification using capsules</li>\n<li>Stacked Capsule Autoencoders（升级版胶囊网络）</li>\n</ul>\n</li>\n<li><p>基于注意力机制的模型</p>\n<ul>\n<li></li>\n</ul>\n</li>\n<li><p>自监督学习 解耦表示 半监督学习</p>\n</li>\n</ul>\n"},{"title":"Zookeeper+Hadoop+HBase搭建","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-05-07T13:54:26.000Z","password":null,"summary":null,"img":null,"keywords":"hadoop zookeeper hbase 大数据","_content":"\n[Hadoop搭建](https://zhishuang.tk/2020/04/30/ubuntu1604-da-jian-hadoop-ji-qun/)\n\n[Zookeeper+Hadoopda搭建（Hadoop HA）](https://zhishuang.tk/2020/05/06/hadoop-ha-da-jian/)\n\n这儿实现在Hadoop HA的基础上搭建Hbase\n\n## 安装Hbase\n\n将安装文件`hbase-2.2.4-bin.tar.gz`到`/usr/local`并重命名为`hbase`\n\n```\ntar -zxvf hbase-2.2.4-bin.tar.gz -C /usr/local\ncd /usr/local\nmv -r hbase-2.2.4 hbase\n```\n\n## 配置Hbase\n\n**环境变量**，执行`sudo gedit /etc/profile`打开配置文件，添加如下内容\n\n```\n#set hbase env\nexport HBASE_HOME=/usr/local/hbase\nexport PATH=$HBASE_HOME/bin:$PATH\n```\n\n记得所有主机都要配置，执行`source /etc/profile`使配置生效\n\n**hbase-env.sh**\n\n```\nexport JAVA_HOME=/usr/java/jdk1.8.0_251\nexport HADOOP_HOME=/usr/local/hadoop\nexport HBASE_HOME=/usr/local/hbase\n#关闭自身zookeeper，采用外部的zookeeper\nexport HBASE_MANAGES_ZK=false\n```\n\n**hbase-site.xml**\n\n```\n<configuration>\n\t<!-- hadoop集群名称 -->\n    <property>\n        <name>hbase.rootdir</name>\n        <value>hdfs://mycluster/hbase</value>\n    </property>\n    <property>\n        <name>hbase.zookeeper.quorum</name>\n        <value>master,slave1,slave2</value>\n    </property>\n    <property>\n        <name>hbase.zookeeper.property.clientPort</name>\n        <value>2181</value>\n    </property>\n    <!--  是否是完全分布式 -->\n    <property>\n        <name>hbase.cluster.distributed</name>\n        <value>true</value>\n    </property>\n    <!--  完全分布式式必须为false  -->\n    <property>\n        <name>hbase.unsafe.stream.capability.enforce</name>\n        <value>false</value>\n    </property>\n    <!--  指定缓存文件存储的路径 -->\n    <property>\n        <name>hbase.tmp.dir</name>\n        <value>/usr/local/hadoop/tmp</value>\n    </property>\n    <!--  指定Zookeeper数据存储的路径  -->\n    <property>\n    \t<name>hbase.zookeeper.property.dataDir</name>\n    \t<value>/usr/local/zookeeper/zkData</value>\n    </property>\n</configuration>\n```\n\n**regionservers**\n\n```\nmaster\nslave1\nslave2\n```\n\n**配置Hmaster高可用**\n\n为了保证HBase集群的高可靠性，HBase支持多Backup Master 设置。当Active Master挂掉后，Backup Master可以自动接管整个HBase的集群。该配置极其简单：在 $HBASE_HOME/conf/目录下新增文件配置backup-masters，在其内添加要用做Backup Master的节点hostname。\n\t\t执行`gedit /usr/local/hbase/conf/backup-masters`新建并打开文件，添加`slave2`\n\t\t没设置backup-masters之前启动hbase， 只有一台有启动了HMaster进程，设置之后，重新启动整个集群，我们会发现，在backup-masters清单上的主机，都启动了HMaster进程\n\n**分发hbase给其他主机**\n\n```\nscp -r /usr/local/hbase/ slave1:/usr/local/\nscp -r /usr/local/hbase/ slave1:/usr/local/\n```\n\n## 时间同步\n\n执行`sudo apt-get install ntp`安装ntp\n\n配置ntp，执行`gedit /etc/ntp.conf`打开配置文件\n\n* master端配置\n\n```\n# /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\npool 0.ubuntu.pool.ntp.org iburst\npool 1.ubuntu.pool.ntp.org iburst\npool 2.ubuntu.pool.ntp.org iburst\npool 3.ubuntu.pool.ntp.org iburst\n\n# Use Ubuntu's ntp server as a fallback.\npool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\nrestrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API\n```\n\n* slave端配置\n\n```\n# /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\n# pool 0.ubuntu.pool.ntp.org iburst\n# pool 1.ubuntu.pool.ntp.org iburst\n# pool 2.ubuntu.pool.ntp.org iburst\n# pool 3.ubuntu.pool.ntp.org iburst\nserver 192.168.79.129\n# Use Ubuntu's ntp server as a fallback.\n# pool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\n# restrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API\n```\n\n\n\n查看ntp的时间服务是否启动：`ps -aux | grep ntp`\n\n执行 `service ntp restart`，重启ntp服务\n\n执行`ntpq -p`查看配置\n\n这个命令可以列出目前我们的 NTP 与相关的上层 NTP 的状态，上头的几个字段的意义为：\n\n* remote: 它指的就是本地机器所连接的远程NTP服务器；\n* refid: 它指的是给远程服务器提供时间同步的服务器；\n* st: 远程服务器的层级别（stratum）. 由于NTP是层型结构,有顶端的服务器,多层的Relay Server再到客户端。所以服务器从高到低级别可以设定为1-16. 为了减缓负荷和网络堵塞,原则上应该避免直接连接到级别为1的服务器的；\n* when: 几秒钟前曾经做过时间同步化更新的动作；\n* poll: 本地机和远程服务器多少时间进行一次同步(单位为秒).在一开始运行NTP的时候这个poll值会比较小,那样和服务器同步的频率也就增加了,可以尽快调整到正确的时间范围.之后poll值会逐渐增大,同步的频率也就会相应减小；\n* reach: 已经向上层 NTP 服务器要求更新的次数；\n* delay: 网络传输过程当中延迟的时间，单位为 10^(-6) 秒；\n* offset: 时间补偿的结果，单位与 10^(-3) 秒；\n* jitter: Linux 系统时间与 BIOS 硬件时间的差异时间， 单为 10^(-6) 秒。简单地说这个数值的绝对值越小我们和服务器的时间就越精确；\n* *: 它告诉我们远端的服务器已经被确认为我们的主NTP Server,我们系统的时间将由这台机器所提供；\n* +: 它将作为辅助的NTP Server和带有号的服务器一起为我们提供同步服务. 当号服务器不可用时它就可以接管；\n* -: 远程服务器被clustering algorithm认为是不合格的NTP Server；\n* x: 远程服务器不可用\n\n## 启动HBase\n\n首先启动Hadoop-HA集群，再执行`start-hbase.start`启动HBase，执行jps命令，可以看到：\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141401.png)\n\n从`http://master:16010/`可查看HBase集群信息\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141902.png)\n\n## 群起脚本\n\n```\n#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo \"No Args Input Error!!!!!\"\n   exit\nfi\ncase $1 in \n\"start\")\n   \techo \"======================== start zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh start\"\n\tdone\n\techo \"======================== start hdfs ========================== \"\n  \tssh master \"source /etc/profile;start-dfs.sh\"\n   \techo \"======================== start yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;start-yarn.sh\"\n   \techo \"======================== start hbase ========================== \"\n   \tssh master \"source /etc/profile;start-hbase.sh\"\n;;\n\"stop\")\n\techo \"======================== stop hbase ========================== \"\n  \tssh master \"source /etc/profile;stop-hbase.sh\"\n\techo \"======================== stop yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;stop-yarn.sh\"\n   \techo \"======================== stop hdfs ========================== \"\n  \tssh master \"source /etc/profile;stop-dfs.sh\"\n  \techo \"======================== stop zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh stop\"\n\tdone\n;;\n*)\n  \techo \"Input Args Error!!!!!\"\n;;\nesac\n```\n\n","source":"_posts/Zookeeper-Hadoop-HBase搭建.md","raw":"---\ntitle: Zookeeper+Hadoop+HBase搭建\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-05-07 21:54:26\npassword:\nsummary:\ncategories: 大数据\nimg:\nkeywords: hadoop zookeeper hbase 大数据\ntags:\n\t- hadoop\n\t- zookeeper\n\t- hbase\n\t- 大数据\n---\n\n[Hadoop搭建](https://zhishuang.tk/2020/04/30/ubuntu1604-da-jian-hadoop-ji-qun/)\n\n[Zookeeper+Hadoopda搭建（Hadoop HA）](https://zhishuang.tk/2020/05/06/hadoop-ha-da-jian/)\n\n这儿实现在Hadoop HA的基础上搭建Hbase\n\n## 安装Hbase\n\n将安装文件`hbase-2.2.4-bin.tar.gz`到`/usr/local`并重命名为`hbase`\n\n```\ntar -zxvf hbase-2.2.4-bin.tar.gz -C /usr/local\ncd /usr/local\nmv -r hbase-2.2.4 hbase\n```\n\n## 配置Hbase\n\n**环境变量**，执行`sudo gedit /etc/profile`打开配置文件，添加如下内容\n\n```\n#set hbase env\nexport HBASE_HOME=/usr/local/hbase\nexport PATH=$HBASE_HOME/bin:$PATH\n```\n\n记得所有主机都要配置，执行`source /etc/profile`使配置生效\n\n**hbase-env.sh**\n\n```\nexport JAVA_HOME=/usr/java/jdk1.8.0_251\nexport HADOOP_HOME=/usr/local/hadoop\nexport HBASE_HOME=/usr/local/hbase\n#关闭自身zookeeper，采用外部的zookeeper\nexport HBASE_MANAGES_ZK=false\n```\n\n**hbase-site.xml**\n\n```\n<configuration>\n\t<!-- hadoop集群名称 -->\n    <property>\n        <name>hbase.rootdir</name>\n        <value>hdfs://mycluster/hbase</value>\n    </property>\n    <property>\n        <name>hbase.zookeeper.quorum</name>\n        <value>master,slave1,slave2</value>\n    </property>\n    <property>\n        <name>hbase.zookeeper.property.clientPort</name>\n        <value>2181</value>\n    </property>\n    <!--  是否是完全分布式 -->\n    <property>\n        <name>hbase.cluster.distributed</name>\n        <value>true</value>\n    </property>\n    <!--  完全分布式式必须为false  -->\n    <property>\n        <name>hbase.unsafe.stream.capability.enforce</name>\n        <value>false</value>\n    </property>\n    <!--  指定缓存文件存储的路径 -->\n    <property>\n        <name>hbase.tmp.dir</name>\n        <value>/usr/local/hadoop/tmp</value>\n    </property>\n    <!--  指定Zookeeper数据存储的路径  -->\n    <property>\n    \t<name>hbase.zookeeper.property.dataDir</name>\n    \t<value>/usr/local/zookeeper/zkData</value>\n    </property>\n</configuration>\n```\n\n**regionservers**\n\n```\nmaster\nslave1\nslave2\n```\n\n**配置Hmaster高可用**\n\n为了保证HBase集群的高可靠性，HBase支持多Backup Master 设置。当Active Master挂掉后，Backup Master可以自动接管整个HBase的集群。该配置极其简单：在 $HBASE_HOME/conf/目录下新增文件配置backup-masters，在其内添加要用做Backup Master的节点hostname。\n\t\t执行`gedit /usr/local/hbase/conf/backup-masters`新建并打开文件，添加`slave2`\n\t\t没设置backup-masters之前启动hbase， 只有一台有启动了HMaster进程，设置之后，重新启动整个集群，我们会发现，在backup-masters清单上的主机，都启动了HMaster进程\n\n**分发hbase给其他主机**\n\n```\nscp -r /usr/local/hbase/ slave1:/usr/local/\nscp -r /usr/local/hbase/ slave1:/usr/local/\n```\n\n## 时间同步\n\n执行`sudo apt-get install ntp`安装ntp\n\n配置ntp，执行`gedit /etc/ntp.conf`打开配置文件\n\n* master端配置\n\n```\n# /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\npool 0.ubuntu.pool.ntp.org iburst\npool 1.ubuntu.pool.ntp.org iburst\npool 2.ubuntu.pool.ntp.org iburst\npool 3.ubuntu.pool.ntp.org iburst\n\n# Use Ubuntu's ntp server as a fallback.\npool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\nrestrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API\n```\n\n* slave端配置\n\n```\n# /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\n# pool 0.ubuntu.pool.ntp.org iburst\n# pool 1.ubuntu.pool.ntp.org iburst\n# pool 2.ubuntu.pool.ntp.org iburst\n# pool 3.ubuntu.pool.ntp.org iburst\nserver 192.168.79.129\n# Use Ubuntu's ntp server as a fallback.\n# pool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\n# restrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API\n```\n\n\n\n查看ntp的时间服务是否启动：`ps -aux | grep ntp`\n\n执行 `service ntp restart`，重启ntp服务\n\n执行`ntpq -p`查看配置\n\n这个命令可以列出目前我们的 NTP 与相关的上层 NTP 的状态，上头的几个字段的意义为：\n\n* remote: 它指的就是本地机器所连接的远程NTP服务器；\n* refid: 它指的是给远程服务器提供时间同步的服务器；\n* st: 远程服务器的层级别（stratum）. 由于NTP是层型结构,有顶端的服务器,多层的Relay Server再到客户端。所以服务器从高到低级别可以设定为1-16. 为了减缓负荷和网络堵塞,原则上应该避免直接连接到级别为1的服务器的；\n* when: 几秒钟前曾经做过时间同步化更新的动作；\n* poll: 本地机和远程服务器多少时间进行一次同步(单位为秒).在一开始运行NTP的时候这个poll值会比较小,那样和服务器同步的频率也就增加了,可以尽快调整到正确的时间范围.之后poll值会逐渐增大,同步的频率也就会相应减小；\n* reach: 已经向上层 NTP 服务器要求更新的次数；\n* delay: 网络传输过程当中延迟的时间，单位为 10^(-6) 秒；\n* offset: 时间补偿的结果，单位与 10^(-3) 秒；\n* jitter: Linux 系统时间与 BIOS 硬件时间的差异时间， 单为 10^(-6) 秒。简单地说这个数值的绝对值越小我们和服务器的时间就越精确；\n* *: 它告诉我们远端的服务器已经被确认为我们的主NTP Server,我们系统的时间将由这台机器所提供；\n* +: 它将作为辅助的NTP Server和带有号的服务器一起为我们提供同步服务. 当号服务器不可用时它就可以接管；\n* -: 远程服务器被clustering algorithm认为是不合格的NTP Server；\n* x: 远程服务器不可用\n\n## 启动HBase\n\n首先启动Hadoop-HA集群，再执行`start-hbase.start`启动HBase，执行jps命令，可以看到：\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141401.png)\n\n从`http://master:16010/`可查看HBase集群信息\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141902.png)\n\n## 群起脚本\n\n```\n#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo \"No Args Input Error!!!!!\"\n   exit\nfi\ncase $1 in \n\"start\")\n   \techo \"======================== start zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh start\"\n\tdone\n\techo \"======================== start hdfs ========================== \"\n  \tssh master \"source /etc/profile;start-dfs.sh\"\n   \techo \"======================== start yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;start-yarn.sh\"\n   \techo \"======================== start hbase ========================== \"\n   \tssh master \"source /etc/profile;start-hbase.sh\"\n;;\n\"stop\")\n\techo \"======================== stop hbase ========================== \"\n  \tssh master \"source /etc/profile;stop-hbase.sh\"\n\techo \"======================== stop yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;stop-yarn.sh\"\n   \techo \"======================== stop hdfs ========================== \"\n  \tssh master \"source /etc/profile;stop-dfs.sh\"\n  \techo \"======================== stop zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh stop\"\n\tdone\n;;\n*)\n  \techo \"Input Args Error!!!!!\"\n;;\nesac\n```\n\n","slug":"Zookeeper-Hadoop-HBase搭建","published":1,"updated":"2020-05-17T13:30:49.420Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqxi0006gswjhtho0t53","content":"<p><a href=\"https://zhishuang.tk/2020/04/30/ubuntu1604-da-jian-hadoop-ji-qun/\">Hadoop搭建</a></p>\n<p><a href=\"https://zhishuang.tk/2020/05/06/hadoop-ha-da-jian/\">Zookeeper+Hadoopda搭建（Hadoop HA）</a></p>\n<p>这儿实现在Hadoop HA的基础上搭建Hbase</p>\n<h2 id=\"安装Hbase\"><a href=\"#安装Hbase\" class=\"headerlink\" title=\"安装Hbase\"></a>安装Hbase</h2><p>将安装文件<code>hbase-2.2.4-bin.tar.gz</code>到<code>/usr/local</code>并重命名为<code>hbase</code></p>\n<pre><code>tar -zxvf hbase-2.2.4-bin.tar.gz -C /usr/local\ncd /usr/local\nmv -r hbase-2.2.4 hbase</code></pre><h2 id=\"配置Hbase\"><a href=\"#配置Hbase\" class=\"headerlink\" title=\"配置Hbase\"></a>配置Hbase</h2><p><strong>环境变量</strong>，执行<code>sudo gedit /etc/profile</code>打开配置文件，添加如下内容</p>\n<pre><code>#set hbase env\nexport HBASE_HOME=/usr/local/hbase\nexport PATH=$HBASE_HOME/bin:$PATH</code></pre><p>记得所有主机都要配置，执行<code>source /etc/profile</code>使配置生效</p>\n<p><strong>hbase-env.sh</strong></p>\n<pre><code>export JAVA_HOME=/usr/java/jdk1.8.0_251\nexport HADOOP_HOME=/usr/local/hadoop\nexport HBASE_HOME=/usr/local/hbase\n#关闭自身zookeeper，采用外部的zookeeper\nexport HBASE_MANAGES_ZK=false</code></pre><p><strong>hbase-site.xml</strong></p>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- hadoop集群名称 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.rootdir&lt;/name&gt;\n        &lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;\n        &lt;value&gt;master,slave1,slave2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;\n        &lt;value&gt;2181&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  是否是完全分布式 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  完全分布式式必须为false  --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;\n        &lt;value&gt;false&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  指定缓存文件存储的路径 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  指定Zookeeper数据存储的路径  --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n        &lt;value&gt;/usr/local/zookeeper/zkData&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>regionservers</strong></p>\n<pre><code>master\nslave1\nslave2</code></pre><p><strong>配置Hmaster高可用</strong></p>\n<p>为了保证HBase集群的高可靠性，HBase支持多Backup Master 设置。当Active Master挂掉后，Backup Master可以自动接管整个HBase的集群。该配置极其简单：在 $HBASE_HOME/conf/目录下新增文件配置backup-masters，在其内添加要用做Backup Master的节点hostname。<br>        执行<code>gedit /usr/local/hbase/conf/backup-masters</code>新建并打开文件，添加<code>slave2</code><br>        没设置backup-masters之前启动hbase， 只有一台有启动了HMaster进程，设置之后，重新启动整个集群，我们会发现，在backup-masters清单上的主机，都启动了HMaster进程</p>\n<p><strong>分发hbase给其他主机</strong></p>\n<pre><code>scp -r /usr/local/hbase/ slave1:/usr/local/\nscp -r /usr/local/hbase/ slave1:/usr/local/</code></pre><h2 id=\"时间同步\"><a href=\"#时间同步\" class=\"headerlink\" title=\"时间同步\"></a>时间同步</h2><p>执行<code>sudo apt-get install ntp</code>安装ntp</p>\n<p>配置ntp，执行<code>gedit /etc/ntp.conf</code>打开配置文件</p>\n<ul>\n<li>master端配置</li>\n</ul>\n<pre><code># /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\npool 0.ubuntu.pool.ntp.org iburst\npool 1.ubuntu.pool.ntp.org iburst\npool 2.ubuntu.pool.ntp.org iburst\npool 3.ubuntu.pool.ntp.org iburst\n\n# Use Ubuntu&#39;s ntp server as a fallback.\npool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\nrestrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API</code></pre><ul>\n<li>slave端配置</li>\n</ul>\n<pre><code># /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\n# pool 0.ubuntu.pool.ntp.org iburst\n# pool 1.ubuntu.pool.ntp.org iburst\n# pool 2.ubuntu.pool.ntp.org iburst\n# pool 3.ubuntu.pool.ntp.org iburst\nserver 192.168.79.129\n# Use Ubuntu&#39;s ntp server as a fallback.\n# pool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\n# restrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API</code></pre><p>查看ntp的时间服务是否启动：<code>ps -aux | grep ntp</code></p>\n<p>执行 <code>service ntp restart</code>，重启ntp服务</p>\n<p>执行<code>ntpq -p</code>查看配置</p>\n<p>这个命令可以列出目前我们的 NTP 与相关的上层 NTP 的状态，上头的几个字段的意义为：</p>\n<ul>\n<li>remote: 它指的就是本地机器所连接的远程NTP服务器；</li>\n<li>refid: 它指的是给远程服务器提供时间同步的服务器；</li>\n<li>st: 远程服务器的层级别（stratum）. 由于NTP是层型结构,有顶端的服务器,多层的Relay Server再到客户端。所以服务器从高到低级别可以设定为1-16. 为了减缓负荷和网络堵塞,原则上应该避免直接连接到级别为1的服务器的；</li>\n<li>when: 几秒钟前曾经做过时间同步化更新的动作；</li>\n<li>poll: 本地机和远程服务器多少时间进行一次同步(单位为秒).在一开始运行NTP的时候这个poll值会比较小,那样和服务器同步的频率也就增加了,可以尽快调整到正确的时间范围.之后poll值会逐渐增大,同步的频率也就会相应减小；</li>\n<li>reach: 已经向上层 NTP 服务器要求更新的次数；</li>\n<li>delay: 网络传输过程当中延迟的时间，单位为 10^(-6) 秒；</li>\n<li>offset: 时间补偿的结果，单位与 10^(-3) 秒；</li>\n<li>jitter: Linux 系统时间与 BIOS 硬件时间的差异时间， 单为 10^(-6) 秒。简单地说这个数值的绝对值越小我们和服务器的时间就越精确；</li>\n<li>*: 它告诉我们远端的服务器已经被确认为我们的主NTP Server,我们系统的时间将由这台机器所提供；</li>\n<li>+: 它将作为辅助的NTP Server和带有号的服务器一起为我们提供同步服务. 当号服务器不可用时它就可以接管；</li>\n<li>-: 远程服务器被clustering algorithm认为是不合格的NTP Server；</li>\n<li>x: 远程服务器不可用</li>\n</ul>\n<h2 id=\"启动HBase\"><a href=\"#启动HBase\" class=\"headerlink\" title=\"启动HBase\"></a>启动HBase</h2><p>首先启动Hadoop-HA集群，再执行<code>start-hbase.start</code>启动HBase，执行jps命令，可以看到：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141401.png\" alt=\"\"></p>\n<p>从<code>http://master:16010/</code>可查看HBase集群信息</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141902.png\" alt=\"\"></p>\n<h2 id=\"群起脚本\"><a href=\"#群起脚本\" class=\"headerlink\" title=\"群起脚本\"></a>群起脚本</h2><pre><code>#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo &quot;No Args Input Error!!!!!&quot;\n   exit\nfi\ncase $1 in \n&quot;start&quot;)\n       echo &quot;======================== start zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh start&quot;\n    done\n    echo &quot;======================== start hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;start-dfs.sh&quot;\n       echo &quot;======================== start yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;start-yarn.sh&quot;\n       echo &quot;======================== start hbase ========================== &quot;\n       ssh master &quot;source /etc/profile;start-hbase.sh&quot;\n;;\n&quot;stop&quot;)\n    echo &quot;======================== stop hbase ========================== &quot;\n      ssh master &quot;source /etc/profile;stop-hbase.sh&quot;\n    echo &quot;======================== stop yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;stop-yarn.sh&quot;\n       echo &quot;======================== stop hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;stop-dfs.sh&quot;\n      echo &quot;======================== stop zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh stop&quot;\n    done\n;;\n*)\n      echo &quot;Input Args Error!!!!!&quot;\n;;\nesac</code></pre>","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p><a href=\"https://zhishuang.tk/2020/04/30/ubuntu1604-da-jian-hadoop-ji-qun/\">Hadoop搭建</a></p>\n<p><a href=\"https://zhishuang.tk/2020/05/06/hadoop-ha-da-jian/\">Zookeeper+Hadoopda搭建（Hadoop HA）</a></p>\n<p>这儿实现在Hadoop HA的基础上搭建Hbase</p>\n<h2 id=\"安装Hbase\"><a href=\"#安装Hbase\" class=\"headerlink\" title=\"安装Hbase\"></a>安装Hbase</h2><p>将安装文件<code>hbase-2.2.4-bin.tar.gz</code>到<code>/usr/local</code>并重命名为<code>hbase</code></p>\n<pre><code>tar -zxvf hbase-2.2.4-bin.tar.gz -C /usr/local\ncd /usr/local\nmv -r hbase-2.2.4 hbase</code></pre><h2 id=\"配置Hbase\"><a href=\"#配置Hbase\" class=\"headerlink\" title=\"配置Hbase\"></a>配置Hbase</h2><p><strong>环境变量</strong>，执行<code>sudo gedit /etc/profile</code>打开配置文件，添加如下内容</p>\n<pre><code>#set hbase env\nexport HBASE_HOME=/usr/local/hbase\nexport PATH=$HBASE_HOME/bin:$PATH</code></pre><p>记得所有主机都要配置，执行<code>source /etc/profile</code>使配置生效</p>\n<p><strong>hbase-env.sh</strong></p>\n<pre><code>export JAVA_HOME=/usr/java/jdk1.8.0_251\nexport HADOOP_HOME=/usr/local/hadoop\nexport HBASE_HOME=/usr/local/hbase\n#关闭自身zookeeper，采用外部的zookeeper\nexport HBASE_MANAGES_ZK=false</code></pre><p><strong>hbase-site.xml</strong></p>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- hadoop集群名称 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.rootdir&lt;/name&gt;\n        &lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;\n        &lt;value&gt;master,slave1,slave2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;\n        &lt;value&gt;2181&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  是否是完全分布式 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  完全分布式式必须为false  --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;\n        &lt;value&gt;false&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  指定缓存文件存储的路径 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!--  指定Zookeeper数据存储的路径  --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n        &lt;value&gt;/usr/local/zookeeper/zkData&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>regionservers</strong></p>\n<pre><code>master\nslave1\nslave2</code></pre><p><strong>配置Hmaster高可用</strong></p>\n<p>为了保证HBase集群的高可靠性，HBase支持多Backup Master 设置。当Active Master挂掉后，Backup Master可以自动接管整个HBase的集群。该配置极其简单：在 $HBASE_HOME/conf/目录下新增文件配置backup-masters，在其内添加要用做Backup Master的节点hostname。<br>        执行<code>gedit /usr/local/hbase/conf/backup-masters</code>新建并打开文件，添加<code>slave2</code><br>        没设置backup-masters之前启动hbase， 只有一台有启动了HMaster进程，设置之后，重新启动整个集群，我们会发现，在backup-masters清单上的主机，都启动了HMaster进程</p>\n<p><strong>分发hbase给其他主机</strong></p>\n<pre><code>scp -r /usr/local/hbase/ slave1:/usr/local/\nscp -r /usr/local/hbase/ slave1:/usr/local/</code></pre><h2 id=\"时间同步\"><a href=\"#时间同步\" class=\"headerlink\" title=\"时间同步\"></a>时间同步</h2><p>执行<code>sudo apt-get install ntp</code>安装ntp</p>\n<p>配置ntp，执行<code>gedit /etc/ntp.conf</code>打开配置文件</p>\n<ul>\n<li>master端配置</li>\n</ul>\n<pre><code># /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\npool 0.ubuntu.pool.ntp.org iburst\npool 1.ubuntu.pool.ntp.org iburst\npool 2.ubuntu.pool.ntp.org iburst\npool 3.ubuntu.pool.ntp.org iburst\n\n# Use Ubuntu&#39;s ntp server as a fallback.\npool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\nrestrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API</code></pre><ul>\n<li>slave端配置</li>\n</ul>\n<pre><code># /etc/ntp.conf, configuration for ntpd; see ntp.conf(5) for help\n# 时间差异文件\ndriftfile /var/lib/ntp/ntp.drift\n\n# 分析统计信息\n#statsdir /var/log/ntpstats/\n\nstatistics loopstats peerstats clockstats\nfilegen loopstats file loopstats type day enable\nfilegen peerstats file peerstats type day enable\nfilegen clockstats file clockstats type day enable\n\n# 上层ntp server.\n# pool 0.ubuntu.pool.ntp.org iburst\n# pool 1.ubuntu.pool.ntp.org iburst\n# pool 2.ubuntu.pool.ntp.org iburst\n# pool 3.ubuntu.pool.ntp.org iburst\nserver 192.168.79.129\n# Use Ubuntu&#39;s ntp server as a fallback.\n# pool ntp.ubuntu.com\n\n# 不允许来自公网上ipv4和ipv6客户端的访问\nrestrict -4 default kod notrap nomodify nopeer noquery limited\nrestrict -6 default kod notrap nomodify nopeer noquery limited\n\n# 让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端.\nrestrict 127.0.0.1\nrestrict ::1\n\n# Needed for adding pool entries\nrestrict source notrap nomodify noquery\n\n# 允许这个网段的对时请求.\n# restrict 192.168.79.0 mask 255.255.255.0 nomodify \n\n# If you want to provide time to your local subnet, change the next line.\n# (Again, the address is an example only.)\n#broadcast 192.168.123.255\n\n# If you want to listen to time broadcasts on your local subnet, de-comment the\n# next lines.  Please do this only if you trust everybody on the network!\n#disable auth\n#broadcastclient\n\n#Changes recquired to use pps synchonisation as explained in documentation:\n#http://www.ntp.org/ntpfaq/NTP-s-config-adv.htm#AEN3918\n\n#server 127.127.8.1 mode 135 prefer    # Meinberg GPS167 with PPS\n#fudge 127.127.8.1 time1 0.0042        # relative to PPS for my hardware\n\n#server 127.127.22.1                   # ATOM(PPS)\n#fudge 127.127.22.1 flag3 1            # enable PPS API</code></pre><p>查看ntp的时间服务是否启动：<code>ps -aux | grep ntp</code></p>\n<p>执行 <code>service ntp restart</code>，重启ntp服务</p>\n<p>执行<code>ntpq -p</code>查看配置</p>\n<p>这个命令可以列出目前我们的 NTP 与相关的上层 NTP 的状态，上头的几个字段的意义为：</p>\n<ul>\n<li>remote: 它指的就是本地机器所连接的远程NTP服务器；</li>\n<li>refid: 它指的是给远程服务器提供时间同步的服务器；</li>\n<li>st: 远程服务器的层级别（stratum）. 由于NTP是层型结构,有顶端的服务器,多层的Relay Server再到客户端。所以服务器从高到低级别可以设定为1-16. 为了减缓负荷和网络堵塞,原则上应该避免直接连接到级别为1的服务器的；</li>\n<li>when: 几秒钟前曾经做过时间同步化更新的动作；</li>\n<li>poll: 本地机和远程服务器多少时间进行一次同步(单位为秒).在一开始运行NTP的时候这个poll值会比较小,那样和服务器同步的频率也就增加了,可以尽快调整到正确的时间范围.之后poll值会逐渐增大,同步的频率也就会相应减小；</li>\n<li>reach: 已经向上层 NTP 服务器要求更新的次数；</li>\n<li>delay: 网络传输过程当中延迟的时间，单位为 10^(-6) 秒；</li>\n<li>offset: 时间补偿的结果，单位与 10^(-3) 秒；</li>\n<li>jitter: Linux 系统时间与 BIOS 硬件时间的差异时间， 单为 10^(-6) 秒。简单地说这个数值的绝对值越小我们和服务器的时间就越精确；</li>\n<li>*: 它告诉我们远端的服务器已经被确认为我们的主NTP Server,我们系统的时间将由这台机器所提供；</li>\n<li>+: 它将作为辅助的NTP Server和带有号的服务器一起为我们提供同步服务. 当号服务器不可用时它就可以接管；</li>\n<li>-: 远程服务器被clustering algorithm认为是不合格的NTP Server；</li>\n<li>x: 远程服务器不可用</li>\n</ul>\n<h2 id=\"启动HBase\"><a href=\"#启动HBase\" class=\"headerlink\" title=\"启动HBase\"></a>启动HBase</h2><p>首先启动Hadoop-HA集群，再执行<code>start-hbase.start</code>启动HBase，执行jps命令，可以看到：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141401.png\" alt=\"\"></p>\n<p>从<code>http://master:16010/</code>可查看HBase集群信息</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200509141902.png\" alt=\"\"></p>\n<h2 id=\"群起脚本\"><a href=\"#群起脚本\" class=\"headerlink\" title=\"群起脚本\"></a>群起脚本</h2><pre><code>#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo &quot;No Args Input Error!!!!!&quot;\n   exit\nfi\ncase $1 in \n&quot;start&quot;)\n       echo &quot;======================== start zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh start&quot;\n    done\n    echo &quot;======================== start hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;start-dfs.sh&quot;\n       echo &quot;======================== start yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;start-yarn.sh&quot;\n       echo &quot;======================== start hbase ========================== &quot;\n       ssh master &quot;source /etc/profile;start-hbase.sh&quot;\n;;\n&quot;stop&quot;)\n    echo &quot;======================== stop hbase ========================== &quot;\n      ssh master &quot;source /etc/profile;stop-hbase.sh&quot;\n    echo &quot;======================== stop yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;stop-yarn.sh&quot;\n       echo &quot;======================== stop hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;stop-dfs.sh&quot;\n      echo &quot;======================== stop zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh stop&quot;\n    done\n;;\n*)\n      echo &quot;Input Args Error!!!!!&quot;\n;;\nesac</code></pre>"},{"title":"Hadoop HA 搭建","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-05-06T12:30:35.000Z","password":null,"summary":null,"img":null,"keywords":"高可用 HA hadoop 大数据","_content":"\n所谓HA（High Available）是Hadoop2.0中引入来解决Hadoop1.0中单点故障问题的一种机制。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。\n\n## HDFS-HA集群配置\n\n### 规划集群\n\n| master            | slave1                  | slave2                   |\n| ----------------- | ----------------------- | ------------------------ |\n| NameNode (active) | NameNode (standby)      |                          |\n| JournalNode       | JournalNode             | JournalNode              |\n| DataNode          | DataNode                | DataNode                 |\n| ZK                | ZK                      | ZK                       |\n|                   | ResourceManager(active) | ResourceManager(standby) |\n| NodeManager       | NodeManager             | NodeManager              |\n\n### 配置Zookeeper集群\n\n在master、slave1和slave2三个节点上部署Zookeeper\n\n### 安装zookeeper\n\n解压zookeeper，并重命名为zookeeper\n\n```\ntar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/\ncd /usr/local\nmv apache-zookeeper-3.5.7-bin/ zookeeper\n```\n\n### 配置zookeeper\n\n* 在`/usr/local/zookeeper/`这个目录下创建zkData\n\n```\ncd /usr/local/zookeeper\nmkdir zkData\n```\n\n* 重命名`/usr/local/zookeeper/conf`这个目录下的zoo_sample.cfg为zoo.cfg\n\n```\ncd /usr/local/zookeeper/conf\nmv zoo_sample.cfg zoo.cfg\n```\n\n* 执行`sudo gedit zoo.cfg`打开配置文件，配置如下：\n\n```\n# 修改原有dataDir值如下\ndataDir=/usr/local/zookeeper/zkData\n#######################cluster##########################\nserver.1=master:2888:3888\nserver.2=slave1:2888:3888\nserver.3=slave2:2888:3888\n```\n\nServer.A=B:C:D。\n\nA是一个数字，表示这个是第几号服务器；\n\nB是这个服务器的IP地址；\n\nC是这个服务器与集群中的Leader服务器交换信息的端口；\n\nD是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。\n\n集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。\n\n* 在/usr/local/zookeeper/zkData目录下创建并打开文件myid\n\n```\ngedit myid\n```\n\n在myid文件中增加数据：1\n\n* 拷贝配置好的zookeeper到其他机器上,并分别修改myid文件中内容为2、3\n\n```\nscp -r /usr/local/zookeeper/ slave1:/usr/local/\nscp -r /usr/local/zookeeper/ slave2:/usr/local/\n```\n\n* 配置zookeeper环境变量\n\n执行`sudo gedit /etc/profile`打开配置文件，加入下列内容\n\n```\nexport ZOOKEEPER_HOME=/usr/local/zookeeper\nexport PATH=$ZOOKEEPER_HOME/bin:$PATH\n```\n\n执行`source /etc/profile`命令让配置文件生效\n\n* 拷贝`/etc/profile`文件到其他机器\n\n```\nscp /etc/profile slave1:/etc\n```\n\n\n\n### 启动zookeeper\n\n分别启动zookeeper,在三台机器上执行`zkServer.sh start`命令启动zookeeper,再执行`jps`命令可以看到有`QuorumPeerMain`\n\n## 配置HDFS-HA集群\n\n* 配置core-site.xml：\n\n```\n<configuration>\n\t<!-- 把两个NameNode的地址组装成一个集群mycluster -->\n\t<property>\n\t\t<name>fs.defaultFS</name>\n        <value>hdfs://mycluster</value>\n\t</property>\n\n\t<!-- 指定hadoop运行时产生文件的存储目录 -->\n\t<property>\n\t\t<name>hadoop.tmp.dir</name>\n\t\t<value>/usr/local/hadoop/tmp</value>\n\t</property>\n\t<!-- 在网页界面访问数据使用的用户名。默认值是一个不真实存在的用户，此用户权限很小 -->\n\t<property>\n        <name>hadoop.http.staticuser.user</name>\n        <value>ubuntu</value>\n\t</property> \n\t<!--Ha功能，需要一组zk地址，用逗号分隔。被ZKFailoverController使用于自动失效备援failover-->\n\t<property>\n   \t\t<name>ha.zookeeper.quorum</name>\n  \t    <value>master:2181,slave1:2181,slave2:2181</value>\n \t</property>\n</configuration>\n```\n\n* 配置hdfs-site.xml\n\n```\n<configuration>\n\t<!-- 冗余度 -->\n\t<property>\n  \t\t<name>dfs.replication</name>\n  \t\t<value>3</value>\n\t</property>\n\t<!-- 暂不配置 \n\t<property>\n  \t\t<name>dfs.namenode.secondary.http-address</name>\n  \t\t<value>slave1:9869</value>\n\t</property>\n\t-->\n\t<!-- 完全分布式集群名称 -->\n\t<property>\n\t\t<name>dfs.nameservices</name>\n\t\t<value>mycluster</value>\n\t</property>\n\n\t<!-- 集群中NameNode节点都有哪些 -->\n\t<property>\n\t\t<name>dfs.ha.namenodes.mycluster</name>\n\t\t<value>nn1,nn2</value>\n\t</property>\n\n\t<!-- nn1的RPC通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.rpc-address.mycluster.nn1</name>\n\t\t<value>master:8020</value>\n\t</property>\n\n\t<!-- nn2的RPC通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.rpc-address.mycluster.nn2</name>\n\t\t<value>slave1:8020</value>\n\t</property>\n\n\t<!-- nn1的http通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.http-address.mycluster.nn1</name>\n\t\t<value>master:9870</value>\n\t</property>\n\n\t<!-- nn2的http通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.http-address.mycluster.nn2</name>\n\t\t<value>slave1:9870</value>\n\t</property>\n\n\t<!-- 指定NameNode元数据在JournalNode上的存放位置 -->\n\t<property>\n\t\t<name>dfs.namenode.shared.edits.dir</name>\n\t<value>qjournal://master:8485;slave1:8485;slave2:8485/mycluster</value>\n\t</property>\n\n\t<!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 -->\n\t<property>\n\t\t<name>dfs.ha.fencing.methods</name>\n\t\t<value>sshfence</value>\n\t</property>\n\n\t<!-- 使用隔离机制时需要ssh无秘钥登录-->\n\t<property>\n\t\t<name>dfs.ha.fencing.ssh.private-key-files</name>\n\t\t<value>/home/ubuntu/.ssh/id_rsa</value>\n\t</property>\n\n\t<!-- 声明journalnode服务器存储目录-->\n\t<property>\n\t\t<name>dfs.journalnode.edits.dir</name>\n\t\t<value>/usr/local/hadoop/tmp/jn</value>\n\t</property>\n\n\t<!-- 关闭权限检查-->\n\t<property>\n\t\t<name>dfs.permissions.enable</name>\n\t\t<value>false</value>\n\t</property>\n\t\n\t<!-- 是否开启自动故障转移-->\n\t<property>\n   \t\t<name>dfs.ha.automatic-failover.enabled</name>\n   \t\t<value>true</value>\n\t</property>\n\t\n\t<!--访问代理类：client，mycluster，active配置失败自动切换实现方式-->\n\t<property>\n  \t\t<name>dfs.client.failover.proxy.provider.mycluster</name>\n\t<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n\t</property>\n</configuration>\n```\n\n* 配置mapred-site.xml\n\n```\n<configuration>\n   <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n   </property>\n</configuration>\n```\n\n配置yarn-site.xml\n\n```\n<configuration>\n    <property>\n        <name>yarn.nodemanager.aux-services</name>\n        <value>mapreduce_shuffle</value>\n    </property>\n\n    <!--启用resourcemanager ha-->\n    <property>\n        <name>yarn.resourcemanager.ha.enabled</name>\n        <value>true</value>\n    </property>\n \n    <!--声明两台resourcemanager的地址-->\n    <property>\n        <name>yarn.resourcemanager.cluster-id</name>\n        <value>cluster-yarn1</value>\n    </property>\n\n    <property>\n        <name>yarn.resourcemanager.ha.rm-ids</name>\n        <value>rm1,rm2</value>\n    </property>\n\n    <property>\n        <name>yarn.resourcemanager.hostname.rm1</name>\n        <value>slave1</value>\n    </property>\n\n    <property>\n        <name>yarn.resourcemanager.hostname.rm2</name>\n        <value>slave2</value>\n    </property>\n \n    <!--指定zookeeper集群的地址--> \n    <property>\n        <name>yarn.resourcemanager.zk-address</name>\n        <value>master:2181,slave1:2181,slave2:2181</value>\n    </property>\n\n    <!--启用自动恢复--> \n    <property>\n        <name>yarn.resourcemanager.recovery.enabled</name>\n        <value>true</value>\n    </property>\n \n    <!--指定resourcemanager的状态信息存储在zookeeper集群--> \n    <property>\n\t<name>yarn.resourcemanager.store.class</name>\n<value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>\n    </property>\n\n</configuration>\n```\n\n* 拷贝配置好的Hadoop文件到其他机器上\n\n```\nscp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/\n```\n\n## 启动\n\n### 启动zookeeper集群\n\n分别在master，slave1，slave2上执行`zkServer.sh start`命名启动zk\n\n### 启动journalnode\n\n分别在master，slave1，slave2上执行`hdfs --daemon start journalnode`命令启动JN\n\n运行jps命令检验，master，slave1，slave2上多了JournalNode进程\n\n### 格式化namenode，并启动\n\n在master上执行命令`hdfs namenode -format`格式化namenode\n\n在master上执行命令`hdfs --daemon start namenode`命令格式化namenode\n\n### 副节点同步主节点格式化\n\n在slave1上执行命令`hdfs namenode -bootstrapStandby`命令同步主节点格式化\n\n### 格式化ZKFC\n\n在master上执行命令`hdfs zkfc -formatZK`格式化ZKFC，第一次启动时需要格式化\n\n### 启动HDFS\n\n在master上执行命令`start-dfs.sh`启动HDFS\n\n### 启动YARN\n\n在slave1上执行`start-yarn.sh`命令启动YARN，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动\n\n## 测试集群工作状态的一些指令 \n\n* `hdfs dfsadmin -report` 查看hdfs的各节点状态信息\n\n* `hdfs haadmin -getServiceState nn1` 获取一个namenode节点的HA状态\n* `hdfs haadmin -transitionToActive nn1`将nn1切换为Active\n* `hdfs haadmin -transitionToStandby nn1`将nn1切换为Standby\n* `hdfs haadmin -failover nn1 nn2`主备切换\n* `yarn rmadmin -getServiceState rm1`获取一个resourcemanager节点的HA状态\n* `hdfs --daemon start namenode` 单独启动一个namenode进程\n* `hdfs --daemon start zkfc` 单独启动一个zkfc进程\n\n## 测试集群高可用\n\n执行`hadoop fs -put /etc/profile /profile`上传一个文件到hdfs\n\n执行`hadoop fs -ls /`可查看hdfs下的文件 ：\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507183228.png)\n\n执行`hdfs haadmin -getServiceState nn1`和``hdfs haadmin -getServiceState nn2`命令查master和slave1上NameNode的状态\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191108.png)\n\n在master上执行`jps`命令查看NameNode进程ID，再执行`kill -p <pid of NameNode>`关掉Active状态的NameNode，再执行`jps`会发现没有NameNode了,最后执行`hdfs haadmin -getServiceState nn2`会发现slave1的NameNode已经是active状态了\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191904.png)\n\n执行`hadoop fs -ls /`会发现仍然能访问到hdfs的文件\n\n在master上执行`hdfs --daemon start namenode`重新启动NameNode，再执行`hdfs haadmin -getServiceState nn1`会发现master上NameNode的状态变为了standby\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507192833.png)\n\n执行`hdfs haadmin -failover nn2 nn1`会主备切换，nn1变为active，nn2变为standby.\n\n## 群起脚本\n\n```bash\n#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo \"No Args Input Error!!!!!\"\n   exit\nfi\ncase $1 in \n\"start\")\n   \techo \"======================== start zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh start\"\n\tdone\n\techo \"======================== start hdfs ========================== \"\n  \tssh master \"source /etc/profile;start-dfs.sh\"\n   \techo \"======================== start yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;start-yarn.sh\"\n;;\n\"stop\")\n\techo \"======================== stop yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;stop-yarn.sh\"\n   \techo \"======================== stop hdfs ========================== \"\n  \tssh master \"source /etc/profile;stop-dfs.sh\"\n  \techo \"======================== stop zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh stop\"\n\tdone\n;;\n*)\n  \techo \"Input Args Error!!!!!\"\n;;\nesac\n```\n\n","source":"_posts/Hadoop-HA-搭建.md","raw":"---\ntitle: Hadoop HA 搭建\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-05-06 20:30:35\npassword:\nsummary: \ncategories: 大数据\nimg:\nkeywords: 高可用 HA hadoop 大数据\ntags:\n\t- 高可用\n\t- HA\n\t- hadoop\n\t- 大数据\n---\n\n所谓HA（High Available）是Hadoop2.0中引入来解决Hadoop1.0中单点故障问题的一种机制。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。\n\n## HDFS-HA集群配置\n\n### 规划集群\n\n| master            | slave1                  | slave2                   |\n| ----------------- | ----------------------- | ------------------------ |\n| NameNode (active) | NameNode (standby)      |                          |\n| JournalNode       | JournalNode             | JournalNode              |\n| DataNode          | DataNode                | DataNode                 |\n| ZK                | ZK                      | ZK                       |\n|                   | ResourceManager(active) | ResourceManager(standby) |\n| NodeManager       | NodeManager             | NodeManager              |\n\n### 配置Zookeeper集群\n\n在master、slave1和slave2三个节点上部署Zookeeper\n\n### 安装zookeeper\n\n解压zookeeper，并重命名为zookeeper\n\n```\ntar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/\ncd /usr/local\nmv apache-zookeeper-3.5.7-bin/ zookeeper\n```\n\n### 配置zookeeper\n\n* 在`/usr/local/zookeeper/`这个目录下创建zkData\n\n```\ncd /usr/local/zookeeper\nmkdir zkData\n```\n\n* 重命名`/usr/local/zookeeper/conf`这个目录下的zoo_sample.cfg为zoo.cfg\n\n```\ncd /usr/local/zookeeper/conf\nmv zoo_sample.cfg zoo.cfg\n```\n\n* 执行`sudo gedit zoo.cfg`打开配置文件，配置如下：\n\n```\n# 修改原有dataDir值如下\ndataDir=/usr/local/zookeeper/zkData\n#######################cluster##########################\nserver.1=master:2888:3888\nserver.2=slave1:2888:3888\nserver.3=slave2:2888:3888\n```\n\nServer.A=B:C:D。\n\nA是一个数字，表示这个是第几号服务器；\n\nB是这个服务器的IP地址；\n\nC是这个服务器与集群中的Leader服务器交换信息的端口；\n\nD是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。\n\n集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。\n\n* 在/usr/local/zookeeper/zkData目录下创建并打开文件myid\n\n```\ngedit myid\n```\n\n在myid文件中增加数据：1\n\n* 拷贝配置好的zookeeper到其他机器上,并分别修改myid文件中内容为2、3\n\n```\nscp -r /usr/local/zookeeper/ slave1:/usr/local/\nscp -r /usr/local/zookeeper/ slave2:/usr/local/\n```\n\n* 配置zookeeper环境变量\n\n执行`sudo gedit /etc/profile`打开配置文件，加入下列内容\n\n```\nexport ZOOKEEPER_HOME=/usr/local/zookeeper\nexport PATH=$ZOOKEEPER_HOME/bin:$PATH\n```\n\n执行`source /etc/profile`命令让配置文件生效\n\n* 拷贝`/etc/profile`文件到其他机器\n\n```\nscp /etc/profile slave1:/etc\n```\n\n\n\n### 启动zookeeper\n\n分别启动zookeeper,在三台机器上执行`zkServer.sh start`命令启动zookeeper,再执行`jps`命令可以看到有`QuorumPeerMain`\n\n## 配置HDFS-HA集群\n\n* 配置core-site.xml：\n\n```\n<configuration>\n\t<!-- 把两个NameNode的地址组装成一个集群mycluster -->\n\t<property>\n\t\t<name>fs.defaultFS</name>\n        <value>hdfs://mycluster</value>\n\t</property>\n\n\t<!-- 指定hadoop运行时产生文件的存储目录 -->\n\t<property>\n\t\t<name>hadoop.tmp.dir</name>\n\t\t<value>/usr/local/hadoop/tmp</value>\n\t</property>\n\t<!-- 在网页界面访问数据使用的用户名。默认值是一个不真实存在的用户，此用户权限很小 -->\n\t<property>\n        <name>hadoop.http.staticuser.user</name>\n        <value>ubuntu</value>\n\t</property> \n\t<!--Ha功能，需要一组zk地址，用逗号分隔。被ZKFailoverController使用于自动失效备援failover-->\n\t<property>\n   \t\t<name>ha.zookeeper.quorum</name>\n  \t    <value>master:2181,slave1:2181,slave2:2181</value>\n \t</property>\n</configuration>\n```\n\n* 配置hdfs-site.xml\n\n```\n<configuration>\n\t<!-- 冗余度 -->\n\t<property>\n  \t\t<name>dfs.replication</name>\n  \t\t<value>3</value>\n\t</property>\n\t<!-- 暂不配置 \n\t<property>\n  \t\t<name>dfs.namenode.secondary.http-address</name>\n  \t\t<value>slave1:9869</value>\n\t</property>\n\t-->\n\t<!-- 完全分布式集群名称 -->\n\t<property>\n\t\t<name>dfs.nameservices</name>\n\t\t<value>mycluster</value>\n\t</property>\n\n\t<!-- 集群中NameNode节点都有哪些 -->\n\t<property>\n\t\t<name>dfs.ha.namenodes.mycluster</name>\n\t\t<value>nn1,nn2</value>\n\t</property>\n\n\t<!-- nn1的RPC通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.rpc-address.mycluster.nn1</name>\n\t\t<value>master:8020</value>\n\t</property>\n\n\t<!-- nn2的RPC通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.rpc-address.mycluster.nn2</name>\n\t\t<value>slave1:8020</value>\n\t</property>\n\n\t<!-- nn1的http通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.http-address.mycluster.nn1</name>\n\t\t<value>master:9870</value>\n\t</property>\n\n\t<!-- nn2的http通信地址 -->\n\t<property>\n\t\t<name>dfs.namenode.http-address.mycluster.nn2</name>\n\t\t<value>slave1:9870</value>\n\t</property>\n\n\t<!-- 指定NameNode元数据在JournalNode上的存放位置 -->\n\t<property>\n\t\t<name>dfs.namenode.shared.edits.dir</name>\n\t<value>qjournal://master:8485;slave1:8485;slave2:8485/mycluster</value>\n\t</property>\n\n\t<!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 -->\n\t<property>\n\t\t<name>dfs.ha.fencing.methods</name>\n\t\t<value>sshfence</value>\n\t</property>\n\n\t<!-- 使用隔离机制时需要ssh无秘钥登录-->\n\t<property>\n\t\t<name>dfs.ha.fencing.ssh.private-key-files</name>\n\t\t<value>/home/ubuntu/.ssh/id_rsa</value>\n\t</property>\n\n\t<!-- 声明journalnode服务器存储目录-->\n\t<property>\n\t\t<name>dfs.journalnode.edits.dir</name>\n\t\t<value>/usr/local/hadoop/tmp/jn</value>\n\t</property>\n\n\t<!-- 关闭权限检查-->\n\t<property>\n\t\t<name>dfs.permissions.enable</name>\n\t\t<value>false</value>\n\t</property>\n\t\n\t<!-- 是否开启自动故障转移-->\n\t<property>\n   \t\t<name>dfs.ha.automatic-failover.enabled</name>\n   \t\t<value>true</value>\n\t</property>\n\t\n\t<!--访问代理类：client，mycluster，active配置失败自动切换实现方式-->\n\t<property>\n  \t\t<name>dfs.client.failover.proxy.provider.mycluster</name>\n\t<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n\t</property>\n</configuration>\n```\n\n* 配置mapred-site.xml\n\n```\n<configuration>\n   <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n   </property>\n</configuration>\n```\n\n配置yarn-site.xml\n\n```\n<configuration>\n    <property>\n        <name>yarn.nodemanager.aux-services</name>\n        <value>mapreduce_shuffle</value>\n    </property>\n\n    <!--启用resourcemanager ha-->\n    <property>\n        <name>yarn.resourcemanager.ha.enabled</name>\n        <value>true</value>\n    </property>\n \n    <!--声明两台resourcemanager的地址-->\n    <property>\n        <name>yarn.resourcemanager.cluster-id</name>\n        <value>cluster-yarn1</value>\n    </property>\n\n    <property>\n        <name>yarn.resourcemanager.ha.rm-ids</name>\n        <value>rm1,rm2</value>\n    </property>\n\n    <property>\n        <name>yarn.resourcemanager.hostname.rm1</name>\n        <value>slave1</value>\n    </property>\n\n    <property>\n        <name>yarn.resourcemanager.hostname.rm2</name>\n        <value>slave2</value>\n    </property>\n \n    <!--指定zookeeper集群的地址--> \n    <property>\n        <name>yarn.resourcemanager.zk-address</name>\n        <value>master:2181,slave1:2181,slave2:2181</value>\n    </property>\n\n    <!--启用自动恢复--> \n    <property>\n        <name>yarn.resourcemanager.recovery.enabled</name>\n        <value>true</value>\n    </property>\n \n    <!--指定resourcemanager的状态信息存储在zookeeper集群--> \n    <property>\n\t<name>yarn.resourcemanager.store.class</name>\n<value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>\n    </property>\n\n</configuration>\n```\n\n* 拷贝配置好的Hadoop文件到其他机器上\n\n```\nscp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/\n```\n\n## 启动\n\n### 启动zookeeper集群\n\n分别在master，slave1，slave2上执行`zkServer.sh start`命名启动zk\n\n### 启动journalnode\n\n分别在master，slave1，slave2上执行`hdfs --daemon start journalnode`命令启动JN\n\n运行jps命令检验，master，slave1，slave2上多了JournalNode进程\n\n### 格式化namenode，并启动\n\n在master上执行命令`hdfs namenode -format`格式化namenode\n\n在master上执行命令`hdfs --daemon start namenode`命令格式化namenode\n\n### 副节点同步主节点格式化\n\n在slave1上执行命令`hdfs namenode -bootstrapStandby`命令同步主节点格式化\n\n### 格式化ZKFC\n\n在master上执行命令`hdfs zkfc -formatZK`格式化ZKFC，第一次启动时需要格式化\n\n### 启动HDFS\n\n在master上执行命令`start-dfs.sh`启动HDFS\n\n### 启动YARN\n\n在slave1上执行`start-yarn.sh`命令启动YARN，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动\n\n## 测试集群工作状态的一些指令 \n\n* `hdfs dfsadmin -report` 查看hdfs的各节点状态信息\n\n* `hdfs haadmin -getServiceState nn1` 获取一个namenode节点的HA状态\n* `hdfs haadmin -transitionToActive nn1`将nn1切换为Active\n* `hdfs haadmin -transitionToStandby nn1`将nn1切换为Standby\n* `hdfs haadmin -failover nn1 nn2`主备切换\n* `yarn rmadmin -getServiceState rm1`获取一个resourcemanager节点的HA状态\n* `hdfs --daemon start namenode` 单独启动一个namenode进程\n* `hdfs --daemon start zkfc` 单独启动一个zkfc进程\n\n## 测试集群高可用\n\n执行`hadoop fs -put /etc/profile /profile`上传一个文件到hdfs\n\n执行`hadoop fs -ls /`可查看hdfs下的文件 ：\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507183228.png)\n\n执行`hdfs haadmin -getServiceState nn1`和``hdfs haadmin -getServiceState nn2`命令查master和slave1上NameNode的状态\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191108.png)\n\n在master上执行`jps`命令查看NameNode进程ID，再执行`kill -p <pid of NameNode>`关掉Active状态的NameNode，再执行`jps`会发现没有NameNode了,最后执行`hdfs haadmin -getServiceState nn2`会发现slave1的NameNode已经是active状态了\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191904.png)\n\n执行`hadoop fs -ls /`会发现仍然能访问到hdfs的文件\n\n在master上执行`hdfs --daemon start namenode`重新启动NameNode，再执行`hdfs haadmin -getServiceState nn1`会发现master上NameNode的状态变为了standby\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507192833.png)\n\n执行`hdfs haadmin -failover nn2 nn1`会主备切换，nn1变为active，nn2变为standby.\n\n## 群起脚本\n\n```bash\n#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo \"No Args Input Error!!!!!\"\n   exit\nfi\ncase $1 in \n\"start\")\n   \techo \"======================== start zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh start\"\n\tdone\n\techo \"======================== start hdfs ========================== \"\n  \tssh master \"source /etc/profile;start-dfs.sh\"\n   \techo \"======================== start yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;start-yarn.sh\"\n;;\n\"stop\")\n\techo \"======================== stop yarn ========================== \"\n   \tssh slave1 \"source /etc/profile;stop-yarn.sh\"\n   \techo \"======================== stop hdfs ========================== \"\n  \tssh master \"source /etc/profile;stop-dfs.sh\"\n  \techo \"======================== stop zookeeper ========================== \"\n\tfor i in master slave1 slave2\n\tdo\n   \t\techo \"========== $i zookeeper ==========\"\n   \t\tssh $i \"source /etc/profile;zkServer.sh stop\"\n\tdone\n;;\n*)\n  \techo \"Input Args Error!!!!!\"\n;;\nesac\n```\n\n","slug":"Hadoop-HA-搭建","published":1,"updated":"2020-05-17T13:25:54.597Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqxl0008gswjav6k0giu","content":"<p>所谓HA（High Available）是Hadoop2.0中引入来解决Hadoop1.0中单点故障问题的一种机制。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。</p>\n<h2 id=\"HDFS-HA集群配置\"><a href=\"#HDFS-HA集群配置\" class=\"headerlink\" title=\"HDFS-HA集群配置\"></a>HDFS-HA集群配置</h2><h3 id=\"规划集群\"><a href=\"#规划集群\" class=\"headerlink\" title=\"规划集群\"></a>规划集群</h3><table>\n<thead>\n<tr>\n<th>master</th>\n<th>slave1</th>\n<th>slave2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>NameNode (active)</td>\n<td>NameNode (standby)</td>\n<td></td>\n</tr>\n<tr>\n<td>JournalNode</td>\n<td>JournalNode</td>\n<td>JournalNode</td>\n</tr>\n<tr>\n<td>DataNode</td>\n<td>DataNode</td>\n<td>DataNode</td>\n</tr>\n<tr>\n<td>ZK</td>\n<td>ZK</td>\n<td>ZK</td>\n</tr>\n<tr>\n<td></td>\n<td>ResourceManager(active)</td>\n<td>ResourceManager(standby)</td>\n</tr>\n<tr>\n<td>NodeManager</td>\n<td>NodeManager</td>\n<td>NodeManager</td>\n</tr>\n</tbody></table>\n<h3 id=\"配置Zookeeper集群\"><a href=\"#配置Zookeeper集群\" class=\"headerlink\" title=\"配置Zookeeper集群\"></a>配置Zookeeper集群</h3><p>在master、slave1和slave2三个节点上部署Zookeeper</p>\n<h3 id=\"安装zookeeper\"><a href=\"#安装zookeeper\" class=\"headerlink\" title=\"安装zookeeper\"></a>安装zookeeper</h3><p>解压zookeeper，并重命名为zookeeper</p>\n<pre><code>tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/\ncd /usr/local\nmv apache-zookeeper-3.5.7-bin/ zookeeper</code></pre><h3 id=\"配置zookeeper\"><a href=\"#配置zookeeper\" class=\"headerlink\" title=\"配置zookeeper\"></a>配置zookeeper</h3><ul>\n<li>在<code>/usr/local/zookeeper/</code>这个目录下创建zkData</li>\n</ul>\n<pre><code>cd /usr/local/zookeeper\nmkdir zkData</code></pre><ul>\n<li>重命名<code>/usr/local/zookeeper/conf</code>这个目录下的zoo_sample.cfg为zoo.cfg</li>\n</ul>\n<pre><code>cd /usr/local/zookeeper/conf\nmv zoo_sample.cfg zoo.cfg</code></pre><ul>\n<li>执行<code>sudo gedit zoo.cfg</code>打开配置文件，配置如下：</li>\n</ul>\n<pre><code># 修改原有dataDir值如下\ndataDir=/usr/local/zookeeper/zkData\n#######################cluster##########################\nserver.1=master:2888:3888\nserver.2=slave1:2888:3888\nserver.3=slave2:2888:3888</code></pre><p>Server.A=B:C:D。</p>\n<p>A是一个数字，表示这个是第几号服务器；</p>\n<p>B是这个服务器的IP地址；</p>\n<p>C是这个服务器与集群中的Leader服务器交换信息的端口；</p>\n<p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>\n<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>\n<ul>\n<li>在/usr/local/zookeeper/zkData目录下创建并打开文件myid</li>\n</ul>\n<pre><code>gedit myid</code></pre><p>在myid文件中增加数据：1</p>\n<ul>\n<li>拷贝配置好的zookeeper到其他机器上,并分别修改myid文件中内容为2、3</li>\n</ul>\n<pre><code>scp -r /usr/local/zookeeper/ slave1:/usr/local/\nscp -r /usr/local/zookeeper/ slave2:/usr/local/</code></pre><ul>\n<li>配置zookeeper环境变量</li>\n</ul>\n<p>执行<code>sudo gedit /etc/profile</code>打开配置文件，加入下列内容</p>\n<pre><code>export ZOOKEEPER_HOME=/usr/local/zookeeper\nexport PATH=$ZOOKEEPER_HOME/bin:$PATH</code></pre><p>执行<code>source /etc/profile</code>命令让配置文件生效</p>\n<ul>\n<li>拷贝<code>/etc/profile</code>文件到其他机器</li>\n</ul>\n<pre><code>scp /etc/profile slave1:/etc</code></pre><h3 id=\"启动zookeeper\"><a href=\"#启动zookeeper\" class=\"headerlink\" title=\"启动zookeeper\"></a>启动zookeeper</h3><p>分别启动zookeeper,在三台机器上执行<code>zkServer.sh start</code>命令启动zookeeper,再执行<code>jps</code>命令可以看到有<code>QuorumPeerMain</code></p>\n<h2 id=\"配置HDFS-HA集群\"><a href=\"#配置HDFS-HA集群\" class=\"headerlink\" title=\"配置HDFS-HA集群\"></a>配置HDFS-HA集群</h2><ul>\n<li>配置core-site.xml：</li>\n</ul>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 把两个NameNode的地址组装成一个集群mycluster --&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;/name&gt;\n        &lt;value&gt;hdfs://mycluster&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 在网页界面访问数据使用的用户名。默认值是一个不真实存在的用户，此用户权限很小 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;\n        &lt;value&gt;ubuntu&lt;/value&gt;\n    &lt;/property&gt; \n    &lt;!--Ha功能，需要一组zk地址，用逗号分隔。被ZKFailoverController使用于自动失效备援failover--&gt;\n    &lt;property&gt;\n           &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;\n          &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>配置hdfs-site.xml</li>\n</ul>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 冗余度 --&gt;\n    &lt;property&gt;\n          &lt;name&gt;dfs.replication&lt;/name&gt;\n          &lt;value&gt;3&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 暂不配置 \n    &lt;property&gt;\n          &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n          &lt;value&gt;slave1:9869&lt;/value&gt;\n    &lt;/property&gt;\n    --&gt;\n    &lt;!-- 完全分布式集群名称 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.nameservices&lt;/name&gt;\n        &lt;value&gt;mycluster&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 集群中NameNode节点都有哪些 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;\n        &lt;value&gt;nn1,nn2&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn1的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;\n        &lt;value&gt;master:8020&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn2的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;\n        &lt;value&gt;slave1:8020&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn1的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;\n        &lt;value&gt;master:9870&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn2的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;\n        &lt;value&gt;slave1:9870&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;\n    &lt;value&gt;qjournal://master:8485;slave1:8485;slave2:8485/mycluster&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;\n        &lt;value&gt;sshfence&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;\n        &lt;value&gt;/home/ubuntu/.ssh/id_rsa&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 声明journalnode服务器存储目录--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;\n        &lt;value&gt;/usr/local/hadoop/tmp/jn&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 关闭权限检查--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.permissions.enable&lt;/name&gt;\n        &lt;value&gt;false&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 是否开启自动故障转移--&gt;\n    &lt;property&gt;\n           &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;\n           &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;\n    &lt;property&gt;\n          &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>配置mapred-site.xml</li>\n</ul>\n<pre><code>&lt;configuration&gt;\n   &lt;property&gt;\n       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n       &lt;value&gt;yarn&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>配置yarn-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--启用resourcemanager ha--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--声明两台resourcemanager的地址--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;\n        &lt;value&gt;cluster-yarn1&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;\n        &lt;value&gt;rm1,rm2&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;\n        &lt;value&gt;slave1&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;\n        &lt;value&gt;slave2&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--指定zookeeper集群的地址--&gt; \n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;\n        &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--启用自动恢复--&gt; \n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt; \n    &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;\n&lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;\n    &lt;/property&gt;\n\n&lt;/configuration&gt;</code></pre><ul>\n<li>拷贝配置好的Hadoop文件到其他机器上</li>\n</ul>\n<pre><code>scp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/</code></pre><h2 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h2><h3 id=\"启动zookeeper集群\"><a href=\"#启动zookeeper集群\" class=\"headerlink\" title=\"启动zookeeper集群\"></a>启动zookeeper集群</h3><p>分别在master，slave1，slave2上执行<code>zkServer.sh start</code>命名启动zk</p>\n<h3 id=\"启动journalnode\"><a href=\"#启动journalnode\" class=\"headerlink\" title=\"启动journalnode\"></a>启动journalnode</h3><p>分别在master，slave1，slave2上执行<code>hdfs --daemon start journalnode</code>命令启动JN</p>\n<p>运行jps命令检验，master，slave1，slave2上多了JournalNode进程</p>\n<h3 id=\"格式化namenode，并启动\"><a href=\"#格式化namenode，并启动\" class=\"headerlink\" title=\"格式化namenode，并启动\"></a>格式化namenode，并启动</h3><p>在master上执行命令<code>hdfs namenode -format</code>格式化namenode</p>\n<p>在master上执行命令<code>hdfs --daemon start namenode</code>命令格式化namenode</p>\n<h3 id=\"副节点同步主节点格式化\"><a href=\"#副节点同步主节点格式化\" class=\"headerlink\" title=\"副节点同步主节点格式化\"></a>副节点同步主节点格式化</h3><p>在slave1上执行命令<code>hdfs namenode -bootstrapStandby</code>命令同步主节点格式化</p>\n<h3 id=\"格式化ZKFC\"><a href=\"#格式化ZKFC\" class=\"headerlink\" title=\"格式化ZKFC\"></a>格式化ZKFC</h3><p>在master上执行命令<code>hdfs zkfc -formatZK</code>格式化ZKFC，第一次启动时需要格式化</p>\n<h3 id=\"启动HDFS\"><a href=\"#启动HDFS\" class=\"headerlink\" title=\"启动HDFS\"></a>启动HDFS</h3><p>在master上执行命令<code>start-dfs.sh</code>启动HDFS</p>\n<h3 id=\"启动YARN\"><a href=\"#启动YARN\" class=\"headerlink\" title=\"启动YARN\"></a>启动YARN</h3><p>在slave1上执行<code>start-yarn.sh</code>命令启动YARN，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动</p>\n<h2 id=\"测试集群工作状态的一些指令\"><a href=\"#测试集群工作状态的一些指令\" class=\"headerlink\" title=\"测试集群工作状态的一些指令\"></a>测试集群工作状态的一些指令</h2><ul>\n<li><p><code>hdfs dfsadmin -report</code> 查看hdfs的各节点状态信息</p>\n</li>\n<li><p><code>hdfs haadmin -getServiceState nn1</code> 获取一个namenode节点的HA状态</p>\n</li>\n<li><p><code>hdfs haadmin -transitionToActive nn1</code>将nn1切换为Active</p>\n</li>\n<li><p><code>hdfs haadmin -transitionToStandby nn1</code>将nn1切换为Standby</p>\n</li>\n<li><p><code>hdfs haadmin -failover nn1 nn2</code>主备切换</p>\n</li>\n<li><p><code>yarn rmadmin -getServiceState rm1</code>获取一个resourcemanager节点的HA状态</p>\n</li>\n<li><p><code>hdfs --daemon start namenode</code> 单独启动一个namenode进程</p>\n</li>\n<li><p><code>hdfs --daemon start zkfc</code> 单独启动一个zkfc进程</p>\n</li>\n</ul>\n<h2 id=\"测试集群高可用\"><a href=\"#测试集群高可用\" class=\"headerlink\" title=\"测试集群高可用\"></a>测试集群高可用</h2><p>执行<code>hadoop fs -put /etc/profile /profile</code>上传一个文件到hdfs</p>\n<p>执行<code>hadoop fs -ls /</code>可查看hdfs下的文件 ：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507183228.png\" alt=\"\"></p>\n<p>执行<code>hdfs haadmin -getServiceState nn1</code>和``hdfs haadmin -getServiceState nn2`命令查master和slave1上NameNode的状态</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191108.png\" alt=\"\"></p>\n<p>在master上执行<code>jps</code>命令查看NameNode进程ID，再执行<code>kill -p &lt;pid of NameNode&gt;</code>关掉Active状态的NameNode，再执行<code>jps</code>会发现没有NameNode了,最后执行<code>hdfs haadmin -getServiceState nn2</code>会发现slave1的NameNode已经是active状态了</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191904.png\" alt=\"\"></p>\n<p>执行<code>hadoop fs -ls /</code>会发现仍然能访问到hdfs的文件</p>\n<p>在master上执行<code>hdfs --daemon start namenode</code>重新启动NameNode，再执行<code>hdfs haadmin -getServiceState nn1</code>会发现master上NameNode的状态变为了standby</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507192833.png\" alt=\"\"></p>\n<p>执行<code>hdfs haadmin -failover nn2 nn1</code>会主备切换，nn1变为active，nn2变为standby.</p>\n<h2 id=\"群起脚本\"><a href=\"#群起脚本\" class=\"headerlink\" title=\"群起脚本\"></a>群起脚本</h2><pre><code class=\"bash\">#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo &quot;No Args Input Error!!!!!&quot;\n   exit\nfi\ncase $1 in \n&quot;start&quot;)\n       echo &quot;======================== start zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh start&quot;\n    done\n    echo &quot;======================== start hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;start-dfs.sh&quot;\n       echo &quot;======================== start yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;start-yarn.sh&quot;\n;;\n&quot;stop&quot;)\n    echo &quot;======================== stop yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;stop-yarn.sh&quot;\n       echo &quot;======================== stop hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;stop-dfs.sh&quot;\n      echo &quot;======================== stop zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh stop&quot;\n    done\n;;\n*)\n      echo &quot;Input Args Error!!!!!&quot;\n;;\nesac</code></pre>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>所谓HA（High Available）是Hadoop2.0中引入来解决Hadoop1.0中单点故障问题的一种机制。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。</p>\n<h2 id=\"HDFS-HA集群配置\"><a href=\"#HDFS-HA集群配置\" class=\"headerlink\" title=\"HDFS-HA集群配置\"></a>HDFS-HA集群配置</h2><h3 id=\"规划集群\"><a href=\"#规划集群\" class=\"headerlink\" title=\"规划集群\"></a>规划集群</h3><table>\n<thead>\n<tr>\n<th>master</th>\n<th>slave1</th>\n<th>slave2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>NameNode (active)</td>\n<td>NameNode (standby)</td>\n<td></td>\n</tr>\n<tr>\n<td>JournalNode</td>\n<td>JournalNode</td>\n<td>JournalNode</td>\n</tr>\n<tr>\n<td>DataNode</td>\n<td>DataNode</td>\n<td>DataNode</td>\n</tr>\n<tr>\n<td>ZK</td>\n<td>ZK</td>\n<td>ZK</td>\n</tr>\n<tr>\n<td></td>\n<td>ResourceManager(active)</td>\n<td>ResourceManager(standby)</td>\n</tr>\n<tr>\n<td>NodeManager</td>\n<td>NodeManager</td>\n<td>NodeManager</td>\n</tr>\n</tbody></table>\n<h3 id=\"配置Zookeeper集群\"><a href=\"#配置Zookeeper集群\" class=\"headerlink\" title=\"配置Zookeeper集群\"></a>配置Zookeeper集群</h3><p>在master、slave1和slave2三个节点上部署Zookeeper</p>\n<h3 id=\"安装zookeeper\"><a href=\"#安装zookeeper\" class=\"headerlink\" title=\"安装zookeeper\"></a>安装zookeeper</h3><p>解压zookeeper，并重命名为zookeeper</p>\n<pre><code>tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/\ncd /usr/local\nmv apache-zookeeper-3.5.7-bin/ zookeeper</code></pre><h3 id=\"配置zookeeper\"><a href=\"#配置zookeeper\" class=\"headerlink\" title=\"配置zookeeper\"></a>配置zookeeper</h3><ul>\n<li>在<code>/usr/local/zookeeper/</code>这个目录下创建zkData</li>\n</ul>\n<pre><code>cd /usr/local/zookeeper\nmkdir zkData</code></pre><ul>\n<li>重命名<code>/usr/local/zookeeper/conf</code>这个目录下的zoo_sample.cfg为zoo.cfg</li>\n</ul>\n<pre><code>cd /usr/local/zookeeper/conf\nmv zoo_sample.cfg zoo.cfg</code></pre><ul>\n<li>执行<code>sudo gedit zoo.cfg</code>打开配置文件，配置如下：</li>\n</ul>\n<pre><code># 修改原有dataDir值如下\ndataDir=/usr/local/zookeeper/zkData\n#######################cluster##########################\nserver.1=master:2888:3888\nserver.2=slave1:2888:3888\nserver.3=slave2:2888:3888</code></pre><p>Server.A=B:C:D。</p>\n<p>A是一个数字，表示这个是第几号服务器；</p>\n<p>B是这个服务器的IP地址；</p>\n<p>C是这个服务器与集群中的Leader服务器交换信息的端口；</p>\n<p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>\n<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>\n<ul>\n<li>在/usr/local/zookeeper/zkData目录下创建并打开文件myid</li>\n</ul>\n<pre><code>gedit myid</code></pre><p>在myid文件中增加数据：1</p>\n<ul>\n<li>拷贝配置好的zookeeper到其他机器上,并分别修改myid文件中内容为2、3</li>\n</ul>\n<pre><code>scp -r /usr/local/zookeeper/ slave1:/usr/local/\nscp -r /usr/local/zookeeper/ slave2:/usr/local/</code></pre><ul>\n<li>配置zookeeper环境变量</li>\n</ul>\n<p>执行<code>sudo gedit /etc/profile</code>打开配置文件，加入下列内容</p>\n<pre><code>export ZOOKEEPER_HOME=/usr/local/zookeeper\nexport PATH=$ZOOKEEPER_HOME/bin:$PATH</code></pre><p>执行<code>source /etc/profile</code>命令让配置文件生效</p>\n<ul>\n<li>拷贝<code>/etc/profile</code>文件到其他机器</li>\n</ul>\n<pre><code>scp /etc/profile slave1:/etc</code></pre><h3 id=\"启动zookeeper\"><a href=\"#启动zookeeper\" class=\"headerlink\" title=\"启动zookeeper\"></a>启动zookeeper</h3><p>分别启动zookeeper,在三台机器上执行<code>zkServer.sh start</code>命令启动zookeeper,再执行<code>jps</code>命令可以看到有<code>QuorumPeerMain</code></p>\n<h2 id=\"配置HDFS-HA集群\"><a href=\"#配置HDFS-HA集群\" class=\"headerlink\" title=\"配置HDFS-HA集群\"></a>配置HDFS-HA集群</h2><ul>\n<li>配置core-site.xml：</li>\n</ul>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 把两个NameNode的地址组装成一个集群mycluster --&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;/name&gt;\n        &lt;value&gt;hdfs://mycluster&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 在网页界面访问数据使用的用户名。默认值是一个不真实存在的用户，此用户权限很小 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;\n        &lt;value&gt;ubuntu&lt;/value&gt;\n    &lt;/property&gt; \n    &lt;!--Ha功能，需要一组zk地址，用逗号分隔。被ZKFailoverController使用于自动失效备援failover--&gt;\n    &lt;property&gt;\n           &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;\n          &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt;\n     &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>配置hdfs-site.xml</li>\n</ul>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 冗余度 --&gt;\n    &lt;property&gt;\n          &lt;name&gt;dfs.replication&lt;/name&gt;\n          &lt;value&gt;3&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 暂不配置 \n    &lt;property&gt;\n          &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n          &lt;value&gt;slave1:9869&lt;/value&gt;\n    &lt;/property&gt;\n    --&gt;\n    &lt;!-- 完全分布式集群名称 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.nameservices&lt;/name&gt;\n        &lt;value&gt;mycluster&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 集群中NameNode节点都有哪些 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;\n        &lt;value&gt;nn1,nn2&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn1的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;\n        &lt;value&gt;master:8020&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn2的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;\n        &lt;value&gt;slave1:8020&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn1的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;\n        &lt;value&gt;master:9870&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- nn2的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;\n        &lt;value&gt;slave1:9870&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;\n    &lt;value&gt;qjournal://master:8485;slave1:8485;slave2:8485/mycluster&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;\n        &lt;value&gt;sshfence&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;\n        &lt;value&gt;/home/ubuntu/.ssh/id_rsa&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 声明journalnode服务器存储目录--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;\n        &lt;value&gt;/usr/local/hadoop/tmp/jn&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 关闭权限检查--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.permissions.enable&lt;/name&gt;\n        &lt;value&gt;false&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 是否开启自动故障转移--&gt;\n    &lt;property&gt;\n           &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;\n           &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;\n    &lt;property&gt;\n          &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>配置mapred-site.xml</li>\n</ul>\n<pre><code>&lt;configuration&gt;\n   &lt;property&gt;\n       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n       &lt;value&gt;yarn&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>配置yarn-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--启用resourcemanager ha--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--声明两台resourcemanager的地址--&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;\n        &lt;value&gt;cluster-yarn1&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;\n        &lt;value&gt;rm1,rm2&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;\n        &lt;value&gt;slave1&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;\n        &lt;value&gt;slave2&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--指定zookeeper集群的地址--&gt; \n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;\n        &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--启用自动恢复--&gt; \n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt; \n    &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;\n&lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;\n    &lt;/property&gt;\n\n&lt;/configuration&gt;</code></pre><ul>\n<li>拷贝配置好的Hadoop文件到其他机器上</li>\n</ul>\n<pre><code>scp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/</code></pre><h2 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h2><h3 id=\"启动zookeeper集群\"><a href=\"#启动zookeeper集群\" class=\"headerlink\" title=\"启动zookeeper集群\"></a>启动zookeeper集群</h3><p>分别在master，slave1，slave2上执行<code>zkServer.sh start</code>命名启动zk</p>\n<h3 id=\"启动journalnode\"><a href=\"#启动journalnode\" class=\"headerlink\" title=\"启动journalnode\"></a>启动journalnode</h3><p>分别在master，slave1，slave2上执行<code>hdfs --daemon start journalnode</code>命令启动JN</p>\n<p>运行jps命令检验，master，slave1，slave2上多了JournalNode进程</p>\n<h3 id=\"格式化namenode，并启动\"><a href=\"#格式化namenode，并启动\" class=\"headerlink\" title=\"格式化namenode，并启动\"></a>格式化namenode，并启动</h3><p>在master上执行命令<code>hdfs namenode -format</code>格式化namenode</p>\n<p>在master上执行命令<code>hdfs --daemon start namenode</code>命令格式化namenode</p>\n<h3 id=\"副节点同步主节点格式化\"><a href=\"#副节点同步主节点格式化\" class=\"headerlink\" title=\"副节点同步主节点格式化\"></a>副节点同步主节点格式化</h3><p>在slave1上执行命令<code>hdfs namenode -bootstrapStandby</code>命令同步主节点格式化</p>\n<h3 id=\"格式化ZKFC\"><a href=\"#格式化ZKFC\" class=\"headerlink\" title=\"格式化ZKFC\"></a>格式化ZKFC</h3><p>在master上执行命令<code>hdfs zkfc -formatZK</code>格式化ZKFC，第一次启动时需要格式化</p>\n<h3 id=\"启动HDFS\"><a href=\"#启动HDFS\" class=\"headerlink\" title=\"启动HDFS\"></a>启动HDFS</h3><p>在master上执行命令<code>start-dfs.sh</code>启动HDFS</p>\n<h3 id=\"启动YARN\"><a href=\"#启动YARN\" class=\"headerlink\" title=\"启动YARN\"></a>启动YARN</h3><p>在slave1上执行<code>start-yarn.sh</code>命令启动YARN，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动</p>\n<h2 id=\"测试集群工作状态的一些指令\"><a href=\"#测试集群工作状态的一些指令\" class=\"headerlink\" title=\"测试集群工作状态的一些指令\"></a>测试集群工作状态的一些指令</h2><ul>\n<li><p><code>hdfs dfsadmin -report</code> 查看hdfs的各节点状态信息</p>\n</li>\n<li><p><code>hdfs haadmin -getServiceState nn1</code> 获取一个namenode节点的HA状态</p>\n</li>\n<li><p><code>hdfs haadmin -transitionToActive nn1</code>将nn1切换为Active</p>\n</li>\n<li><p><code>hdfs haadmin -transitionToStandby nn1</code>将nn1切换为Standby</p>\n</li>\n<li><p><code>hdfs haadmin -failover nn1 nn2</code>主备切换</p>\n</li>\n<li><p><code>yarn rmadmin -getServiceState rm1</code>获取一个resourcemanager节点的HA状态</p>\n</li>\n<li><p><code>hdfs --daemon start namenode</code> 单独启动一个namenode进程</p>\n</li>\n<li><p><code>hdfs --daemon start zkfc</code> 单独启动一个zkfc进程</p>\n</li>\n</ul>\n<h2 id=\"测试集群高可用\"><a href=\"#测试集群高可用\" class=\"headerlink\" title=\"测试集群高可用\"></a>测试集群高可用</h2><p>执行<code>hadoop fs -put /etc/profile /profile</code>上传一个文件到hdfs</p>\n<p>执行<code>hadoop fs -ls /</code>可查看hdfs下的文件 ：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507183228.png\" alt=\"\"></p>\n<p>执行<code>hdfs haadmin -getServiceState nn1</code>和``hdfs haadmin -getServiceState nn2`命令查master和slave1上NameNode的状态</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191108.png\" alt=\"\"></p>\n<p>在master上执行<code>jps</code>命令查看NameNode进程ID，再执行<code>kill -p &lt;pid of NameNode&gt;</code>关掉Active状态的NameNode，再执行<code>jps</code>会发现没有NameNode了,最后执行<code>hdfs haadmin -getServiceState nn2</code>会发现slave1的NameNode已经是active状态了</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507191904.png\" alt=\"\"></p>\n<p>执行<code>hadoop fs -ls /</code>会发现仍然能访问到hdfs的文件</p>\n<p>在master上执行<code>hdfs --daemon start namenode</code>重新启动NameNode，再执行<code>hdfs haadmin -getServiceState nn1</code>会发现master上NameNode的状态变为了standby</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200507192833.png\" alt=\"\"></p>\n<p>执行<code>hdfs haadmin -failover nn2 nn1</code>会主备切换，nn1变为active，nn2变为standby.</p>\n<h2 id=\"群起脚本\"><a href=\"#群起脚本\" class=\"headerlink\" title=\"群起脚本\"></a>群起脚本</h2><pre><code class=\"bash\">#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo &quot;No Args Input Error!!!!!&quot;\n   exit\nfi\ncase $1 in \n&quot;start&quot;)\n       echo &quot;======================== start zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh start&quot;\n    done\n    echo &quot;======================== start hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;start-dfs.sh&quot;\n       echo &quot;======================== start yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;start-yarn.sh&quot;\n;;\n&quot;stop&quot;)\n    echo &quot;======================== stop yarn ========================== &quot;\n       ssh slave1 &quot;source /etc/profile;stop-yarn.sh&quot;\n       echo &quot;======================== stop hdfs ========================== &quot;\n      ssh master &quot;source /etc/profile;stop-dfs.sh&quot;\n      echo &quot;======================== stop zookeeper ========================== &quot;\n    for i in master slave1 slave2\n    do\n           echo &quot;========== $i zookeeper ==========&quot;\n           ssh $i &quot;source /etc/profile;zkServer.sh stop&quot;\n    done\n;;\n*)\n      echo &quot;Input Args Error!!!!!&quot;\n;;\nesac</code></pre>\n"},{"title":"ubuntu1604 设置静态IP","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-04-30T07:29:44.000Z","password":null,"summary":null,"img":null,"keywords":"IP 静态IP Ubuntu","_content":"\n1. 首先确保是NAT连接模式\n\n2. 在VMware Workstation的“编辑”选项找到虚拟网络编辑器，在虚拟网络编辑器面板中找到NAT设置，获取子网掩码和网关。\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430154842.png)\n\n3. 在虚拟机中打开终端，输入命令`ifconfig`查看网卡信息\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430160112.png)\n\n4. 输入命令`sudo gedit /etc/network/interfaces`手动配置网络\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161332.png)\n\n5. 输入命令`reboot`重启虚拟机\n\n6. 重启后输入命令`ifconfig`可看到IP地址变成了我们手动设置的IP\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161920.png)\n\n7. 改好了呢","source":"_posts/ubuntu1604-设置静态IP.md","raw":"---\ntitle: ubuntu1604 设置静态IP\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-04-30 15:29:44\npassword:\nsummary:\ncategories: Linux\nimg:\nkeywords: IP 静态IP Ubuntu\ntags:\n\t- IP\n\t- 静态IP\n\t- Ubuntu\n---\n\n1. 首先确保是NAT连接模式\n\n2. 在VMware Workstation的“编辑”选项找到虚拟网络编辑器，在虚拟网络编辑器面板中找到NAT设置，获取子网掩码和网关。\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430154842.png)\n\n3. 在虚拟机中打开终端，输入命令`ifconfig`查看网卡信息\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430160112.png)\n\n4. 输入命令`sudo gedit /etc/network/interfaces`手动配置网络\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161332.png)\n\n5. 输入命令`reboot`重启虚拟机\n\n6. 重启后输入命令`ifconfig`可看到IP地址变成了我们手动设置的IP\n\n\t![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161920.png)\n\n7. 改好了呢","slug":"ubuntu1604-设置静态IP","published":1,"updated":"2020-05-17T13:34:05.166Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqxu000agswjhwa00yoj","content":"<ol>\n<li><p>首先确保是NAT连接模式</p>\n</li>\n<li><p>在VMware Workstation的“编辑”选项找到虚拟网络编辑器，在虚拟网络编辑器面板中找到NAT设置，获取子网掩码和网关。</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430154842.png\" alt=\"\"></p>\n</li>\n<li><p>在虚拟机中打开终端，输入命令<code>ifconfig</code>查看网卡信息</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430160112.png\" alt=\"\"></p>\n</li>\n<li><p>输入命令<code>sudo gedit /etc/network/interfaces</code>手动配置网络</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161332.png\" alt=\"\"></p>\n</li>\n<li><p>输入命令<code>reboot</code>重启虚拟机</p>\n</li>\n<li><p>重启后输入命令<code>ifconfig</code>可看到IP地址变成了我们手动设置的IP</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161920.png\" alt=\"\"></p>\n</li>\n<li><p>改好了呢</p>\n</li>\n</ol>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<ol>\n<li><p>首先确保是NAT连接模式</p>\n</li>\n<li><p>在VMware Workstation的“编辑”选项找到虚拟网络编辑器，在虚拟网络编辑器面板中找到NAT设置，获取子网掩码和网关。</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430154842.png\" alt=\"\"></p>\n</li>\n<li><p>在虚拟机中打开终端，输入命令<code>ifconfig</code>查看网卡信息</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430160112.png\" alt=\"\"></p>\n</li>\n<li><p>输入命令<code>sudo gedit /etc/network/interfaces</code>手动配置网络</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161332.png\" alt=\"\"></p>\n</li>\n<li><p>输入命令<code>reboot</code>重启虚拟机</p>\n</li>\n<li><p>重启后输入命令<code>ifconfig</code>可看到IP地址变成了我们手动设置的IP</p>\n<p> <img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430161920.png\" alt=\"\"></p>\n</li>\n<li><p>改好了呢</p>\n</li>\n</ol>\n"},{"title":"个人可持续性发展","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-04-21T03:28:54.000Z","password":null,"summary":null,"img":null,"keywords":"可持续性发展","_content":"\n不要很拼 人们常说，身体是革命的本钱，年轻人最大的资本是什么，那就是年轻，年轻便意味着精力旺盛，身体好，可人终究是人，不可能像机器那样连轴转，机器坏了还能再换，人坏了可就再没有机会了。\n\n生活中有两个极端，一个是太拼，不把自己当人，为了工作也好，为了学习也好，总是使出十二分的力气，另一个是散漫，做什么都不积极，总是只出三分力气。\n\n可持续发展便是在两者之间寻找一个平衡点，既能把要做的做好，也能保护好自己。\n\n现如今的可持续发展领域涉及macro level、meso level，macro level 包括地球生态、气候变化等等，meso level 包括国家可持续性发展、社会可持续性发展等等，但在micro level方面涉及太少，包括个人和人际交往等等。\n\n在讨论可持续发展时，我们讨论的是环境，是我们身处的外界环境，到目前为止，可持续发展只针对基础设施，经济体系和社会的转型，而不是针对个人，不涉及个人的情感和心理发展以及身体健康等等。\n\n影响个人可持续性发展的原因主要有两个，一个是外部特征，例如身体健康，另一个是内部特征，包括情感、世界观、思想、价值观、需求以及愿望等等。 内部特征还存在着个体差异，支持个人可持续性的内在需求和品质可能会有所不同。 ","source":"_posts/个人可持续性发展.md","raw":"---\ntitle: 个人可持续性发展\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-04-21 11:28:54\npassword:\nsummary:\ntags: 可持续性发展\ncategories: 杂\nimg:\nkeywords: 可持续性发展\n---\n\n不要很拼 人们常说，身体是革命的本钱，年轻人最大的资本是什么，那就是年轻，年轻便意味着精力旺盛，身体好，可人终究是人，不可能像机器那样连轴转，机器坏了还能再换，人坏了可就再没有机会了。\n\n生活中有两个极端，一个是太拼，不把自己当人，为了工作也好，为了学习也好，总是使出十二分的力气，另一个是散漫，做什么都不积极，总是只出三分力气。\n\n可持续发展便是在两者之间寻找一个平衡点，既能把要做的做好，也能保护好自己。\n\n现如今的可持续发展领域涉及macro level、meso level，macro level 包括地球生态、气候变化等等，meso level 包括国家可持续性发展、社会可持续性发展等等，但在micro level方面涉及太少，包括个人和人际交往等等。\n\n在讨论可持续发展时，我们讨论的是环境，是我们身处的外界环境，到目前为止，可持续发展只针对基础设施，经济体系和社会的转型，而不是针对个人，不涉及个人的情感和心理发展以及身体健康等等。\n\n影响个人可持续性发展的原因主要有两个，一个是外部特征，例如身体健康，另一个是内部特征，包括情感、世界观、思想、价值观、需求以及愿望等等。 内部特征还存在着个体差异，支持个人可持续性的内在需求和品质可能会有所不同。 ","slug":"个人可持续性发展","published":1,"updated":"2020-05-17T13:03:33.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqxy000egswj7sm67lmv","content":"<p>不要很拼 人们常说，身体是革命的本钱，年轻人最大的资本是什么，那就是年轻，年轻便意味着精力旺盛，身体好，可人终究是人，不可能像机器那样连轴转，机器坏了还能再换，人坏了可就再没有机会了。</p>\n<p>生活中有两个极端，一个是太拼，不把自己当人，为了工作也好，为了学习也好，总是使出十二分的力气，另一个是散漫，做什么都不积极，总是只出三分力气。</p>\n<p>可持续发展便是在两者之间寻找一个平衡点，既能把要做的做好，也能保护好自己。</p>\n<p>现如今的可持续发展领域涉及macro level、meso level，macro level 包括地球生态、气候变化等等，meso level 包括国家可持续性发展、社会可持续性发展等等，但在micro level方面涉及太少，包括个人和人际交往等等。</p>\n<p>在讨论可持续发展时，我们讨论的是环境，是我们身处的外界环境，到目前为止，可持续发展只针对基础设施，经济体系和社会的转型，而不是针对个人，不涉及个人的情感和心理发展以及身体健康等等。</p>\n<p>影响个人可持续性发展的原因主要有两个，一个是外部特征，例如身体健康，另一个是内部特征，包括情感、世界观、思想、价值观、需求以及愿望等等。 内部特征还存在着个体差异，支持个人可持续性的内在需求和品质可能会有所不同。 </p>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>不要很拼 人们常说，身体是革命的本钱，年轻人最大的资本是什么，那就是年轻，年轻便意味着精力旺盛，身体好，可人终究是人，不可能像机器那样连轴转，机器坏了还能再换，人坏了可就再没有机会了。</p>\n<p>生活中有两个极端，一个是太拼，不把自己当人，为了工作也好，为了学习也好，总是使出十二分的力气，另一个是散漫，做什么都不积极，总是只出三分力气。</p>\n<p>可持续发展便是在两者之间寻找一个平衡点，既能把要做的做好，也能保护好自己。</p>\n<p>现如今的可持续发展领域涉及macro level、meso level，macro level 包括地球生态、气候变化等等，meso level 包括国家可持续性发展、社会可持续性发展等等，但在micro level方面涉及太少，包括个人和人际交往等等。</p>\n<p>在讨论可持续发展时，我们讨论的是环境，是我们身处的外界环境，到目前为止，可持续发展只针对基础设施，经济体系和社会的转型，而不是针对个人，不涉及个人的情感和心理发展以及身体健康等等。</p>\n<p>影响个人可持续性发展的原因主要有两个，一个是外部特征，例如身体健康，另一个是内部特征，包括情感、世界观、思想、价值观、需求以及愿望等等。 内部特征还存在着个体差异，支持个人可持续性的内在需求和品质可能会有所不同。 </p>\n"},{"title":"【求甚解】怎样评价一个模型的泛化能力","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-05-03T14:34:59.000Z","password":null,"summary":null,"img":null,"keywords":"求甚解","_content":"\n一般来说通过泛化误差来评价一个模型的泛化能力。那什么是泛化误差呢？所谓的泛化误差就是用来衡量一个学习机器推广未知数据的能力，即根据从样本数据中学习到的规则能够应用到新数据的能力。\n\n泛化误差也称作期望误差，与之相对的有一个经验误差，经验误差就是模型在训练数据集上的误差，泛化误差就是模型在所有数据（不仅仅是测试数据）上的误差。泛化误差和经验误差中的误差指的是模型的标签与真实标签之间的误差。\n\n理解了概念，我们来看一下数学形式，以回归问题为例（结论适用于其他模型），我们假设样本的真实分布为$P_r(𝒙,𝑦)$(即包含所有的数据)，数据集$\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$是真实分布中数据集的一个子集，并采用平方损失函数，模型$f_\\mathcal{D}(x)$的期望误差为：\n$$\nErr(f)=\\mathbb{E}_{(x, y) \\sim p_{r}(x, y)}\\left[(y-f_\\mathcal{D}(x))^{2}\\right]\n$$\n\n模型$f_\\mathcal{D}(x)$的经验误差为：\n$$\nErr(f)=\\frac{1}{N} \\sum_{n=1}^{N}\\left[(y_n-f_\\mathcal{D}(x_n))^{2}\\right]\n$$\n其中$\\mathbb{E}$表示求期望，$f_\\mathcal{D}(x)$表示在训练集$\\mathcal{D}$上训练得到的模型，$(x,y)\\sim P_r(x,y)$表示$(x,y)$服从$P_r(x,y)$分布，即所有的数据。$(y-f_\\mathcal{D}(x))^{2}$表示真实标签与模型预测标签的平方损失（忽略了系数1/2）。\n\n假定$f^*(x)$是假设空间中的最优模型，则期望误差可分解为\n$$\n\\begin{aligned}\nErr(f) &=\\mathbb{E}_{(x, y) \\sim p_{r}(x, y)}\\left[\\left(y-f^*(x)+f^*(x)-f(x)\\right)^{2}\\right] \\\\\n&=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(x)}\\left[\\left(f(x)-f^{*}(x)\\right)^{2}\\right]+\\epsilon\n\\end{aligned}\n$$\n\n\n\n\n","source":"_posts/【求甚解】怎样评价一个模型的泛化能力.md","raw":"---\ntitle: 【求甚解】怎样评价一个模型的泛化能力\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-05-03 22:34:59\npassword:\nsummary:\ncategories: 求甚解\nimg:\nkeywords: 求甚解\ntags:\n\t-求甚解\n---\n\n一般来说通过泛化误差来评价一个模型的泛化能力。那什么是泛化误差呢？所谓的泛化误差就是用来衡量一个学习机器推广未知数据的能力，即根据从样本数据中学习到的规则能够应用到新数据的能力。\n\n泛化误差也称作期望误差，与之相对的有一个经验误差，经验误差就是模型在训练数据集上的误差，泛化误差就是模型在所有数据（不仅仅是测试数据）上的误差。泛化误差和经验误差中的误差指的是模型的标签与真实标签之间的误差。\n\n理解了概念，我们来看一下数学形式，以回归问题为例（结论适用于其他模型），我们假设样本的真实分布为$P_r(𝒙,𝑦)$(即包含所有的数据)，数据集$\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$是真实分布中数据集的一个子集，并采用平方损失函数，模型$f_\\mathcal{D}(x)$的期望误差为：\n$$\nErr(f)=\\mathbb{E}_{(x, y) \\sim p_{r}(x, y)}\\left[(y-f_\\mathcal{D}(x))^{2}\\right]\n$$\n\n模型$f_\\mathcal{D}(x)$的经验误差为：\n$$\nErr(f)=\\frac{1}{N} \\sum_{n=1}^{N}\\left[(y_n-f_\\mathcal{D}(x_n))^{2}\\right]\n$$\n其中$\\mathbb{E}$表示求期望，$f_\\mathcal{D}(x)$表示在训练集$\\mathcal{D}$上训练得到的模型，$(x,y)\\sim P_r(x,y)$表示$(x,y)$服从$P_r(x,y)$分布，即所有的数据。$(y-f_\\mathcal{D}(x))^{2}$表示真实标签与模型预测标签的平方损失（忽略了系数1/2）。\n\n假定$f^*(x)$是假设空间中的最优模型，则期望误差可分解为\n$$\n\\begin{aligned}\nErr(f) &=\\mathbb{E}_{(x, y) \\sim p_{r}(x, y)}\\left[\\left(y-f^*(x)+f^*(x)-f(x)\\right)^{2}\\right] \\\\\n&=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(x)}\\left[\\left(f(x)-f^{*}(x)\\right)^{2}\\right]+\\epsilon\n\\end{aligned}\n$$\n\n\n\n\n","slug":"【求甚解】怎样评价一个模型的泛化能力","published":1,"updated":"2020-05-17T13:35:21.710Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqy1000ggswjfctxgld4","content":"<p>一般来说通过泛化误差来评价一个模型的泛化能力。那什么是泛化误差呢？所谓的泛化误差就是用来衡量一个学习机器推广未知数据的能力，即根据从样本数据中学习到的规则能够应用到新数据的能力。</p>\n<p>泛化误差也称作期望误差，与之相对的有一个经验误差，经验误差就是模型在训练数据集上的误差，泛化误差就是模型在所有数据（不仅仅是测试数据）上的误差。泛化误差和经验误差中的误差指的是模型的标签与真实标签之间的误差。</p>\n<p>理解了概念，我们来看一下数学形式，以回归问题为例（结论适用于其他模型），我们假设样本的真实分布为$P_r(𝒙,𝑦)$(即包含所有的数据)，数据集$\\mathcal{D}=\\left{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right}<em>{n=1}^{N}$是真实分布中数据集的一个子集，并采用平方损失函数，模型$f_\\mathcal{D}(x)$的期望误差为：<br>$$<br>Err(f)=\\mathbb{E}</em>{(x, y) \\sim p_{r}(x, y)}\\left[(y-f_\\mathcal{D}(x))^{2}\\right]<br>$$</p>\n<p>模型$f_\\mathcal{D}(x)$的经验误差为：<br>$$<br>Err(f)=\\frac{1}{N} \\sum_{n=1}^{N}\\left[(y_n-f_\\mathcal{D}(x_n))^{2}\\right]<br>$$<br>其中$\\mathbb{E}$表示求期望，$f_\\mathcal{D}(x)$表示在训练集$\\mathcal{D}$上训练得到的模型，$(x,y)\\sim P_r(x,y)$表示$(x,y)$服从$P_r(x,y)$分布，即所有的数据。$(y-f_\\mathcal{D}(x))^{2}$表示真实标签与模型预测标签的平方损失（忽略了系数1/2）。</p>\n<p>假定$f^<em>(x)$是假设空间中的最优模型，则期望误差可分解为<br>$$<br>\\begin{aligned}<br>Err(f) &amp;=\\mathbb{E}<em>{(x, y) \\sim p</em>{r}(x, y)}\\left[\\left(y-f^</em>(x)+f^<em>(x)-f(x)\\right)^{2}\\right] \\<br>&amp;=\\mathbb{E}<em>{\\boldsymbol{x} \\sim p</em>{r}(x)}\\left[\\left(f(x)-f^{</em>}(x)\\right)^{2}\\right]+\\epsilon<br>\\end{aligned}<br>$$</p>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>一般来说通过泛化误差来评价一个模型的泛化能力。那什么是泛化误差呢？所谓的泛化误差就是用来衡量一个学习机器推广未知数据的能力，即根据从样本数据中学习到的规则能够应用到新数据的能力。</p>\n<p>泛化误差也称作期望误差，与之相对的有一个经验误差，经验误差就是模型在训练数据集上的误差，泛化误差就是模型在所有数据（不仅仅是测试数据）上的误差。泛化误差和经验误差中的误差指的是模型的标签与真实标签之间的误差。</p>\n<p>理解了概念，我们来看一下数学形式，以回归问题为例（结论适用于其他模型），我们假设样本的真实分布为$P_r(𝒙,𝑦)$(即包含所有的数据)，数据集$\\mathcal{D}=\\left{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right}<em>{n=1}^{N}$是真实分布中数据集的一个子集，并采用平方损失函数，模型$f_\\mathcal{D}(x)$的期望误差为：<br>$$<br>Err(f)=\\mathbb{E}</em>{(x, y) \\sim p_{r}(x, y)}\\left[(y-f_\\mathcal{D}(x))^{2}\\right]<br>$$</p>\n<p>模型$f_\\mathcal{D}(x)$的经验误差为：<br>$$<br>Err(f)=\\frac{1}{N} \\sum_{n=1}^{N}\\left[(y_n-f_\\mathcal{D}(x_n))^{2}\\right]<br>$$<br>其中$\\mathbb{E}$表示求期望，$f_\\mathcal{D}(x)$表示在训练集$\\mathcal{D}$上训练得到的模型，$(x,y)\\sim P_r(x,y)$表示$(x,y)$服从$P_r(x,y)$分布，即所有的数据。$(y-f_\\mathcal{D}(x))^{2}$表示真实标签与模型预测标签的平方损失（忽略了系数1/2）。</p>\n<p>假定$f^<em>(x)$是假设空间中的最优模型，则期望误差可分解为<br>$$<br>\\begin{aligned}<br>Err(f) &amp;=\\mathbb{E}<em>{(x, y) \\sim p</em>{r}(x, y)}\\left[\\left(y-f^</em>(x)+f^<em>(x)-f(x)\\right)^{2}\\right] \\<br>&amp;=\\mathbb{E}<em>{\\boldsymbol{x} \\sim p</em>{r}(x)}\\left[\\left(f(x)-f^{</em>}(x)\\right)^{2}\\right]+\\epsilon<br>\\end{aligned}<br>$$</p>\n"},{"title":"【文献翻译】基于深度学习的文本分类：全面回顾","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-04-27T12:42:51.000Z","password":null,"summary":null,"img":null,"keywords":"文本分类 综述 文献翻译","_content":"\n### 摘要\n\n基于深度学习的模型已经在各种文本分类任务中超过了经典的基于机器学的方法，例如情感分析，新闻分类，问答以及自然语言处理。在这次工作中，我们对近些年开发的150多种基于深度学习的文本分类模型进行了详尽的回顾，讨论了他们的技术贡献，相似点以及优点。我们还对广泛应用于文本分类的40多个流行数据集进行了总结。最后，我们对不同的深度学习模型在**流行基准**上的性能进行了定量分析。\n\n### Introduction\n\n文本分类是自然语言处理中的一个经典问题，旨在为文本单元（例如句子，**询问**，段落和文档）分配标签。文本分类有十分广泛的应用，例如问答，垃圾邮件检测，情感分析，新闻分类，用户意图识别，内容审核等等。文本数据可以来自不同的数据源，例如网页数据，邮件，聊天，社交媒体，机票，保险理赔，用户评论，客户服务中的问题和解答等等。文本中含有极其丰富的信息，但由于它的非结构化特征，想要从中提取信息便极具挑战和耗时。\n\n文本分类可以通过人工标注和自动标注两种方式进行，随着工业应用中文本数据规模不断增大，自动文本分类变得越来越重要。自动文本分类的方法可以被分为3类：\n\n* 基于规则的方法\n* 基于机器学习的方法（数据驱动）\n* 混合方法\n\n基于规则的方法使用一组预定义的规则将文本分为不同的类别。例如，所有包含“足球”，”篮球“或者”棒球“的文档都被标记为”运动“标签。\n\n### 2 用于文本分类的深度学习模型\n\n在这个部分，我们回顾了针对各种文本分类问题提出的150多种深度学习框架。为了更易于遵循，我们根据模型的主要架构贡献将其分为以下类别：\n\n* 基于前馈网络的模型，该模型将文本视为一堆单词（a bag of words）（第2.1节）\n* 基于RNN的模型，该模型将文本视为单词序列，旨在捕获单词相关性和文本结构（第2.2节）\n* 基于CNN的模型，经过训练可识别文本中的模式（例如关键短语）以进行分类（第2.3节）\n* 胶囊网络(Capsule networks)解决了CNN的池化操作所带来的信息丢失问题，最近已应用于文本分类（第2.4节）\n* 注意机制(Attention mechanism)可有效识别文本中的相关单词，并已成为开发深度学习模型的有用工具（第2.5节）\n* 记忆增强网络(Memory-augmented networks)，将神经网络与外部记忆形式结合在一起，模型可以从中读取和写入（第2.6节）\n* Transformers，允许比RNN更多的并行化，因此可以使用GPU集群有效地（预）训练非常大的语言模型（第2.7节）\n* 图神经网络(Graph neural networks)，旨在捕获自然语言的内部图结构，例如句法和语义解析树（第2.8节）\n* 孪生神经网络(Siamese Neural Networks)，用于文本匹配，文本匹配是文本分类的一种特殊情况（第2.9节）\n* 混合模型(Hybrid models)，结合注意力，RNN，CNN等模型来捕获句子和文档的局部和全局特征（第2.10节）\n* 最后，在2.11节中，我们回顾了有监督学习之外的建模技术，包括使用自动编码器(Autoencoder)和对抗训练(Adversarial training)的无监督学习(Unsupervised learning)，以及强化学习(Reinforcement learning)\n\n### 2.1 前馈神经网络\n\n前馈网络是用于文本表示的最简单的深度学习模型之一。但是，它们已经在许多文本分类基准上达到了很高的准确性。 这些模型将文本视为一堆单词。对于每个单词，他们使用诸如word2vec [8]或Glove [9]之类的嵌入模型学习向量表示，将嵌入向量的和或平均值作为文本的表示，将其通过一个或多个前馈层，称为多层感知器（MLP），然后使用诸如逻辑回归、朴素贝叶斯或SVM等分类器对最终层的表示进行分类[10]。一个例子如深度平均网络（Deep Average Network，DAN）[10]，其体系结构如图1所示。尽管简单，但DAN却胜过了其他更复杂的模型，这些模型旨在显式地学习文本的组成。例如，DAN在语法差异较大的数据集上的表现优于语法模型。Joulin等[11]提出了一种简单而有效的文本分类器，称为fastText。 像DAN一样，fastText将文本视为一堆单词，与DAN不同的是，fastText使用n-gram作为附加特征来捕获局部单词顺序信息。 事实证明，这在实践中非常有效，同时可达到与显式使用单词顺序的方法[12]相当的结果。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200428171503.png)\n\nLe和Mikolov [13]提出了doc2vec，它使用一种无监督算法来学习可变长度文本（例如句子，段落和文档）的定长特征表示。如图2所示，doc2vec的体系结构类似于连续词袋（CBOW）模型的体系结构[8，14]。唯一的区别是附加的段落标记通过矩阵D映射到段落向量。在doc2vec中，此向量与三个单词的上下文的连接或平均值用于预测第四个单词。 段落向量表示当前上下文中丢失的信息，可以用作该段落的主题记忆。经过训练后，段落向量将用作段落的特征并送入分类器进行预测。  Doc2vec在发布时，在一些文本分类和情感分析任务上获得了最优结果。\n\n### 2.2 基于RNN的模型\n\n基于RNN的模型将文本视为一系列单词，旨在捕获单词依赖性和文本结构以进行文本分类。但是，普通的RNN(vanilla RNN)模型不能很好地工作，并且通常表现不如前馈神经网络。 在RNN的许多变体中，长短期记忆网络（LSTM）是最受欢迎的结构，旨在更好地捕获长期依赖关系。LSTM通过引入存储单元以记住任意时间间隔的值以及三个门（输入门，输出门，遗忘门）来调节信息的流动，从而解决了普通RNN遇到的梯度消失或爆炸问题。已经有工作通过捕获更丰富的信息（例如自然语言的树结构，文本中的大跨度单词关系，文档主题等）来改进用于文本分类的RNN和LSTM模型。\n\nTai等[15]已经开发了Tree-LSTM模型，将LSTM推广到树结构网络类型，以学习丰富的语义表示。作者认为，针对自然语言处理任务，Tree-LSTM比链结构LSTM更好，因为自然语言具有句法属性，可以自然地将单词和短语组合在一起。他们在两个任务上验证了Tree-LSTM的有效性：情感分类和预测两个句子的语义相关性。这些模型的架构如图3所示。 [16]通过使用存储单元在递归过程中存储多个子单元或多个后代单元的历史将chain-structured LSTM展到树状结构。他们认为，新模型提供了一种原则上的方法，可以考虑在层次结构（例如语言或图像解析结构）上进行长距离交互。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430103448.png)\n\n为了对机器学习的大跨度单词关系进行建模，Cheng等人[17]用一个存储网络代替单个存储单元来增强LSTM体系结构。这可以在神经注意力复发期间启用自适应内存使用，从而提供一种弱化标记之间关系的方法。 该模型在语言建模，情感分析和NLI上取得了可喜的结果。\n\n多时标LSTM（MT-LSTM）神经网络[18]被设计为通过捕获具有不同时标的有价值的信息来对长文本（例如句子和文档）建模。MT-LSTM将标准LSTM模型的隐藏状态分为几组。 每个组在不同的时间段被激活和更新。 因此，MT-LSTM可以对很长的文档进行建模。MT-LSTM在文本分类方面优于包括基于LSTM和RNN的模型在内的基准。\n\nRNN擅长捕获单词序列的局部结构，但是面对远距离依赖关系会有点力不从心。相反，潜在主题模型（latent topic models）能够捕获文档的全局语义结构，但不考虑单词顺序。Bieng等 [19]提出了TopicRNN模型，以整合RNN和潜在主题模型的优点。 它使用RNN捕获局部（语法）依赖性，并使用潜在主题捕获全局（语义）依赖性。 TopicRNN在情感分析方面优于RNN基线。\n\n还有其他有趣的基于RNN的模型。 刘等[20]使用多任务学习来训练RNN，以利用来自多个相关任务的标记训练数据。Johnson和Rie [21]探索了使用LSTM的文本区域嵌入方法。周等 [22]集成了双向LSTM（Bi-LSTM）模型和二维最大池来捕获文本特征。Wang等[23]提出了在“matching-aggregation”框架下的双边多视角匹配模型。  Wan等[24]使用双向LSMT模型生成的多个位置句子表示来探索语义匹配。\n\n### 2.3 基于CNN的模型\n\n训练RNN识别跨时间的模式，而CNN学会识别跨空间的模式[25]。在需要理解远程语义的POS标签或QA等NLP任务中，RNN效果很好，而在检测局部和位置不变模式很重要的情况下，CNN效果很好。这些模式可能是表达特定情绪（例如“我喜欢”）或主题（例如“濒危物种”）的关键短语。 因此，CNN已成为最受欢迎的文本分类模型体系结构之一。\n\nKalchbrenner等人提出了最早的基于CNN的文本分类模型之一[26]。 该模型使用动态k-max池，称为动态CNN（DCNN）。如图4所示，DCNN的第一层使用对句子中每个单词的嵌入来构造句子矩阵。 然后使用将宽卷积层与动态k-max池给定的动态池层交替的卷积体系结构来生成句子的特征映射，该特征映射能够显式捕获单词和短语的短时和长时关系。可以根据句子大小和卷积层次结构的级别来动态选择池化参数k。\n\n后来，Kim [27]提出了一种比DCNN简单得多的基于CNN的模型，用于文本分类。 如图5所示，Kim的模型仅在从无监督神经语言模型（即word2vec）获得的单词向量上使用一层卷积。Kim还比较了四种学习单词嵌入的方法：\n\n* CNN-rand，其中所有单词嵌入都在训练过程中被随机初始化，然后进行修改\n* CNN-static，在模型训练期间使用预训练的word2vec嵌入并保持固定\n* CNN-non-static，其中word2vec嵌入在针对每个任务的训练过程中进行了微调\n* CNN-multi-channel，其中使用了两组词嵌入向量集，都使用word2vec进行了初始化，其中一个在模型训练期间进行了更新，而另一个则在固定的情况下进行了更新。\n\n这些基于CNN的模型将改进情感分析和问题分类的SOTA。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164349.png)\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164600.png)\n\n[26，27]已经做出了一些努力来改进基于CNN模型的体系结构。刘等[28]提出了一种新的基于CNN的模型，该模型对TextCNN [27]的体系结构进行了两次修改。首先，采用动态最大池化方案来从文档的不同区域捕获更多细粒度的特征。其次，在池化层和输出层之间插入一个隐藏的瓶颈层（bottleneck layer）学习紧凑的文档表示形式，以减小模型大小并提高模型性能。在[29，30]中，作者没有使用预先训练的低维词向量作为CNN的输入，而是直接将CNN应用于高维文本数据，以学习小文本区域的嵌入进行分类。\n\n字符级的CNN也已经被用于文本分类[31，32]。Zhang等人提出了最早的此类模型之一[31]。如图6所示，该模型以固定大小的字符作为输入，将其编码为一个one-hot向量，然后将它们通过一个深CNN模型，该模型由具有池化操作的六个卷积层和三个全连接层组成。Prusa等[33]提出了一种使用CNN编码文本的方法，该方法大大减少了学习字符级文本表示所需的内存消耗和训练时间。此方法可根据字母大小很好地缩放，从而可以保留原始文本中的更多信息以增强分类性能\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164852.png)\n\n有研究调查词嵌入和CNN架构对模型性能的影响。受到VGG [34]和ResNets [35]的启发，Conneau等人 [36]提出了一种非常深的CNN（VDCNN）模型用于文本处理。它直接在字符级别上操作，并且仅使用小的卷积和池化操作。 研究表明，VDCNN的性能随着深度的增加而增加。杜克等[37]修改了VDCNN的结构，以适应移动平台的限制并保持性能。他们能够将模型大小压缩10倍至20倍，而精度损失在0.4％至1.3％之间。Le等[38]表明，当文本输入表示为字符序列时，深层模型确实优于浅层模型。但是，一个简单的浅层和广域网络在词输入方面胜过DenseNet [39]等深层模型。郭等[40]研究了词嵌入的影响，并提出通过多通道CNN模型使用加权词嵌入。张等[41]研究了不同词嵌入方法和池化机制的影响，发现使用非静态word2vec和GloVe优于one-hot向量，并且最大池化始终优于其他池化方法。\n\n还有其他有趣的基于CNN的模型。Mou等[42]提出了一种基于树的CNN来捕获句子级语义。庞等[43]将文本匹配转换为图像识别任务，并使用多层CNN识别显著n-gram模式。Wang等[44]提出了一种基于CNN的模型，该模型结合了短文本的显式和隐式表示形式进行分类。 将CNN应用于生物医学文本分类的兴趣也越来越高[45-48]。\n\n### 2.4 胶囊网络\n\nCNN通过使用连续的卷积和池化层对图像或文本进行分类。 尽管池化操作可识别显著特征并降低卷积操作的计算复杂性，但它们会丢失有关空间关系的信息，并可能根据其方向或比例对实体进行错误分类\n\n为了解决池化带来的问题，Geoffrey Hinton提出了一种新方法，称为胶囊网络（CapsNets）[49，50]。一个胶囊是一组神经元，其活动向量代表特定类型的实体（例如对象或对象部分）的不同属性。向量的长度代表实体存在的概率，向量的方向代表实体的属性。与CNN的最大池化（选择一些信息并丢弃其余信息）不同，胶囊使用网络中直到最后一层的所有可用信息，将底层的每个胶囊“路由”到上层最匹配的父胶囊。可以使用不同的算法来实现路由，例如协议动态路由[50]或EM算法[51]。\n\n近来，胶囊网络已经被应用于文本分类，其中胶囊适于将句子或文档表示为向量。  [52–54]提出了一种基于CapsNets变体的文本分类模型。该模型由四层组成：（1）n-gram卷积层，（2）胶囊层，（3）卷积胶囊层，以及（4）完全连接的胶囊层。 作者尝试了三种策略来稳定动态路由过程，以减轻包含背景信息（例如停用词或与任何文档类别无关的词）的噪声包的干扰。 他们还探索了两种胶囊架构，如图7所示。分别为Capsule-A和Capsule-B。Capsule-A与[50]中的CapsNet类似。  Capsule-B使用三个并行网络，并在n-gram卷积层中使用具有不同窗口大小的过滤器，以学习更全面的文本表示形式。  CapsNet-B在实验中表现更好。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165324.png)\n\nKim等人提出的基于CapsNet的模型[55]使用类似的架构。 该模型包括（1）一个输入层，该输入层将文档作为单词嵌入的序列；（2）卷积层，生成特征图并使用门控线性单元保留空间信息；（3）卷积胶囊层，通过聚合卷积层检测到的局部特征形成整体特征；（4）文本胶囊层以预测类标签。作者观察到，相比于图像，对象可以更自由地组合在文本中。 例如，即使某些句子的顺序改变了，文档的语义也可以保持不变，这与人脸上的眼睛和鼻子的位置不同。 因此，他们使用静态路由方案，该方案始终优于动态路由[50]进行文本分类。Aly等[56]提议使用CapsNets进行分层多标签分类（HMC），认为CapsNet编码子代关系的能力使其比传统方法更好地解决了HMC任务，在HMC任务中，文档被分配了一个或多个分类标签，这些标签被组织在一个层次结构。 他们模型的架构类似于[52，53，55]中的架构。任等人 [57]提出了CapsNets的另一种变体，它使用了胶囊之间的成分编码机制和基于k-means聚类的新路由算法。 首先，使用codebooks中的所有 codeword vectors 形成单词嵌入。 然后，通过k均值路由将下层胶囊捕获的特征汇总到高层胶囊中。\n\n### 2.5 基于注意力机制模型\n\n在开发用于NLP的深度学习模型时，注意力已成为越来越流行的概念和有用的工具[58，59]。 简而言之，语言模型中的注意力可被解释为重要权重的向量。 为了预测句子中的单词，我们使用注意力向量来估计它与其他单词的相关性或“与之相关”的程度，然后将注意力向量加权的值之和作为目标的近似值\n\n本节回顾了一些最突出的注意力模型，这些模型在发布时就在文本分类任务上取得了SOTA。\n\n杨等[60]提出了一种用于文本分类的分层注意力网络。 该模型具有两个鲜明的特征：（1）反映文档的层次结构的层次结构，（2）在单词和句子级别上应用的两个级别的注意力机制，使它能够在构建文档表示形式时以不同的方式参加重要或不重要的内容。 在六个文本分类任务上，该模型大大优于以前的方法。周等[61]将分层注意力模型扩展到跨语言情感分类。 在每种语言中，都使用LSTM网络对文档进行建模。 然后，通过使用分层注意机制实现分类，其中句子级别的注意模型了解文档的哪些句子对于确定总体情绪更重要。 而词级注意力模型则学习每个句子中哪些词具有决定性。\n\n沉等[62]提出了一种定向自我注意网络，用于无RNN / CNN语言理解，其中来自输入序列的元素之间的注意力是定向的和多维的。 轻量级神经网络仅基于所提出的注意力而无需任何RNN / CNN结构即可用于学习句子嵌入。刘等[63]提出了一个具有inner-attention的LSTM模型,用来做NLI任务。 该模型使用两阶段过程对句子进行编码。 首先，在词级Bi-LSTM上使用平均池化以生成第一阶段句子表示。 其次，采用注意力机制来代替同一句子的平均池，以获得更好的表示。 句子的第一阶段表示法用于出现在句子中的单词。\n\n注意模型也广泛应用于成对排序（pair-wise ranking）或匹配任务。  Santos等[64]提出了一种双向注意机制，称为Attentive Pooling（AP），用于成对排名。  AP可以使池化层知道当前的输入对（例如，问题-答案对），以使两个输入项的信息可以直接影响彼此表示的计算。 除了学习输入对的表示之外，AP联合学习该对投影段的相似性度量，然后为每个输入导出相应的注意力向量以指导池化。  AP是独立于底层表示学习的通用框架，并且可以应用于CNN和RNN，如图8（a）所示。Wang等[65]将文本分类视为标签-单词匹配问题：每个标签与单词向量一起嵌入相同的空间。作者介绍了一种注意力框架，该框架通过余弦相似性来度量文本序列和标签之间嵌入的兼容性，如图8（b）所示。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165837.png)\n\nKim等[66]提出了一种使用密集连接的循环共同注意力网络的语义句子匹配方法。 类似于DenseNet [39]，该模型的每一层都使用所有先前的递归层的注意特征以及隐藏特征的级联信息。它可以保留从最底层单词嵌入层到最上层循环层的原始和共同注意特征信息。Yin等[67]提出了另一种基于注意力的CNN模型，用于句子对匹配。 他们提出了三种将句子之间的相互影响整合到CNN中的注意力方案，以便每个句子的表示都考虑到其成对的句子。 这些相互依赖的句子对表示形式比孤立的句子表示形式更为强大，这在包括答案选择，复述识别和文本蕴涵在内的多个分类任务中得到了验证。Tan等[68]在匹配聚合框架下采用了多种注意函数来匹配句子对。 杨等。  [69]介绍了一种基于注意力的神经匹配模型，用于对简短答案文本进行排名。 他们采用价值共享加权方案代替位置共享加权方案来组合不同的匹配信号，并使用问题关注网络将问题术语重要性学习纳入其中。 该模型在TREC QA数据集上取得了可喜的结果。\n\n还有其他有趣的注意力模型。  Lin等[70]使用自注意力来提取可解释的句子嵌入。  Wang等[71]提出了一种具有多尺度特征关注度的紧密连接的CNN，以产生可变的n-gram特征。  Yamada和Shindo [72] 使用neural attentive bag-of-entities 模型（使用知识库中的实体）进行文本分类。  Parikh等。  [73]使用注意力将问题分解为可以单独解决的子问题。  Chen等[74]探索了通用的池化方法来增强句子嵌入，并提出了一个基于向量的多头注意力模型。  Liu和Lane [75]提出了一种基于注意力的RNN模型，用于联合意图检测和空缺填充。\n\n### 2.6 记忆增强网络\n\n注意力模型在编码过程中存储的隐藏向量可以看作是模型内部记忆，而记忆增强网络则将神经网络与外部记忆结合在一起，模型可以对其进行读写。\n\nMunkhdalai和Yu[76]提出了一种记忆增强的神经网络，称为神经语义编码器（NSE），用于文本分类和QA。  NSE配备了一个可变大小的编码记忆，该编码记忆会随着时间的推移而发展，并通过读取，编写和写入操作保持对输入序列的理解，如图9所示。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200503113637.png)\n\n韦斯顿等[77]设计了一个用于综合QA任务的记忆网络，在该网络中，向模型提供了一系列语句（记忆记录），作为问题的支持事实。 该模型会根据问题和先前检索到的记忆来一次从记忆中检索一个条目。Sukhbaatar等[78]扩展了这项工作，并提出了端到端的记忆网络，在记忆网络中以柔和的方式利用注意力机制检索记忆条目，从而实现了端到端的训练。 他们表明，通过多次回合（跳数），该模型能够检索并推理几个支持事实，以回答特定问题。\n\nKumar等[79]提出了一种动态记忆方法（DMN），它处理输入序列和问题，形成情节记忆，并产生相关的答案。 问题触发迭代注意进程，该进程允许模型将注意条件设置为输入和先前迭代的结果。 然后，在分层递归序列模型中对这些结果进行推理以生成答案。 对DMN进行端到端训练，并获得有关QA和POS标记的最新结果。 熊等[80]提出了DMN的详细分析，并改进了其就医和输入模块。","source":"_posts/【文献翻译】基于深度学习的文本分类：全面回顾.md","raw":"---\ntitle: 【文献翻译】基于深度学习的文本分类：全面回顾\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-04-27 20:42:51\npassword:\nsummary:\ncategories: 文献翻译\nimg:\nkeywords: 文本分类 综述 文献翻译\ntags:\n\t- 文本分类\n\t- 综述\n\t- 文献翻译\n---\n\n### 摘要\n\n基于深度学习的模型已经在各种文本分类任务中超过了经典的基于机器学的方法，例如情感分析，新闻分类，问答以及自然语言处理。在这次工作中，我们对近些年开发的150多种基于深度学习的文本分类模型进行了详尽的回顾，讨论了他们的技术贡献，相似点以及优点。我们还对广泛应用于文本分类的40多个流行数据集进行了总结。最后，我们对不同的深度学习模型在**流行基准**上的性能进行了定量分析。\n\n### Introduction\n\n文本分类是自然语言处理中的一个经典问题，旨在为文本单元（例如句子，**询问**，段落和文档）分配标签。文本分类有十分广泛的应用，例如问答，垃圾邮件检测，情感分析，新闻分类，用户意图识别，内容审核等等。文本数据可以来自不同的数据源，例如网页数据，邮件，聊天，社交媒体，机票，保险理赔，用户评论，客户服务中的问题和解答等等。文本中含有极其丰富的信息，但由于它的非结构化特征，想要从中提取信息便极具挑战和耗时。\n\n文本分类可以通过人工标注和自动标注两种方式进行，随着工业应用中文本数据规模不断增大，自动文本分类变得越来越重要。自动文本分类的方法可以被分为3类：\n\n* 基于规则的方法\n* 基于机器学习的方法（数据驱动）\n* 混合方法\n\n基于规则的方法使用一组预定义的规则将文本分为不同的类别。例如，所有包含“足球”，”篮球“或者”棒球“的文档都被标记为”运动“标签。\n\n### 2 用于文本分类的深度学习模型\n\n在这个部分，我们回顾了针对各种文本分类问题提出的150多种深度学习框架。为了更易于遵循，我们根据模型的主要架构贡献将其分为以下类别：\n\n* 基于前馈网络的模型，该模型将文本视为一堆单词（a bag of words）（第2.1节）\n* 基于RNN的模型，该模型将文本视为单词序列，旨在捕获单词相关性和文本结构（第2.2节）\n* 基于CNN的模型，经过训练可识别文本中的模式（例如关键短语）以进行分类（第2.3节）\n* 胶囊网络(Capsule networks)解决了CNN的池化操作所带来的信息丢失问题，最近已应用于文本分类（第2.4节）\n* 注意机制(Attention mechanism)可有效识别文本中的相关单词，并已成为开发深度学习模型的有用工具（第2.5节）\n* 记忆增强网络(Memory-augmented networks)，将神经网络与外部记忆形式结合在一起，模型可以从中读取和写入（第2.6节）\n* Transformers，允许比RNN更多的并行化，因此可以使用GPU集群有效地（预）训练非常大的语言模型（第2.7节）\n* 图神经网络(Graph neural networks)，旨在捕获自然语言的内部图结构，例如句法和语义解析树（第2.8节）\n* 孪生神经网络(Siamese Neural Networks)，用于文本匹配，文本匹配是文本分类的一种特殊情况（第2.9节）\n* 混合模型(Hybrid models)，结合注意力，RNN，CNN等模型来捕获句子和文档的局部和全局特征（第2.10节）\n* 最后，在2.11节中，我们回顾了有监督学习之外的建模技术，包括使用自动编码器(Autoencoder)和对抗训练(Adversarial training)的无监督学习(Unsupervised learning)，以及强化学习(Reinforcement learning)\n\n### 2.1 前馈神经网络\n\n前馈网络是用于文本表示的最简单的深度学习模型之一。但是，它们已经在许多文本分类基准上达到了很高的准确性。 这些模型将文本视为一堆单词。对于每个单词，他们使用诸如word2vec [8]或Glove [9]之类的嵌入模型学习向量表示，将嵌入向量的和或平均值作为文本的表示，将其通过一个或多个前馈层，称为多层感知器（MLP），然后使用诸如逻辑回归、朴素贝叶斯或SVM等分类器对最终层的表示进行分类[10]。一个例子如深度平均网络（Deep Average Network，DAN）[10]，其体系结构如图1所示。尽管简单，但DAN却胜过了其他更复杂的模型，这些模型旨在显式地学习文本的组成。例如，DAN在语法差异较大的数据集上的表现优于语法模型。Joulin等[11]提出了一种简单而有效的文本分类器，称为fastText。 像DAN一样，fastText将文本视为一堆单词，与DAN不同的是，fastText使用n-gram作为附加特征来捕获局部单词顺序信息。 事实证明，这在实践中非常有效，同时可达到与显式使用单词顺序的方法[12]相当的结果。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200428171503.png)\n\nLe和Mikolov [13]提出了doc2vec，它使用一种无监督算法来学习可变长度文本（例如句子，段落和文档）的定长特征表示。如图2所示，doc2vec的体系结构类似于连续词袋（CBOW）模型的体系结构[8，14]。唯一的区别是附加的段落标记通过矩阵D映射到段落向量。在doc2vec中，此向量与三个单词的上下文的连接或平均值用于预测第四个单词。 段落向量表示当前上下文中丢失的信息，可以用作该段落的主题记忆。经过训练后，段落向量将用作段落的特征并送入分类器进行预测。  Doc2vec在发布时，在一些文本分类和情感分析任务上获得了最优结果。\n\n### 2.2 基于RNN的模型\n\n基于RNN的模型将文本视为一系列单词，旨在捕获单词依赖性和文本结构以进行文本分类。但是，普通的RNN(vanilla RNN)模型不能很好地工作，并且通常表现不如前馈神经网络。 在RNN的许多变体中，长短期记忆网络（LSTM）是最受欢迎的结构，旨在更好地捕获长期依赖关系。LSTM通过引入存储单元以记住任意时间间隔的值以及三个门（输入门，输出门，遗忘门）来调节信息的流动，从而解决了普通RNN遇到的梯度消失或爆炸问题。已经有工作通过捕获更丰富的信息（例如自然语言的树结构，文本中的大跨度单词关系，文档主题等）来改进用于文本分类的RNN和LSTM模型。\n\nTai等[15]已经开发了Tree-LSTM模型，将LSTM推广到树结构网络类型，以学习丰富的语义表示。作者认为，针对自然语言处理任务，Tree-LSTM比链结构LSTM更好，因为自然语言具有句法属性，可以自然地将单词和短语组合在一起。他们在两个任务上验证了Tree-LSTM的有效性：情感分类和预测两个句子的语义相关性。这些模型的架构如图3所示。 [16]通过使用存储单元在递归过程中存储多个子单元或多个后代单元的历史将chain-structured LSTM展到树状结构。他们认为，新模型提供了一种原则上的方法，可以考虑在层次结构（例如语言或图像解析结构）上进行长距离交互。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430103448.png)\n\n为了对机器学习的大跨度单词关系进行建模，Cheng等人[17]用一个存储网络代替单个存储单元来增强LSTM体系结构。这可以在神经注意力复发期间启用自适应内存使用，从而提供一种弱化标记之间关系的方法。 该模型在语言建模，情感分析和NLI上取得了可喜的结果。\n\n多时标LSTM（MT-LSTM）神经网络[18]被设计为通过捕获具有不同时标的有价值的信息来对长文本（例如句子和文档）建模。MT-LSTM将标准LSTM模型的隐藏状态分为几组。 每个组在不同的时间段被激活和更新。 因此，MT-LSTM可以对很长的文档进行建模。MT-LSTM在文本分类方面优于包括基于LSTM和RNN的模型在内的基准。\n\nRNN擅长捕获单词序列的局部结构，但是面对远距离依赖关系会有点力不从心。相反，潜在主题模型（latent topic models）能够捕获文档的全局语义结构，但不考虑单词顺序。Bieng等 [19]提出了TopicRNN模型，以整合RNN和潜在主题模型的优点。 它使用RNN捕获局部（语法）依赖性，并使用潜在主题捕获全局（语义）依赖性。 TopicRNN在情感分析方面优于RNN基线。\n\n还有其他有趣的基于RNN的模型。 刘等[20]使用多任务学习来训练RNN，以利用来自多个相关任务的标记训练数据。Johnson和Rie [21]探索了使用LSTM的文本区域嵌入方法。周等 [22]集成了双向LSTM（Bi-LSTM）模型和二维最大池来捕获文本特征。Wang等[23]提出了在“matching-aggregation”框架下的双边多视角匹配模型。  Wan等[24]使用双向LSMT模型生成的多个位置句子表示来探索语义匹配。\n\n### 2.3 基于CNN的模型\n\n训练RNN识别跨时间的模式，而CNN学会识别跨空间的模式[25]。在需要理解远程语义的POS标签或QA等NLP任务中，RNN效果很好，而在检测局部和位置不变模式很重要的情况下，CNN效果很好。这些模式可能是表达特定情绪（例如“我喜欢”）或主题（例如“濒危物种”）的关键短语。 因此，CNN已成为最受欢迎的文本分类模型体系结构之一。\n\nKalchbrenner等人提出了最早的基于CNN的文本分类模型之一[26]。 该模型使用动态k-max池，称为动态CNN（DCNN）。如图4所示，DCNN的第一层使用对句子中每个单词的嵌入来构造句子矩阵。 然后使用将宽卷积层与动态k-max池给定的动态池层交替的卷积体系结构来生成句子的特征映射，该特征映射能够显式捕获单词和短语的短时和长时关系。可以根据句子大小和卷积层次结构的级别来动态选择池化参数k。\n\n后来，Kim [27]提出了一种比DCNN简单得多的基于CNN的模型，用于文本分类。 如图5所示，Kim的模型仅在从无监督神经语言模型（即word2vec）获得的单词向量上使用一层卷积。Kim还比较了四种学习单词嵌入的方法：\n\n* CNN-rand，其中所有单词嵌入都在训练过程中被随机初始化，然后进行修改\n* CNN-static，在模型训练期间使用预训练的word2vec嵌入并保持固定\n* CNN-non-static，其中word2vec嵌入在针对每个任务的训练过程中进行了微调\n* CNN-multi-channel，其中使用了两组词嵌入向量集，都使用word2vec进行了初始化，其中一个在模型训练期间进行了更新，而另一个则在固定的情况下进行了更新。\n\n这些基于CNN的模型将改进情感分析和问题分类的SOTA。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164349.png)\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164600.png)\n\n[26，27]已经做出了一些努力来改进基于CNN模型的体系结构。刘等[28]提出了一种新的基于CNN的模型，该模型对TextCNN [27]的体系结构进行了两次修改。首先，采用动态最大池化方案来从文档的不同区域捕获更多细粒度的特征。其次，在池化层和输出层之间插入一个隐藏的瓶颈层（bottleneck layer）学习紧凑的文档表示形式，以减小模型大小并提高模型性能。在[29，30]中，作者没有使用预先训练的低维词向量作为CNN的输入，而是直接将CNN应用于高维文本数据，以学习小文本区域的嵌入进行分类。\n\n字符级的CNN也已经被用于文本分类[31，32]。Zhang等人提出了最早的此类模型之一[31]。如图6所示，该模型以固定大小的字符作为输入，将其编码为一个one-hot向量，然后将它们通过一个深CNN模型，该模型由具有池化操作的六个卷积层和三个全连接层组成。Prusa等[33]提出了一种使用CNN编码文本的方法，该方法大大减少了学习字符级文本表示所需的内存消耗和训练时间。此方法可根据字母大小很好地缩放，从而可以保留原始文本中的更多信息以增强分类性能\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164852.png)\n\n有研究调查词嵌入和CNN架构对模型性能的影响。受到VGG [34]和ResNets [35]的启发，Conneau等人 [36]提出了一种非常深的CNN（VDCNN）模型用于文本处理。它直接在字符级别上操作，并且仅使用小的卷积和池化操作。 研究表明，VDCNN的性能随着深度的增加而增加。杜克等[37]修改了VDCNN的结构，以适应移动平台的限制并保持性能。他们能够将模型大小压缩10倍至20倍，而精度损失在0.4％至1.3％之间。Le等[38]表明，当文本输入表示为字符序列时，深层模型确实优于浅层模型。但是，一个简单的浅层和广域网络在词输入方面胜过DenseNet [39]等深层模型。郭等[40]研究了词嵌入的影响，并提出通过多通道CNN模型使用加权词嵌入。张等[41]研究了不同词嵌入方法和池化机制的影响，发现使用非静态word2vec和GloVe优于one-hot向量，并且最大池化始终优于其他池化方法。\n\n还有其他有趣的基于CNN的模型。Mou等[42]提出了一种基于树的CNN来捕获句子级语义。庞等[43]将文本匹配转换为图像识别任务，并使用多层CNN识别显著n-gram模式。Wang等[44]提出了一种基于CNN的模型，该模型结合了短文本的显式和隐式表示形式进行分类。 将CNN应用于生物医学文本分类的兴趣也越来越高[45-48]。\n\n### 2.4 胶囊网络\n\nCNN通过使用连续的卷积和池化层对图像或文本进行分类。 尽管池化操作可识别显著特征并降低卷积操作的计算复杂性，但它们会丢失有关空间关系的信息，并可能根据其方向或比例对实体进行错误分类\n\n为了解决池化带来的问题，Geoffrey Hinton提出了一种新方法，称为胶囊网络（CapsNets）[49，50]。一个胶囊是一组神经元，其活动向量代表特定类型的实体（例如对象或对象部分）的不同属性。向量的长度代表实体存在的概率，向量的方向代表实体的属性。与CNN的最大池化（选择一些信息并丢弃其余信息）不同，胶囊使用网络中直到最后一层的所有可用信息，将底层的每个胶囊“路由”到上层最匹配的父胶囊。可以使用不同的算法来实现路由，例如协议动态路由[50]或EM算法[51]。\n\n近来，胶囊网络已经被应用于文本分类，其中胶囊适于将句子或文档表示为向量。  [52–54]提出了一种基于CapsNets变体的文本分类模型。该模型由四层组成：（1）n-gram卷积层，（2）胶囊层，（3）卷积胶囊层，以及（4）完全连接的胶囊层。 作者尝试了三种策略来稳定动态路由过程，以减轻包含背景信息（例如停用词或与任何文档类别无关的词）的噪声包的干扰。 他们还探索了两种胶囊架构，如图7所示。分别为Capsule-A和Capsule-B。Capsule-A与[50]中的CapsNet类似。  Capsule-B使用三个并行网络，并在n-gram卷积层中使用具有不同窗口大小的过滤器，以学习更全面的文本表示形式。  CapsNet-B在实验中表现更好。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165324.png)\n\nKim等人提出的基于CapsNet的模型[55]使用类似的架构。 该模型包括（1）一个输入层，该输入层将文档作为单词嵌入的序列；（2）卷积层，生成特征图并使用门控线性单元保留空间信息；（3）卷积胶囊层，通过聚合卷积层检测到的局部特征形成整体特征；（4）文本胶囊层以预测类标签。作者观察到，相比于图像，对象可以更自由地组合在文本中。 例如，即使某些句子的顺序改变了，文档的语义也可以保持不变，这与人脸上的眼睛和鼻子的位置不同。 因此，他们使用静态路由方案，该方案始终优于动态路由[50]进行文本分类。Aly等[56]提议使用CapsNets进行分层多标签分类（HMC），认为CapsNet编码子代关系的能力使其比传统方法更好地解决了HMC任务，在HMC任务中，文档被分配了一个或多个分类标签，这些标签被组织在一个层次结构。 他们模型的架构类似于[52，53，55]中的架构。任等人 [57]提出了CapsNets的另一种变体，它使用了胶囊之间的成分编码机制和基于k-means聚类的新路由算法。 首先，使用codebooks中的所有 codeword vectors 形成单词嵌入。 然后，通过k均值路由将下层胶囊捕获的特征汇总到高层胶囊中。\n\n### 2.5 基于注意力机制模型\n\n在开发用于NLP的深度学习模型时，注意力已成为越来越流行的概念和有用的工具[58，59]。 简而言之，语言模型中的注意力可被解释为重要权重的向量。 为了预测句子中的单词，我们使用注意力向量来估计它与其他单词的相关性或“与之相关”的程度，然后将注意力向量加权的值之和作为目标的近似值\n\n本节回顾了一些最突出的注意力模型，这些模型在发布时就在文本分类任务上取得了SOTA。\n\n杨等[60]提出了一种用于文本分类的分层注意力网络。 该模型具有两个鲜明的特征：（1）反映文档的层次结构的层次结构，（2）在单词和句子级别上应用的两个级别的注意力机制，使它能够在构建文档表示形式时以不同的方式参加重要或不重要的内容。 在六个文本分类任务上，该模型大大优于以前的方法。周等[61]将分层注意力模型扩展到跨语言情感分类。 在每种语言中，都使用LSTM网络对文档进行建模。 然后，通过使用分层注意机制实现分类，其中句子级别的注意模型了解文档的哪些句子对于确定总体情绪更重要。 而词级注意力模型则学习每个句子中哪些词具有决定性。\n\n沉等[62]提出了一种定向自我注意网络，用于无RNN / CNN语言理解，其中来自输入序列的元素之间的注意力是定向的和多维的。 轻量级神经网络仅基于所提出的注意力而无需任何RNN / CNN结构即可用于学习句子嵌入。刘等[63]提出了一个具有inner-attention的LSTM模型,用来做NLI任务。 该模型使用两阶段过程对句子进行编码。 首先，在词级Bi-LSTM上使用平均池化以生成第一阶段句子表示。 其次，采用注意力机制来代替同一句子的平均池，以获得更好的表示。 句子的第一阶段表示法用于出现在句子中的单词。\n\n注意模型也广泛应用于成对排序（pair-wise ranking）或匹配任务。  Santos等[64]提出了一种双向注意机制，称为Attentive Pooling（AP），用于成对排名。  AP可以使池化层知道当前的输入对（例如，问题-答案对），以使两个输入项的信息可以直接影响彼此表示的计算。 除了学习输入对的表示之外，AP联合学习该对投影段的相似性度量，然后为每个输入导出相应的注意力向量以指导池化。  AP是独立于底层表示学习的通用框架，并且可以应用于CNN和RNN，如图8（a）所示。Wang等[65]将文本分类视为标签-单词匹配问题：每个标签与单词向量一起嵌入相同的空间。作者介绍了一种注意力框架，该框架通过余弦相似性来度量文本序列和标签之间嵌入的兼容性，如图8（b）所示。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165837.png)\n\nKim等[66]提出了一种使用密集连接的循环共同注意力网络的语义句子匹配方法。 类似于DenseNet [39]，该模型的每一层都使用所有先前的递归层的注意特征以及隐藏特征的级联信息。它可以保留从最底层单词嵌入层到最上层循环层的原始和共同注意特征信息。Yin等[67]提出了另一种基于注意力的CNN模型，用于句子对匹配。 他们提出了三种将句子之间的相互影响整合到CNN中的注意力方案，以便每个句子的表示都考虑到其成对的句子。 这些相互依赖的句子对表示形式比孤立的句子表示形式更为强大，这在包括答案选择，复述识别和文本蕴涵在内的多个分类任务中得到了验证。Tan等[68]在匹配聚合框架下采用了多种注意函数来匹配句子对。 杨等。  [69]介绍了一种基于注意力的神经匹配模型，用于对简短答案文本进行排名。 他们采用价值共享加权方案代替位置共享加权方案来组合不同的匹配信号，并使用问题关注网络将问题术语重要性学习纳入其中。 该模型在TREC QA数据集上取得了可喜的结果。\n\n还有其他有趣的注意力模型。  Lin等[70]使用自注意力来提取可解释的句子嵌入。  Wang等[71]提出了一种具有多尺度特征关注度的紧密连接的CNN，以产生可变的n-gram特征。  Yamada和Shindo [72] 使用neural attentive bag-of-entities 模型（使用知识库中的实体）进行文本分类。  Parikh等。  [73]使用注意力将问题分解为可以单独解决的子问题。  Chen等[74]探索了通用的池化方法来增强句子嵌入，并提出了一个基于向量的多头注意力模型。  Liu和Lane [75]提出了一种基于注意力的RNN模型，用于联合意图检测和空缺填充。\n\n### 2.6 记忆增强网络\n\n注意力模型在编码过程中存储的隐藏向量可以看作是模型内部记忆，而记忆增强网络则将神经网络与外部记忆结合在一起，模型可以对其进行读写。\n\nMunkhdalai和Yu[76]提出了一种记忆增强的神经网络，称为神经语义编码器（NSE），用于文本分类和QA。  NSE配备了一个可变大小的编码记忆，该编码记忆会随着时间的推移而发展，并通过读取，编写和写入操作保持对输入序列的理解，如图9所示。\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200503113637.png)\n\n韦斯顿等[77]设计了一个用于综合QA任务的记忆网络，在该网络中，向模型提供了一系列语句（记忆记录），作为问题的支持事实。 该模型会根据问题和先前检索到的记忆来一次从记忆中检索一个条目。Sukhbaatar等[78]扩展了这项工作，并提出了端到端的记忆网络，在记忆网络中以柔和的方式利用注意力机制检索记忆条目，从而实现了端到端的训练。 他们表明，通过多次回合（跳数），该模型能够检索并推理几个支持事实，以回答特定问题。\n\nKumar等[79]提出了一种动态记忆方法（DMN），它处理输入序列和问题，形成情节记忆，并产生相关的答案。 问题触发迭代注意进程，该进程允许模型将注意条件设置为输入和先前迭代的结果。 然后，在分层递归序列模型中对这些结果进行推理以生成答案。 对DMN进行端到端训练，并获得有关QA和POS标记的最新结果。 熊等[80]提出了DMN的详细分析，并改进了其就医和输入模块。","slug":"【文献翻译】基于深度学习的文本分类：全面回顾","published":1,"updated":"2020-05-17T13:35:49.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqy5000kgswjfxvsh49k","content":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>基于深度学习的模型已经在各种文本分类任务中超过了经典的基于机器学的方法，例如情感分析，新闻分类，问答以及自然语言处理。在这次工作中，我们对近些年开发的150多种基于深度学习的文本分类模型进行了详尽的回顾，讨论了他们的技术贡献，相似点以及优点。我们还对广泛应用于文本分类的40多个流行数据集进行了总结。最后，我们对不同的深度学习模型在<strong>流行基准</strong>上的性能进行了定量分析。</p>\n<h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><p>文本分类是自然语言处理中的一个经典问题，旨在为文本单元（例如句子，<strong>询问</strong>，段落和文档）分配标签。文本分类有十分广泛的应用，例如问答，垃圾邮件检测，情感分析，新闻分类，用户意图识别，内容审核等等。文本数据可以来自不同的数据源，例如网页数据，邮件，聊天，社交媒体，机票，保险理赔，用户评论，客户服务中的问题和解答等等。文本中含有极其丰富的信息，但由于它的非结构化特征，想要从中提取信息便极具挑战和耗时。</p>\n<p>文本分类可以通过人工标注和自动标注两种方式进行，随着工业应用中文本数据规模不断增大，自动文本分类变得越来越重要。自动文本分类的方法可以被分为3类：</p>\n<ul>\n<li>基于规则的方法</li>\n<li>基于机器学习的方法（数据驱动）</li>\n<li>混合方法</li>\n</ul>\n<p>基于规则的方法使用一组预定义的规则将文本分为不同的类别。例如，所有包含“足球”，”篮球“或者”棒球“的文档都被标记为”运动“标签。</p>\n<h3 id=\"2-用于文本分类的深度学习模型\"><a href=\"#2-用于文本分类的深度学习模型\" class=\"headerlink\" title=\"2 用于文本分类的深度学习模型\"></a>2 用于文本分类的深度学习模型</h3><p>在这个部分，我们回顾了针对各种文本分类问题提出的150多种深度学习框架。为了更易于遵循，我们根据模型的主要架构贡献将其分为以下类别：</p>\n<ul>\n<li>基于前馈网络的模型，该模型将文本视为一堆单词（a bag of words）（第2.1节）</li>\n<li>基于RNN的模型，该模型将文本视为单词序列，旨在捕获单词相关性和文本结构（第2.2节）</li>\n<li>基于CNN的模型，经过训练可识别文本中的模式（例如关键短语）以进行分类（第2.3节）</li>\n<li>胶囊网络(Capsule networks)解决了CNN的池化操作所带来的信息丢失问题，最近已应用于文本分类（第2.4节）</li>\n<li>注意机制(Attention mechanism)可有效识别文本中的相关单词，并已成为开发深度学习模型的有用工具（第2.5节）</li>\n<li>记忆增强网络(Memory-augmented networks)，将神经网络与外部记忆形式结合在一起，模型可以从中读取和写入（第2.6节）</li>\n<li>Transformers，允许比RNN更多的并行化，因此可以使用GPU集群有效地（预）训练非常大的语言模型（第2.7节）</li>\n<li>图神经网络(Graph neural networks)，旨在捕获自然语言的内部图结构，例如句法和语义解析树（第2.8节）</li>\n<li>孪生神经网络(Siamese Neural Networks)，用于文本匹配，文本匹配是文本分类的一种特殊情况（第2.9节）</li>\n<li>混合模型(Hybrid models)，结合注意力，RNN，CNN等模型来捕获句子和文档的局部和全局特征（第2.10节）</li>\n<li>最后，在2.11节中，我们回顾了有监督学习之外的建模技术，包括使用自动编码器(Autoencoder)和对抗训练(Adversarial training)的无监督学习(Unsupervised learning)，以及强化学习(Reinforcement learning)</li>\n</ul>\n<h3 id=\"2-1-前馈神经网络\"><a href=\"#2-1-前馈神经网络\" class=\"headerlink\" title=\"2.1 前馈神经网络\"></a>2.1 前馈神经网络</h3><p>前馈网络是用于文本表示的最简单的深度学习模型之一。但是，它们已经在许多文本分类基准上达到了很高的准确性。 这些模型将文本视为一堆单词。对于每个单词，他们使用诸如word2vec [8]或Glove [9]之类的嵌入模型学习向量表示，将嵌入向量的和或平均值作为文本的表示，将其通过一个或多个前馈层，称为多层感知器（MLP），然后使用诸如逻辑回归、朴素贝叶斯或SVM等分类器对最终层的表示进行分类[10]。一个例子如深度平均网络（Deep Average Network，DAN）[10]，其体系结构如图1所示。尽管简单，但DAN却胜过了其他更复杂的模型，这些模型旨在显式地学习文本的组成。例如，DAN在语法差异较大的数据集上的表现优于语法模型。Joulin等[11]提出了一种简单而有效的文本分类器，称为fastText。 像DAN一样，fastText将文本视为一堆单词，与DAN不同的是，fastText使用n-gram作为附加特征来捕获局部单词顺序信息。 事实证明，这在实践中非常有效，同时可达到与显式使用单词顺序的方法[12]相当的结果。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200428171503.png\" alt=\"\"></p>\n<p>Le和Mikolov [13]提出了doc2vec，它使用一种无监督算法来学习可变长度文本（例如句子，段落和文档）的定长特征表示。如图2所示，doc2vec的体系结构类似于连续词袋（CBOW）模型的体系结构[8，14]。唯一的区别是附加的段落标记通过矩阵D映射到段落向量。在doc2vec中，此向量与三个单词的上下文的连接或平均值用于预测第四个单词。 段落向量表示当前上下文中丢失的信息，可以用作该段落的主题记忆。经过训练后，段落向量将用作段落的特征并送入分类器进行预测。  Doc2vec在发布时，在一些文本分类和情感分析任务上获得了最优结果。</p>\n<h3 id=\"2-2-基于RNN的模型\"><a href=\"#2-2-基于RNN的模型\" class=\"headerlink\" title=\"2.2 基于RNN的模型\"></a>2.2 基于RNN的模型</h3><p>基于RNN的模型将文本视为一系列单词，旨在捕获单词依赖性和文本结构以进行文本分类。但是，普通的RNN(vanilla RNN)模型不能很好地工作，并且通常表现不如前馈神经网络。 在RNN的许多变体中，长短期记忆网络（LSTM）是最受欢迎的结构，旨在更好地捕获长期依赖关系。LSTM通过引入存储单元以记住任意时间间隔的值以及三个门（输入门，输出门，遗忘门）来调节信息的流动，从而解决了普通RNN遇到的梯度消失或爆炸问题。已经有工作通过捕获更丰富的信息（例如自然语言的树结构，文本中的大跨度单词关系，文档主题等）来改进用于文本分类的RNN和LSTM模型。</p>\n<p>Tai等[15]已经开发了Tree-LSTM模型，将LSTM推广到树结构网络类型，以学习丰富的语义表示。作者认为，针对自然语言处理任务，Tree-LSTM比链结构LSTM更好，因为自然语言具有句法属性，可以自然地将单词和短语组合在一起。他们在两个任务上验证了Tree-LSTM的有效性：情感分类和预测两个句子的语义相关性。这些模型的架构如图3所示。 [16]通过使用存储单元在递归过程中存储多个子单元或多个后代单元的历史将chain-structured LSTM展到树状结构。他们认为，新模型提供了一种原则上的方法，可以考虑在层次结构（例如语言或图像解析结构）上进行长距离交互。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430103448.png\" alt=\"\"></p>\n<p>为了对机器学习的大跨度单词关系进行建模，Cheng等人[17]用一个存储网络代替单个存储单元来增强LSTM体系结构。这可以在神经注意力复发期间启用自适应内存使用，从而提供一种弱化标记之间关系的方法。 该模型在语言建模，情感分析和NLI上取得了可喜的结果。</p>\n<p>多时标LSTM（MT-LSTM）神经网络[18]被设计为通过捕获具有不同时标的有价值的信息来对长文本（例如句子和文档）建模。MT-LSTM将标准LSTM模型的隐藏状态分为几组。 每个组在不同的时间段被激活和更新。 因此，MT-LSTM可以对很长的文档进行建模。MT-LSTM在文本分类方面优于包括基于LSTM和RNN的模型在内的基准。</p>\n<p>RNN擅长捕获单词序列的局部结构，但是面对远距离依赖关系会有点力不从心。相反，潜在主题模型（latent topic models）能够捕获文档的全局语义结构，但不考虑单词顺序。Bieng等 [19]提出了TopicRNN模型，以整合RNN和潜在主题模型的优点。 它使用RNN捕获局部（语法）依赖性，并使用潜在主题捕获全局（语义）依赖性。 TopicRNN在情感分析方面优于RNN基线。</p>\n<p>还有其他有趣的基于RNN的模型。 刘等[20]使用多任务学习来训练RNN，以利用来自多个相关任务的标记训练数据。Johnson和Rie [21]探索了使用LSTM的文本区域嵌入方法。周等 [22]集成了双向LSTM（Bi-LSTM）模型和二维最大池来捕获文本特征。Wang等[23]提出了在“matching-aggregation”框架下的双边多视角匹配模型。  Wan等[24]使用双向LSMT模型生成的多个位置句子表示来探索语义匹配。</p>\n<h3 id=\"2-3-基于CNN的模型\"><a href=\"#2-3-基于CNN的模型\" class=\"headerlink\" title=\"2.3 基于CNN的模型\"></a>2.3 基于CNN的模型</h3><p>训练RNN识别跨时间的模式，而CNN学会识别跨空间的模式[25]。在需要理解远程语义的POS标签或QA等NLP任务中，RNN效果很好，而在检测局部和位置不变模式很重要的情况下，CNN效果很好。这些模式可能是表达特定情绪（例如“我喜欢”）或主题（例如“濒危物种”）的关键短语。 因此，CNN已成为最受欢迎的文本分类模型体系结构之一。</p>\n<p>Kalchbrenner等人提出了最早的基于CNN的文本分类模型之一[26]。 该模型使用动态k-max池，称为动态CNN（DCNN）。如图4所示，DCNN的第一层使用对句子中每个单词的嵌入来构造句子矩阵。 然后使用将宽卷积层与动态k-max池给定的动态池层交替的卷积体系结构来生成句子的特征映射，该特征映射能够显式捕获单词和短语的短时和长时关系。可以根据句子大小和卷积层次结构的级别来动态选择池化参数k。</p>\n<p>后来，Kim [27]提出了一种比DCNN简单得多的基于CNN的模型，用于文本分类。 如图5所示，Kim的模型仅在从无监督神经语言模型（即word2vec）获得的单词向量上使用一层卷积。Kim还比较了四种学习单词嵌入的方法：</p>\n<ul>\n<li>CNN-rand，其中所有单词嵌入都在训练过程中被随机初始化，然后进行修改</li>\n<li>CNN-static，在模型训练期间使用预训练的word2vec嵌入并保持固定</li>\n<li>CNN-non-static，其中word2vec嵌入在针对每个任务的训练过程中进行了微调</li>\n<li>CNN-multi-channel，其中使用了两组词嵌入向量集，都使用word2vec进行了初始化，其中一个在模型训练期间进行了更新，而另一个则在固定的情况下进行了更新。</li>\n</ul>\n<p>这些基于CNN的模型将改进情感分析和问题分类的SOTA。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164349.png\" alt=\"\"></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164600.png\" alt=\"\"></p>\n<p>[26，27]已经做出了一些努力来改进基于CNN模型的体系结构。刘等[28]提出了一种新的基于CNN的模型，该模型对TextCNN [27]的体系结构进行了两次修改。首先，采用动态最大池化方案来从文档的不同区域捕获更多细粒度的特征。其次，在池化层和输出层之间插入一个隐藏的瓶颈层（bottleneck layer）学习紧凑的文档表示形式，以减小模型大小并提高模型性能。在[29，30]中，作者没有使用预先训练的低维词向量作为CNN的输入，而是直接将CNN应用于高维文本数据，以学习小文本区域的嵌入进行分类。</p>\n<p>字符级的CNN也已经被用于文本分类[31，32]。Zhang等人提出了最早的此类模型之一[31]。如图6所示，该模型以固定大小的字符作为输入，将其编码为一个one-hot向量，然后将它们通过一个深CNN模型，该模型由具有池化操作的六个卷积层和三个全连接层组成。Prusa等[33]提出了一种使用CNN编码文本的方法，该方法大大减少了学习字符级文本表示所需的内存消耗和训练时间。此方法可根据字母大小很好地缩放，从而可以保留原始文本中的更多信息以增强分类性能</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164852.png\" alt=\"\"></p>\n<p>有研究调查词嵌入和CNN架构对模型性能的影响。受到VGG [34]和ResNets [35]的启发，Conneau等人 [36]提出了一种非常深的CNN（VDCNN）模型用于文本处理。它直接在字符级别上操作，并且仅使用小的卷积和池化操作。 研究表明，VDCNN的性能随着深度的增加而增加。杜克等[37]修改了VDCNN的结构，以适应移动平台的限制并保持性能。他们能够将模型大小压缩10倍至20倍，而精度损失在0.4％至1.3％之间。Le等[38]表明，当文本输入表示为字符序列时，深层模型确实优于浅层模型。但是，一个简单的浅层和广域网络在词输入方面胜过DenseNet [39]等深层模型。郭等[40]研究了词嵌入的影响，并提出通过多通道CNN模型使用加权词嵌入。张等[41]研究了不同词嵌入方法和池化机制的影响，发现使用非静态word2vec和GloVe优于one-hot向量，并且最大池化始终优于其他池化方法。</p>\n<p>还有其他有趣的基于CNN的模型。Mou等[42]提出了一种基于树的CNN来捕获句子级语义。庞等[43]将文本匹配转换为图像识别任务，并使用多层CNN识别显著n-gram模式。Wang等[44]提出了一种基于CNN的模型，该模型结合了短文本的显式和隐式表示形式进行分类。 将CNN应用于生物医学文本分类的兴趣也越来越高[45-48]。</p>\n<h3 id=\"2-4-胶囊网络\"><a href=\"#2-4-胶囊网络\" class=\"headerlink\" title=\"2.4 胶囊网络\"></a>2.4 胶囊网络</h3><p>CNN通过使用连续的卷积和池化层对图像或文本进行分类。 尽管池化操作可识别显著特征并降低卷积操作的计算复杂性，但它们会丢失有关空间关系的信息，并可能根据其方向或比例对实体进行错误分类</p>\n<p>为了解决池化带来的问题，Geoffrey Hinton提出了一种新方法，称为胶囊网络（CapsNets）[49，50]。一个胶囊是一组神经元，其活动向量代表特定类型的实体（例如对象或对象部分）的不同属性。向量的长度代表实体存在的概率，向量的方向代表实体的属性。与CNN的最大池化（选择一些信息并丢弃其余信息）不同，胶囊使用网络中直到最后一层的所有可用信息，将底层的每个胶囊“路由”到上层最匹配的父胶囊。可以使用不同的算法来实现路由，例如协议动态路由[50]或EM算法[51]。</p>\n<p>近来，胶囊网络已经被应用于文本分类，其中胶囊适于将句子或文档表示为向量。  [52–54]提出了一种基于CapsNets变体的文本分类模型。该模型由四层组成：（1）n-gram卷积层，（2）胶囊层，（3）卷积胶囊层，以及（4）完全连接的胶囊层。 作者尝试了三种策略来稳定动态路由过程，以减轻包含背景信息（例如停用词或与任何文档类别无关的词）的噪声包的干扰。 他们还探索了两种胶囊架构，如图7所示。分别为Capsule-A和Capsule-B。Capsule-A与[50]中的CapsNet类似。  Capsule-B使用三个并行网络，并在n-gram卷积层中使用具有不同窗口大小的过滤器，以学习更全面的文本表示形式。  CapsNet-B在实验中表现更好。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165324.png\" alt=\"\"></p>\n<p>Kim等人提出的基于CapsNet的模型[55]使用类似的架构。 该模型包括（1）一个输入层，该输入层将文档作为单词嵌入的序列；（2）卷积层，生成特征图并使用门控线性单元保留空间信息；（3）卷积胶囊层，通过聚合卷积层检测到的局部特征形成整体特征；（4）文本胶囊层以预测类标签。作者观察到，相比于图像，对象可以更自由地组合在文本中。 例如，即使某些句子的顺序改变了，文档的语义也可以保持不变，这与人脸上的眼睛和鼻子的位置不同。 因此，他们使用静态路由方案，该方案始终优于动态路由[50]进行文本分类。Aly等[56]提议使用CapsNets进行分层多标签分类（HMC），认为CapsNet编码子代关系的能力使其比传统方法更好地解决了HMC任务，在HMC任务中，文档被分配了一个或多个分类标签，这些标签被组织在一个层次结构。 他们模型的架构类似于[52，53，55]中的架构。任等人 [57]提出了CapsNets的另一种变体，它使用了胶囊之间的成分编码机制和基于k-means聚类的新路由算法。 首先，使用codebooks中的所有 codeword vectors 形成单词嵌入。 然后，通过k均值路由将下层胶囊捕获的特征汇总到高层胶囊中。</p>\n<h3 id=\"2-5-基于注意力机制模型\"><a href=\"#2-5-基于注意力机制模型\" class=\"headerlink\" title=\"2.5 基于注意力机制模型\"></a>2.5 基于注意力机制模型</h3><p>在开发用于NLP的深度学习模型时，注意力已成为越来越流行的概念和有用的工具[58，59]。 简而言之，语言模型中的注意力可被解释为重要权重的向量。 为了预测句子中的单词，我们使用注意力向量来估计它与其他单词的相关性或“与之相关”的程度，然后将注意力向量加权的值之和作为目标的近似值</p>\n<p>本节回顾了一些最突出的注意力模型，这些模型在发布时就在文本分类任务上取得了SOTA。</p>\n<p>杨等[60]提出了一种用于文本分类的分层注意力网络。 该模型具有两个鲜明的特征：（1）反映文档的层次结构的层次结构，（2）在单词和句子级别上应用的两个级别的注意力机制，使它能够在构建文档表示形式时以不同的方式参加重要或不重要的内容。 在六个文本分类任务上，该模型大大优于以前的方法。周等[61]将分层注意力模型扩展到跨语言情感分类。 在每种语言中，都使用LSTM网络对文档进行建模。 然后，通过使用分层注意机制实现分类，其中句子级别的注意模型了解文档的哪些句子对于确定总体情绪更重要。 而词级注意力模型则学习每个句子中哪些词具有决定性。</p>\n<p>沉等[62]提出了一种定向自我注意网络，用于无RNN / CNN语言理解，其中来自输入序列的元素之间的注意力是定向的和多维的。 轻量级神经网络仅基于所提出的注意力而无需任何RNN / CNN结构即可用于学习句子嵌入。刘等[63]提出了一个具有inner-attention的LSTM模型,用来做NLI任务。 该模型使用两阶段过程对句子进行编码。 首先，在词级Bi-LSTM上使用平均池化以生成第一阶段句子表示。 其次，采用注意力机制来代替同一句子的平均池，以获得更好的表示。 句子的第一阶段表示法用于出现在句子中的单词。</p>\n<p>注意模型也广泛应用于成对排序（pair-wise ranking）或匹配任务。  Santos等[64]提出了一种双向注意机制，称为Attentive Pooling（AP），用于成对排名。  AP可以使池化层知道当前的输入对（例如，问题-答案对），以使两个输入项的信息可以直接影响彼此表示的计算。 除了学习输入对的表示之外，AP联合学习该对投影段的相似性度量，然后为每个输入导出相应的注意力向量以指导池化。  AP是独立于底层表示学习的通用框架，并且可以应用于CNN和RNN，如图8（a）所示。Wang等[65]将文本分类视为标签-单词匹配问题：每个标签与单词向量一起嵌入相同的空间。作者介绍了一种注意力框架，该框架通过余弦相似性来度量文本序列和标签之间嵌入的兼容性，如图8（b）所示。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165837.png\" alt=\"\"></p>\n<p>Kim等[66]提出了一种使用密集连接的循环共同注意力网络的语义句子匹配方法。 类似于DenseNet [39]，该模型的每一层都使用所有先前的递归层的注意特征以及隐藏特征的级联信息。它可以保留从最底层单词嵌入层到最上层循环层的原始和共同注意特征信息。Yin等[67]提出了另一种基于注意力的CNN模型，用于句子对匹配。 他们提出了三种将句子之间的相互影响整合到CNN中的注意力方案，以便每个句子的表示都考虑到其成对的句子。 这些相互依赖的句子对表示形式比孤立的句子表示形式更为强大，这在包括答案选择，复述识别和文本蕴涵在内的多个分类任务中得到了验证。Tan等[68]在匹配聚合框架下采用了多种注意函数来匹配句子对。 杨等。  [69]介绍了一种基于注意力的神经匹配模型，用于对简短答案文本进行排名。 他们采用价值共享加权方案代替位置共享加权方案来组合不同的匹配信号，并使用问题关注网络将问题术语重要性学习纳入其中。 该模型在TREC QA数据集上取得了可喜的结果。</p>\n<p>还有其他有趣的注意力模型。  Lin等[70]使用自注意力来提取可解释的句子嵌入。  Wang等[71]提出了一种具有多尺度特征关注度的紧密连接的CNN，以产生可变的n-gram特征。  Yamada和Shindo [72] 使用neural attentive bag-of-entities 模型（使用知识库中的实体）进行文本分类。  Parikh等。  [73]使用注意力将问题分解为可以单独解决的子问题。  Chen等[74]探索了通用的池化方法来增强句子嵌入，并提出了一个基于向量的多头注意力模型。  Liu和Lane [75]提出了一种基于注意力的RNN模型，用于联合意图检测和空缺填充。</p>\n<h3 id=\"2-6-记忆增强网络\"><a href=\"#2-6-记忆增强网络\" class=\"headerlink\" title=\"2.6 记忆增强网络\"></a>2.6 记忆增强网络</h3><p>注意力模型在编码过程中存储的隐藏向量可以看作是模型内部记忆，而记忆增强网络则将神经网络与外部记忆结合在一起，模型可以对其进行读写。</p>\n<p>Munkhdalai和Yu[76]提出了一种记忆增强的神经网络，称为神经语义编码器（NSE），用于文本分类和QA。  NSE配备了一个可变大小的编码记忆，该编码记忆会随着时间的推移而发展，并通过读取，编写和写入操作保持对输入序列的理解，如图9所示。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200503113637.png\" alt=\"\"></p>\n<p>韦斯顿等[77]设计了一个用于综合QA任务的记忆网络，在该网络中，向模型提供了一系列语句（记忆记录），作为问题的支持事实。 该模型会根据问题和先前检索到的记忆来一次从记忆中检索一个条目。Sukhbaatar等[78]扩展了这项工作，并提出了端到端的记忆网络，在记忆网络中以柔和的方式利用注意力机制检索记忆条目，从而实现了端到端的训练。 他们表明，通过多次回合（跳数），该模型能够检索并推理几个支持事实，以回答特定问题。</p>\n<p>Kumar等[79]提出了一种动态记忆方法（DMN），它处理输入序列和问题，形成情节记忆，并产生相关的答案。 问题触发迭代注意进程，该进程允许模型将注意条件设置为输入和先前迭代的结果。 然后，在分层递归序列模型中对这些结果进行推理以生成答案。 对DMN进行端到端训练，并获得有关QA和POS标记的最新结果。 熊等[80]提出了DMN的详细分析，并改进了其就医和输入模块。</p>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>基于深度学习的模型已经在各种文本分类任务中超过了经典的基于机器学的方法，例如情感分析，新闻分类，问答以及自然语言处理。在这次工作中，我们对近些年开发的150多种基于深度学习的文本分类模型进行了详尽的回顾，讨论了他们的技术贡献，相似点以及优点。我们还对广泛应用于文本分类的40多个流行数据集进行了总结。最后，我们对不同的深度学习模型在<strong>流行基准</strong>上的性能进行了定量分析。</p>\n<h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><p>文本分类是自然语言处理中的一个经典问题，旨在为文本单元（例如句子，<strong>询问</strong>，段落和文档）分配标签。文本分类有十分广泛的应用，例如问答，垃圾邮件检测，情感分析，新闻分类，用户意图识别，内容审核等等。文本数据可以来自不同的数据源，例如网页数据，邮件，聊天，社交媒体，机票，保险理赔，用户评论，客户服务中的问题和解答等等。文本中含有极其丰富的信息，但由于它的非结构化特征，想要从中提取信息便极具挑战和耗时。</p>\n<p>文本分类可以通过人工标注和自动标注两种方式进行，随着工业应用中文本数据规模不断增大，自动文本分类变得越来越重要。自动文本分类的方法可以被分为3类：</p>\n<ul>\n<li>基于规则的方法</li>\n<li>基于机器学习的方法（数据驱动）</li>\n<li>混合方法</li>\n</ul>\n<p>基于规则的方法使用一组预定义的规则将文本分为不同的类别。例如，所有包含“足球”，”篮球“或者”棒球“的文档都被标记为”运动“标签。</p>\n<h3 id=\"2-用于文本分类的深度学习模型\"><a href=\"#2-用于文本分类的深度学习模型\" class=\"headerlink\" title=\"2 用于文本分类的深度学习模型\"></a>2 用于文本分类的深度学习模型</h3><p>在这个部分，我们回顾了针对各种文本分类问题提出的150多种深度学习框架。为了更易于遵循，我们根据模型的主要架构贡献将其分为以下类别：</p>\n<ul>\n<li>基于前馈网络的模型，该模型将文本视为一堆单词（a bag of words）（第2.1节）</li>\n<li>基于RNN的模型，该模型将文本视为单词序列，旨在捕获单词相关性和文本结构（第2.2节）</li>\n<li>基于CNN的模型，经过训练可识别文本中的模式（例如关键短语）以进行分类（第2.3节）</li>\n<li>胶囊网络(Capsule networks)解决了CNN的池化操作所带来的信息丢失问题，最近已应用于文本分类（第2.4节）</li>\n<li>注意机制(Attention mechanism)可有效识别文本中的相关单词，并已成为开发深度学习模型的有用工具（第2.5节）</li>\n<li>记忆增强网络(Memory-augmented networks)，将神经网络与外部记忆形式结合在一起，模型可以从中读取和写入（第2.6节）</li>\n<li>Transformers，允许比RNN更多的并行化，因此可以使用GPU集群有效地（预）训练非常大的语言模型（第2.7节）</li>\n<li>图神经网络(Graph neural networks)，旨在捕获自然语言的内部图结构，例如句法和语义解析树（第2.8节）</li>\n<li>孪生神经网络(Siamese Neural Networks)，用于文本匹配，文本匹配是文本分类的一种特殊情况（第2.9节）</li>\n<li>混合模型(Hybrid models)，结合注意力，RNN，CNN等模型来捕获句子和文档的局部和全局特征（第2.10节）</li>\n<li>最后，在2.11节中，我们回顾了有监督学习之外的建模技术，包括使用自动编码器(Autoencoder)和对抗训练(Adversarial training)的无监督学习(Unsupervised learning)，以及强化学习(Reinforcement learning)</li>\n</ul>\n<h3 id=\"2-1-前馈神经网络\"><a href=\"#2-1-前馈神经网络\" class=\"headerlink\" title=\"2.1 前馈神经网络\"></a>2.1 前馈神经网络</h3><p>前馈网络是用于文本表示的最简单的深度学习模型之一。但是，它们已经在许多文本分类基准上达到了很高的准确性。 这些模型将文本视为一堆单词。对于每个单词，他们使用诸如word2vec [8]或Glove [9]之类的嵌入模型学习向量表示，将嵌入向量的和或平均值作为文本的表示，将其通过一个或多个前馈层，称为多层感知器（MLP），然后使用诸如逻辑回归、朴素贝叶斯或SVM等分类器对最终层的表示进行分类[10]。一个例子如深度平均网络（Deep Average Network，DAN）[10]，其体系结构如图1所示。尽管简单，但DAN却胜过了其他更复杂的模型，这些模型旨在显式地学习文本的组成。例如，DAN在语法差异较大的数据集上的表现优于语法模型。Joulin等[11]提出了一种简单而有效的文本分类器，称为fastText。 像DAN一样，fastText将文本视为一堆单词，与DAN不同的是，fastText使用n-gram作为附加特征来捕获局部单词顺序信息。 事实证明，这在实践中非常有效，同时可达到与显式使用单词顺序的方法[12]相当的结果。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200428171503.png\" alt=\"\"></p>\n<p>Le和Mikolov [13]提出了doc2vec，它使用一种无监督算法来学习可变长度文本（例如句子，段落和文档）的定长特征表示。如图2所示，doc2vec的体系结构类似于连续词袋（CBOW）模型的体系结构[8，14]。唯一的区别是附加的段落标记通过矩阵D映射到段落向量。在doc2vec中，此向量与三个单词的上下文的连接或平均值用于预测第四个单词。 段落向量表示当前上下文中丢失的信息，可以用作该段落的主题记忆。经过训练后，段落向量将用作段落的特征并送入分类器进行预测。  Doc2vec在发布时，在一些文本分类和情感分析任务上获得了最优结果。</p>\n<h3 id=\"2-2-基于RNN的模型\"><a href=\"#2-2-基于RNN的模型\" class=\"headerlink\" title=\"2.2 基于RNN的模型\"></a>2.2 基于RNN的模型</h3><p>基于RNN的模型将文本视为一系列单词，旨在捕获单词依赖性和文本结构以进行文本分类。但是，普通的RNN(vanilla RNN)模型不能很好地工作，并且通常表现不如前馈神经网络。 在RNN的许多变体中，长短期记忆网络（LSTM）是最受欢迎的结构，旨在更好地捕获长期依赖关系。LSTM通过引入存储单元以记住任意时间间隔的值以及三个门（输入门，输出门，遗忘门）来调节信息的流动，从而解决了普通RNN遇到的梯度消失或爆炸问题。已经有工作通过捕获更丰富的信息（例如自然语言的树结构，文本中的大跨度单词关系，文档主题等）来改进用于文本分类的RNN和LSTM模型。</p>\n<p>Tai等[15]已经开发了Tree-LSTM模型，将LSTM推广到树结构网络类型，以学习丰富的语义表示。作者认为，针对自然语言处理任务，Tree-LSTM比链结构LSTM更好，因为自然语言具有句法属性，可以自然地将单词和短语组合在一起。他们在两个任务上验证了Tree-LSTM的有效性：情感分类和预测两个句子的语义相关性。这些模型的架构如图3所示。 [16]通过使用存储单元在递归过程中存储多个子单元或多个后代单元的历史将chain-structured LSTM展到树状结构。他们认为，新模型提供了一种原则上的方法，可以考虑在层次结构（例如语言或图像解析结构）上进行长距离交互。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430103448.png\" alt=\"\"></p>\n<p>为了对机器学习的大跨度单词关系进行建模，Cheng等人[17]用一个存储网络代替单个存储单元来增强LSTM体系结构。这可以在神经注意力复发期间启用自适应内存使用，从而提供一种弱化标记之间关系的方法。 该模型在语言建模，情感分析和NLI上取得了可喜的结果。</p>\n<p>多时标LSTM（MT-LSTM）神经网络[18]被设计为通过捕获具有不同时标的有价值的信息来对长文本（例如句子和文档）建模。MT-LSTM将标准LSTM模型的隐藏状态分为几组。 每个组在不同的时间段被激活和更新。 因此，MT-LSTM可以对很长的文档进行建模。MT-LSTM在文本分类方面优于包括基于LSTM和RNN的模型在内的基准。</p>\n<p>RNN擅长捕获单词序列的局部结构，但是面对远距离依赖关系会有点力不从心。相反，潜在主题模型（latent topic models）能够捕获文档的全局语义结构，但不考虑单词顺序。Bieng等 [19]提出了TopicRNN模型，以整合RNN和潜在主题模型的优点。 它使用RNN捕获局部（语法）依赖性，并使用潜在主题捕获全局（语义）依赖性。 TopicRNN在情感分析方面优于RNN基线。</p>\n<p>还有其他有趣的基于RNN的模型。 刘等[20]使用多任务学习来训练RNN，以利用来自多个相关任务的标记训练数据。Johnson和Rie [21]探索了使用LSTM的文本区域嵌入方法。周等 [22]集成了双向LSTM（Bi-LSTM）模型和二维最大池来捕获文本特征。Wang等[23]提出了在“matching-aggregation”框架下的双边多视角匹配模型。  Wan等[24]使用双向LSMT模型生成的多个位置句子表示来探索语义匹配。</p>\n<h3 id=\"2-3-基于CNN的模型\"><a href=\"#2-3-基于CNN的模型\" class=\"headerlink\" title=\"2.3 基于CNN的模型\"></a>2.3 基于CNN的模型</h3><p>训练RNN识别跨时间的模式，而CNN学会识别跨空间的模式[25]。在需要理解远程语义的POS标签或QA等NLP任务中，RNN效果很好，而在检测局部和位置不变模式很重要的情况下，CNN效果很好。这些模式可能是表达特定情绪（例如“我喜欢”）或主题（例如“濒危物种”）的关键短语。 因此，CNN已成为最受欢迎的文本分类模型体系结构之一。</p>\n<p>Kalchbrenner等人提出了最早的基于CNN的文本分类模型之一[26]。 该模型使用动态k-max池，称为动态CNN（DCNN）。如图4所示，DCNN的第一层使用对句子中每个单词的嵌入来构造句子矩阵。 然后使用将宽卷积层与动态k-max池给定的动态池层交替的卷积体系结构来生成句子的特征映射，该特征映射能够显式捕获单词和短语的短时和长时关系。可以根据句子大小和卷积层次结构的级别来动态选择池化参数k。</p>\n<p>后来，Kim [27]提出了一种比DCNN简单得多的基于CNN的模型，用于文本分类。 如图5所示，Kim的模型仅在从无监督神经语言模型（即word2vec）获得的单词向量上使用一层卷积。Kim还比较了四种学习单词嵌入的方法：</p>\n<ul>\n<li>CNN-rand，其中所有单词嵌入都在训练过程中被随机初始化，然后进行修改</li>\n<li>CNN-static，在模型训练期间使用预训练的word2vec嵌入并保持固定</li>\n<li>CNN-non-static，其中word2vec嵌入在针对每个任务的训练过程中进行了微调</li>\n<li>CNN-multi-channel，其中使用了两组词嵌入向量集，都使用word2vec进行了初始化，其中一个在模型训练期间进行了更新，而另一个则在固定的情况下进行了更新。</li>\n</ul>\n<p>这些基于CNN的模型将改进情感分析和问题分类的SOTA。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164349.png\" alt=\"\"></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164600.png\" alt=\"\"></p>\n<p>[26，27]已经做出了一些努力来改进基于CNN模型的体系结构。刘等[28]提出了一种新的基于CNN的模型，该模型对TextCNN [27]的体系结构进行了两次修改。首先，采用动态最大池化方案来从文档的不同区域捕获更多细粒度的特征。其次，在池化层和输出层之间插入一个隐藏的瓶颈层（bottleneck layer）学习紧凑的文档表示形式，以减小模型大小并提高模型性能。在[29，30]中，作者没有使用预先训练的低维词向量作为CNN的输入，而是直接将CNN应用于高维文本数据，以学习小文本区域的嵌入进行分类。</p>\n<p>字符级的CNN也已经被用于文本分类[31，32]。Zhang等人提出了最早的此类模型之一[31]。如图6所示，该模型以固定大小的字符作为输入，将其编码为一个one-hot向量，然后将它们通过一个深CNN模型，该模型由具有池化操作的六个卷积层和三个全连接层组成。Prusa等[33]提出了一种使用CNN编码文本的方法，该方法大大减少了学习字符级文本表示所需的内存消耗和训练时间。此方法可根据字母大小很好地缩放，从而可以保留原始文本中的更多信息以增强分类性能</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502164852.png\" alt=\"\"></p>\n<p>有研究调查词嵌入和CNN架构对模型性能的影响。受到VGG [34]和ResNets [35]的启发，Conneau等人 [36]提出了一种非常深的CNN（VDCNN）模型用于文本处理。它直接在字符级别上操作，并且仅使用小的卷积和池化操作。 研究表明，VDCNN的性能随着深度的增加而增加。杜克等[37]修改了VDCNN的结构，以适应移动平台的限制并保持性能。他们能够将模型大小压缩10倍至20倍，而精度损失在0.4％至1.3％之间。Le等[38]表明，当文本输入表示为字符序列时，深层模型确实优于浅层模型。但是，一个简单的浅层和广域网络在词输入方面胜过DenseNet [39]等深层模型。郭等[40]研究了词嵌入的影响，并提出通过多通道CNN模型使用加权词嵌入。张等[41]研究了不同词嵌入方法和池化机制的影响，发现使用非静态word2vec和GloVe优于one-hot向量，并且最大池化始终优于其他池化方法。</p>\n<p>还有其他有趣的基于CNN的模型。Mou等[42]提出了一种基于树的CNN来捕获句子级语义。庞等[43]将文本匹配转换为图像识别任务，并使用多层CNN识别显著n-gram模式。Wang等[44]提出了一种基于CNN的模型，该模型结合了短文本的显式和隐式表示形式进行分类。 将CNN应用于生物医学文本分类的兴趣也越来越高[45-48]。</p>\n<h3 id=\"2-4-胶囊网络\"><a href=\"#2-4-胶囊网络\" class=\"headerlink\" title=\"2.4 胶囊网络\"></a>2.4 胶囊网络</h3><p>CNN通过使用连续的卷积和池化层对图像或文本进行分类。 尽管池化操作可识别显著特征并降低卷积操作的计算复杂性，但它们会丢失有关空间关系的信息，并可能根据其方向或比例对实体进行错误分类</p>\n<p>为了解决池化带来的问题，Geoffrey Hinton提出了一种新方法，称为胶囊网络（CapsNets）[49，50]。一个胶囊是一组神经元，其活动向量代表特定类型的实体（例如对象或对象部分）的不同属性。向量的长度代表实体存在的概率，向量的方向代表实体的属性。与CNN的最大池化（选择一些信息并丢弃其余信息）不同，胶囊使用网络中直到最后一层的所有可用信息，将底层的每个胶囊“路由”到上层最匹配的父胶囊。可以使用不同的算法来实现路由，例如协议动态路由[50]或EM算法[51]。</p>\n<p>近来，胶囊网络已经被应用于文本分类，其中胶囊适于将句子或文档表示为向量。  [52–54]提出了一种基于CapsNets变体的文本分类模型。该模型由四层组成：（1）n-gram卷积层，（2）胶囊层，（3）卷积胶囊层，以及（4）完全连接的胶囊层。 作者尝试了三种策略来稳定动态路由过程，以减轻包含背景信息（例如停用词或与任何文档类别无关的词）的噪声包的干扰。 他们还探索了两种胶囊架构，如图7所示。分别为Capsule-A和Capsule-B。Capsule-A与[50]中的CapsNet类似。  Capsule-B使用三个并行网络，并在n-gram卷积层中使用具有不同窗口大小的过滤器，以学习更全面的文本表示形式。  CapsNet-B在实验中表现更好。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165324.png\" alt=\"\"></p>\n<p>Kim等人提出的基于CapsNet的模型[55]使用类似的架构。 该模型包括（1）一个输入层，该输入层将文档作为单词嵌入的序列；（2）卷积层，生成特征图并使用门控线性单元保留空间信息；（3）卷积胶囊层，通过聚合卷积层检测到的局部特征形成整体特征；（4）文本胶囊层以预测类标签。作者观察到，相比于图像，对象可以更自由地组合在文本中。 例如，即使某些句子的顺序改变了，文档的语义也可以保持不变，这与人脸上的眼睛和鼻子的位置不同。 因此，他们使用静态路由方案，该方案始终优于动态路由[50]进行文本分类。Aly等[56]提议使用CapsNets进行分层多标签分类（HMC），认为CapsNet编码子代关系的能力使其比传统方法更好地解决了HMC任务，在HMC任务中，文档被分配了一个或多个分类标签，这些标签被组织在一个层次结构。 他们模型的架构类似于[52，53，55]中的架构。任等人 [57]提出了CapsNets的另一种变体，它使用了胶囊之间的成分编码机制和基于k-means聚类的新路由算法。 首先，使用codebooks中的所有 codeword vectors 形成单词嵌入。 然后，通过k均值路由将下层胶囊捕获的特征汇总到高层胶囊中。</p>\n<h3 id=\"2-5-基于注意力机制模型\"><a href=\"#2-5-基于注意力机制模型\" class=\"headerlink\" title=\"2.5 基于注意力机制模型\"></a>2.5 基于注意力机制模型</h3><p>在开发用于NLP的深度学习模型时，注意力已成为越来越流行的概念和有用的工具[58，59]。 简而言之，语言模型中的注意力可被解释为重要权重的向量。 为了预测句子中的单词，我们使用注意力向量来估计它与其他单词的相关性或“与之相关”的程度，然后将注意力向量加权的值之和作为目标的近似值</p>\n<p>本节回顾了一些最突出的注意力模型，这些模型在发布时就在文本分类任务上取得了SOTA。</p>\n<p>杨等[60]提出了一种用于文本分类的分层注意力网络。 该模型具有两个鲜明的特征：（1）反映文档的层次结构的层次结构，（2）在单词和句子级别上应用的两个级别的注意力机制，使它能够在构建文档表示形式时以不同的方式参加重要或不重要的内容。 在六个文本分类任务上，该模型大大优于以前的方法。周等[61]将分层注意力模型扩展到跨语言情感分类。 在每种语言中，都使用LSTM网络对文档进行建模。 然后，通过使用分层注意机制实现分类，其中句子级别的注意模型了解文档的哪些句子对于确定总体情绪更重要。 而词级注意力模型则学习每个句子中哪些词具有决定性。</p>\n<p>沉等[62]提出了一种定向自我注意网络，用于无RNN / CNN语言理解，其中来自输入序列的元素之间的注意力是定向的和多维的。 轻量级神经网络仅基于所提出的注意力而无需任何RNN / CNN结构即可用于学习句子嵌入。刘等[63]提出了一个具有inner-attention的LSTM模型,用来做NLI任务。 该模型使用两阶段过程对句子进行编码。 首先，在词级Bi-LSTM上使用平均池化以生成第一阶段句子表示。 其次，采用注意力机制来代替同一句子的平均池，以获得更好的表示。 句子的第一阶段表示法用于出现在句子中的单词。</p>\n<p>注意模型也广泛应用于成对排序（pair-wise ranking）或匹配任务。  Santos等[64]提出了一种双向注意机制，称为Attentive Pooling（AP），用于成对排名。  AP可以使池化层知道当前的输入对（例如，问题-答案对），以使两个输入项的信息可以直接影响彼此表示的计算。 除了学习输入对的表示之外，AP联合学习该对投影段的相似性度量，然后为每个输入导出相应的注意力向量以指导池化。  AP是独立于底层表示学习的通用框架，并且可以应用于CNN和RNN，如图8（a）所示。Wang等[65]将文本分类视为标签-单词匹配问题：每个标签与单词向量一起嵌入相同的空间。作者介绍了一种注意力框架，该框架通过余弦相似性来度量文本序列和标签之间嵌入的兼容性，如图8（b）所示。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200502165837.png\" alt=\"\"></p>\n<p>Kim等[66]提出了一种使用密集连接的循环共同注意力网络的语义句子匹配方法。 类似于DenseNet [39]，该模型的每一层都使用所有先前的递归层的注意特征以及隐藏特征的级联信息。它可以保留从最底层单词嵌入层到最上层循环层的原始和共同注意特征信息。Yin等[67]提出了另一种基于注意力的CNN模型，用于句子对匹配。 他们提出了三种将句子之间的相互影响整合到CNN中的注意力方案，以便每个句子的表示都考虑到其成对的句子。 这些相互依赖的句子对表示形式比孤立的句子表示形式更为强大，这在包括答案选择，复述识别和文本蕴涵在内的多个分类任务中得到了验证。Tan等[68]在匹配聚合框架下采用了多种注意函数来匹配句子对。 杨等。  [69]介绍了一种基于注意力的神经匹配模型，用于对简短答案文本进行排名。 他们采用价值共享加权方案代替位置共享加权方案来组合不同的匹配信号，并使用问题关注网络将问题术语重要性学习纳入其中。 该模型在TREC QA数据集上取得了可喜的结果。</p>\n<p>还有其他有趣的注意力模型。  Lin等[70]使用自注意力来提取可解释的句子嵌入。  Wang等[71]提出了一种具有多尺度特征关注度的紧密连接的CNN，以产生可变的n-gram特征。  Yamada和Shindo [72] 使用neural attentive bag-of-entities 模型（使用知识库中的实体）进行文本分类。  Parikh等。  [73]使用注意力将问题分解为可以单独解决的子问题。  Chen等[74]探索了通用的池化方法来增强句子嵌入，并提出了一个基于向量的多头注意力模型。  Liu和Lane [75]提出了一种基于注意力的RNN模型，用于联合意图检测和空缺填充。</p>\n<h3 id=\"2-6-记忆增强网络\"><a href=\"#2-6-记忆增强网络\" class=\"headerlink\" title=\"2.6 记忆增强网络\"></a>2.6 记忆增强网络</h3><p>注意力模型在编码过程中存储的隐藏向量可以看作是模型内部记忆，而记忆增强网络则将神经网络与外部记忆结合在一起，模型可以对其进行读写。</p>\n<p>Munkhdalai和Yu[76]提出了一种记忆增强的神经网络，称为神经语义编码器（NSE），用于文本分类和QA。  NSE配备了一个可变大小的编码记忆，该编码记忆会随着时间的推移而发展，并通过读取，编写和写入操作保持对输入序列的理解，如图9所示。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200503113637.png\" alt=\"\"></p>\n<p>韦斯顿等[77]设计了一个用于综合QA任务的记忆网络，在该网络中，向模型提供了一系列语句（记忆记录），作为问题的支持事实。 该模型会根据问题和先前检索到的记忆来一次从记忆中检索一个条目。Sukhbaatar等[78]扩展了这项工作，并提出了端到端的记忆网络，在记忆网络中以柔和的方式利用注意力机制检索记忆条目，从而实现了端到端的训练。 他们表明，通过多次回合（跳数），该模型能够检索并推理几个支持事实，以回答特定问题。</p>\n<p>Kumar等[79]提出了一种动态记忆方法（DMN），它处理输入序列和问题，形成情节记忆，并产生相关的答案。 问题触发迭代注意进程，该进程允许模型将注意条件设置为输入和先前迭代的结果。 然后，在分层递归序列模型中对这些结果进行推理以生成答案。 对DMN进行端到端训练，并获得有关QA和POS标记的最新结果。 熊等[80]提出了DMN的详细分析，并改进了其就医和输入模块。</p>\n"},{"title":"胶囊网络","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-05-01T08:32:06.000Z","password":null,"img":null,"summary":null,"keywords":"胶囊网络","_content":"","source":"_posts/胶囊网络.md","raw":"---\ntitle: 胶囊网络\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-05-01 16:32:06\npassword:\nimg:\nsummary:\ncategories: 深度学习\nkeywords: 胶囊网络\ntags:\n\t- 胶囊网络\n\t- Capsule Networks\n---\n","slug":"胶囊网络","published":1,"updated":"2020-05-17T13:26:07.367Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqy7000ngswj0zsedcbi","content":"","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"了不起的盖茨比","top":false,"cover":true,"toc":true,"mathjax":true,"date":"2020-04-11T02:34:01.000Z","password":null,"summary":null,"img":"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/2020-04-11 11-53-25.jpg","keywords":"了不起的盖茨比","_content":"\n&emsp;&emsp;盖茨比——一个可怜、可爱、可敬勇士。\n\n&emsp;&emsp;盖茨比的了不起，千金散尽博红颜笑，纸醉金迷为心中念。盖茨比本人是极其单纯的，出生不好，却仰望星空，渴望走出大山走向世界；出生不好，却爱上豪门爱女，命运捉弄赶赴战场；出生不好，却怀有梦想，他未来的每一步都在向那个女孩靠近。尼克说，他们所有人加起来都比不上你，是的，一个如此痴情一步一步走来怀有美好梦想并一步一步践行的人，他们是比不上的，纵然尼克知道，盖茨比的梦已经渐行渐远。在城堡里盖茨比对尼克说“你对过去的理解是错的”，那时尼克笑了笑，没有说话，盖茨比苦涩一笑，重复了一句“是错的”。尼克或许从那时开始认识到眼前的这个人和其他人是不一样的。盖茨比一直追寻的或许从来不是什么黛西，他爱着黛西，追寻着黛西，却在这之上追寻着更多或许不切实际的东西。就像尼克说的，如果盖茨比要求的只是拥黛西入怀，或许一切都不一样。最终，盖茨比终究还是带着伟大的美好的梦想一起破灭了，他等的电话没等到，他的葬礼，黛西没有来，甚至没有一束花，名门望流不见踪影，只有尼克——他唯一的朋友。尼克很庆幸，庆幸自己当面称赞了盖茨比。\n\n> ​\t\tI offer you whatever insight my books may hold. \n>\n> ​\t\tI offer you the loyalty of a man who has never been loyal. \n>\n> ​\t\tI offer you that kernel of myself that I have saved somehow – the central heart that deals not in words, traffics not with dreams and is untouched by time, by joy, by adversities. \n>\n> ​\t\tI offer you the memory of a yellow rose seen at sunset, years before you were born. \n>\n> ​\t\tI offer you explanations of yourself, theories about yourself, authentic and surprising news of yourself. \n>\n> ​\t\tI can give you my loneliness my darkness, the hunger of my heart.\n>\n> ​\t\tI offer you everything I have, but you never came back.\n>\n> ​\t\tWhat can I hold you with?\n\n&emsp;&emsp;“美国梦”时代，纸醉金迷的享乐时代，尼克就是“美国梦”的一员，尼克帮人保守了两次秘密，第一次是汤姆邀请他参与的私人狂欢，在那儿他第一次尝试到了甜头，沉迷其中又置身事外，始终对其抱着一丝审视的心态，第二次是帮盖茨比保守秘密，不过稍有不同的是这次并没有沉迷其中，或者说这是盖茨比和汤姆的不同，就像汤姆对盖茨比说的“我们所有人都和你不一样，那是一种源自身体，源自血肉的不一样，我们流的血是不一样的”。的确，盖茨比所拥有的一切，所表现出来的种种行为迹象都是为了掩盖心里的伤疤，不过这并没有什么，他本就是如此，虽有欺骗，却也被大众认可，反观汤姆和黛西，一个花心出轨，为了自保漠视情人的遭遇，另一个也是出轨，肇事逃逸就罢了，最终盖茨比死后被盖上了原本是这两人的罪名，不求她为盖茨比做多大牺牲，盖茨比的葬礼，她一束花都没有，这太残忍了，是黄金时代造就了他们，还是本就如此？尼克生日那天，他说他失望透了，他当然失望了，他始终都是一个审视者，他怀抱梦想来到纽约，带着对这个城市的厌恶、恶心离去。\n\n&emsp;&emsp;文学的尽头都或多或少牵扯到虚无主义，《雪国》中驹子的遭遇也好，盖茨比的遭遇也好，都是理想与现实冲撞下的无可奈何的事实，梦，总是那么遥远，却又不可或缺，可远观不可亵玩。\n\n\n\n","source":"_posts/了不起的盖茨比.md","raw":"---\ntitle: 了不起的盖茨比\ntop: false\ncover: true\ntoc: true\nmathjax: true\ndate: 2020-04-11 10:34:01\npassword:\nsummary:\ntags: 影评\ncategories: 影评\nimg: https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/2020-04-11 11-53-25.jpg\nkeywords: 了不起的盖茨比\n---\n\n&emsp;&emsp;盖茨比——一个可怜、可爱、可敬勇士。\n\n&emsp;&emsp;盖茨比的了不起，千金散尽博红颜笑，纸醉金迷为心中念。盖茨比本人是极其单纯的，出生不好，却仰望星空，渴望走出大山走向世界；出生不好，却爱上豪门爱女，命运捉弄赶赴战场；出生不好，却怀有梦想，他未来的每一步都在向那个女孩靠近。尼克说，他们所有人加起来都比不上你，是的，一个如此痴情一步一步走来怀有美好梦想并一步一步践行的人，他们是比不上的，纵然尼克知道，盖茨比的梦已经渐行渐远。在城堡里盖茨比对尼克说“你对过去的理解是错的”，那时尼克笑了笑，没有说话，盖茨比苦涩一笑，重复了一句“是错的”。尼克或许从那时开始认识到眼前的这个人和其他人是不一样的。盖茨比一直追寻的或许从来不是什么黛西，他爱着黛西，追寻着黛西，却在这之上追寻着更多或许不切实际的东西。就像尼克说的，如果盖茨比要求的只是拥黛西入怀，或许一切都不一样。最终，盖茨比终究还是带着伟大的美好的梦想一起破灭了，他等的电话没等到，他的葬礼，黛西没有来，甚至没有一束花，名门望流不见踪影，只有尼克——他唯一的朋友。尼克很庆幸，庆幸自己当面称赞了盖茨比。\n\n> ​\t\tI offer you whatever insight my books may hold. \n>\n> ​\t\tI offer you the loyalty of a man who has never been loyal. \n>\n> ​\t\tI offer you that kernel of myself that I have saved somehow – the central heart that deals not in words, traffics not with dreams and is untouched by time, by joy, by adversities. \n>\n> ​\t\tI offer you the memory of a yellow rose seen at sunset, years before you were born. \n>\n> ​\t\tI offer you explanations of yourself, theories about yourself, authentic and surprising news of yourself. \n>\n> ​\t\tI can give you my loneliness my darkness, the hunger of my heart.\n>\n> ​\t\tI offer you everything I have, but you never came back.\n>\n> ​\t\tWhat can I hold you with?\n\n&emsp;&emsp;“美国梦”时代，纸醉金迷的享乐时代，尼克就是“美国梦”的一员，尼克帮人保守了两次秘密，第一次是汤姆邀请他参与的私人狂欢，在那儿他第一次尝试到了甜头，沉迷其中又置身事外，始终对其抱着一丝审视的心态，第二次是帮盖茨比保守秘密，不过稍有不同的是这次并没有沉迷其中，或者说这是盖茨比和汤姆的不同，就像汤姆对盖茨比说的“我们所有人都和你不一样，那是一种源自身体，源自血肉的不一样，我们流的血是不一样的”。的确，盖茨比所拥有的一切，所表现出来的种种行为迹象都是为了掩盖心里的伤疤，不过这并没有什么，他本就是如此，虽有欺骗，却也被大众认可，反观汤姆和黛西，一个花心出轨，为了自保漠视情人的遭遇，另一个也是出轨，肇事逃逸就罢了，最终盖茨比死后被盖上了原本是这两人的罪名，不求她为盖茨比做多大牺牲，盖茨比的葬礼，她一束花都没有，这太残忍了，是黄金时代造就了他们，还是本就如此？尼克生日那天，他说他失望透了，他当然失望了，他始终都是一个审视者，他怀抱梦想来到纽约，带着对这个城市的厌恶、恶心离去。\n\n&emsp;&emsp;文学的尽头都或多或少牵扯到虚无主义，《雪国》中驹子的遭遇也好，盖茨比的遭遇也好，都是理想与现实冲撞下的无可奈何的事实，梦，总是那么遥远，却又不可或缺，可远观不可亵玩。\n\n\n\n","slug":"了不起的盖茨比","published":1,"updated":"2020-05-17T11:29:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqya000sgswjem3tfp1u","content":"<p>&emsp;&emsp;盖茨比——一个可怜、可爱、可敬勇士。</p>\n<p>&emsp;&emsp;盖茨比的了不起，千金散尽博红颜笑，纸醉金迷为心中念。盖茨比本人是极其单纯的，出生不好，却仰望星空，渴望走出大山走向世界；出生不好，却爱上豪门爱女，命运捉弄赶赴战场；出生不好，却怀有梦想，他未来的每一步都在向那个女孩靠近。尼克说，他们所有人加起来都比不上你，是的，一个如此痴情一步一步走来怀有美好梦想并一步一步践行的人，他们是比不上的，纵然尼克知道，盖茨比的梦已经渐行渐远。在城堡里盖茨比对尼克说“你对过去的理解是错的”，那时尼克笑了笑，没有说话，盖茨比苦涩一笑，重复了一句“是错的”。尼克或许从那时开始认识到眼前的这个人和其他人是不一样的。盖茨比一直追寻的或许从来不是什么黛西，他爱着黛西，追寻着黛西，却在这之上追寻着更多或许不切实际的东西。就像尼克说的，如果盖茨比要求的只是拥黛西入怀，或许一切都不一样。最终，盖茨比终究还是带着伟大的美好的梦想一起破灭了，他等的电话没等到，他的葬礼，黛西没有来，甚至没有一束花，名门望流不见踪影，只有尼克——他唯一的朋友。尼克很庆幸，庆幸自己当面称赞了盖茨比。</p>\n<blockquote>\n<p>​        I offer you whatever insight my books may hold. </p>\n<p>​        I offer you the loyalty of a man who has never been loyal. </p>\n<p>​        I offer you that kernel of myself that I have saved somehow – the central heart that deals not in words, traffics not with dreams and is untouched by time, by joy, by adversities. </p>\n<p>​        I offer you the memory of a yellow rose seen at sunset, years before you were born. </p>\n<p>​        I offer you explanations of yourself, theories about yourself, authentic and surprising news of yourself. </p>\n<p>​        I can give you my loneliness my darkness, the hunger of my heart.</p>\n<p>​        I offer you everything I have, but you never came back.</p>\n<p>​        What can I hold you with?</p>\n</blockquote>\n<p>&emsp;&emsp;“美国梦”时代，纸醉金迷的享乐时代，尼克就是“美国梦”的一员，尼克帮人保守了两次秘密，第一次是汤姆邀请他参与的私人狂欢，在那儿他第一次尝试到了甜头，沉迷其中又置身事外，始终对其抱着一丝审视的心态，第二次是帮盖茨比保守秘密，不过稍有不同的是这次并没有沉迷其中，或者说这是盖茨比和汤姆的不同，就像汤姆对盖茨比说的“我们所有人都和你不一样，那是一种源自身体，源自血肉的不一样，我们流的血是不一样的”。的确，盖茨比所拥有的一切，所表现出来的种种行为迹象都是为了掩盖心里的伤疤，不过这并没有什么，他本就是如此，虽有欺骗，却也被大众认可，反观汤姆和黛西，一个花心出轨，为了自保漠视情人的遭遇，另一个也是出轨，肇事逃逸就罢了，最终盖茨比死后被盖上了原本是这两人的罪名，不求她为盖茨比做多大牺牲，盖茨比的葬礼，她一束花都没有，这太残忍了，是黄金时代造就了他们，还是本就如此？尼克生日那天，他说他失望透了，他当然失望了，他始终都是一个审视者，他怀抱梦想来到纽约，带着对这个城市的厌恶、恶心离去。</p>\n<p>&emsp;&emsp;文学的尽头都或多或少牵扯到虚无主义，《雪国》中驹子的遭遇也好，盖茨比的遭遇也好，都是理想与现实冲撞下的无可奈何的事实，梦，总是那么遥远，却又不可或缺，可远观不可亵玩。</p>\n","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>&emsp;&emsp;盖茨比——一个可怜、可爱、可敬勇士。</p>\n<p>&emsp;&emsp;盖茨比的了不起，千金散尽博红颜笑，纸醉金迷为心中念。盖茨比本人是极其单纯的，出生不好，却仰望星空，渴望走出大山走向世界；出生不好，却爱上豪门爱女，命运捉弄赶赴战场；出生不好，却怀有梦想，他未来的每一步都在向那个女孩靠近。尼克说，他们所有人加起来都比不上你，是的，一个如此痴情一步一步走来怀有美好梦想并一步一步践行的人，他们是比不上的，纵然尼克知道，盖茨比的梦已经渐行渐远。在城堡里盖茨比对尼克说“你对过去的理解是错的”，那时尼克笑了笑，没有说话，盖茨比苦涩一笑，重复了一句“是错的”。尼克或许从那时开始认识到眼前的这个人和其他人是不一样的。盖茨比一直追寻的或许从来不是什么黛西，他爱着黛西，追寻着黛西，却在这之上追寻着更多或许不切实际的东西。就像尼克说的，如果盖茨比要求的只是拥黛西入怀，或许一切都不一样。最终，盖茨比终究还是带着伟大的美好的梦想一起破灭了，他等的电话没等到，他的葬礼，黛西没有来，甚至没有一束花，名门望流不见踪影，只有尼克——他唯一的朋友。尼克很庆幸，庆幸自己当面称赞了盖茨比。</p>\n<blockquote>\n<p>​        I offer you whatever insight my books may hold. </p>\n<p>​        I offer you the loyalty of a man who has never been loyal. </p>\n<p>​        I offer you that kernel of myself that I have saved somehow – the central heart that deals not in words, traffics not with dreams and is untouched by time, by joy, by adversities. </p>\n<p>​        I offer you the memory of a yellow rose seen at sunset, years before you were born. </p>\n<p>​        I offer you explanations of yourself, theories about yourself, authentic and surprising news of yourself. </p>\n<p>​        I can give you my loneliness my darkness, the hunger of my heart.</p>\n<p>​        I offer you everything I have, but you never came back.</p>\n<p>​        What can I hold you with?</p>\n</blockquote>\n<p>&emsp;&emsp;“美国梦”时代，纸醉金迷的享乐时代，尼克就是“美国梦”的一员，尼克帮人保守了两次秘密，第一次是汤姆邀请他参与的私人狂欢，在那儿他第一次尝试到了甜头，沉迷其中又置身事外，始终对其抱着一丝审视的心态，第二次是帮盖茨比保守秘密，不过稍有不同的是这次并没有沉迷其中，或者说这是盖茨比和汤姆的不同，就像汤姆对盖茨比说的“我们所有人都和你不一样，那是一种源自身体，源自血肉的不一样，我们流的血是不一样的”。的确，盖茨比所拥有的一切，所表现出来的种种行为迹象都是为了掩盖心里的伤疤，不过这并没有什么，他本就是如此，虽有欺骗，却也被大众认可，反观汤姆和黛西，一个花心出轨，为了自保漠视情人的遭遇，另一个也是出轨，肇事逃逸就罢了，最终盖茨比死后被盖上了原本是这两人的罪名，不求她为盖茨比做多大牺牲，盖茨比的葬礼，她一束花都没有，这太残忍了，是黄金时代造就了他们，还是本就如此？尼克生日那天，他说他失望透了，他当然失望了，他始终都是一个审视者，他怀抱梦想来到纽约，带着对这个城市的厌恶、恶心离去。</p>\n<p>&emsp;&emsp;文学的尽头都或多或少牵扯到虚无主义，《雪国》中驹子的遭遇也好，盖茨比的遭遇也好，都是理想与现实冲撞下的无可奈何的事实，梦，总是那么遥远，却又不可或缺，可远观不可亵玩。</p>\n"},{"title":"ubuntu1604 搭建Hadoop集群","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2020-04-30T08:28:34.000Z","password":null,"summary":null,"img":null,"keywords":"hadoop 集群","_content":"\n## 系统环境\n\n| 名称   | 版本                                                         |\n| ------ | ------------------------------------------------------------ |\n| Ununtu | 1604                                                         |\n| JDK    | [JDK8](https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html) |\n| Hadoop | [3.1.3](https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz) |\n\n下载JDK8和Hadoop3.1.3，放在ubuntu里Downloads文件夹下\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430165326.png)\n\n## 基本配置\n\n### 设置静态IP\n\n[ubuntu1604 设置静态IP](https://zhishuang.tk/2020/04/30/ubuntu1604-she-zhi-jing-tai-ip/)\n\n### 修改hostname\n\n执行命令`sudo gedit /etc/hostname`,修改hostname为master\n\n### 配置主机映射\n\n执行命令`ifconfig`获取IP地址\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504220459.png)\n\n执行命令`sudo gedit /etc/hosts`,添加映射关系，注意IP地址换成自己的\n\n```\n192.168.79.129\tmaster\n```\n\n### 关闭防火墙\n\n执行命名`sudo ufw disable`关闭防火墙\n\n### 配置SSH\n\n>Hadoop名称节点(NameNode)需要启动集群中所有机器的Hadoop守护进程，这个过 程需要通过SSH登录来实现。Hadoop并没有提供SSH输入密码登录的形式，因此，为 了能够顺利登录每台机器，需要将所有机器配置为名称节点可以无密码登录它们。\n\n#### 配置SSH的无密码登录\n\n安装openssh-server( 通常Linux系统会默认安装openssh的客户端软件openssh-client)，所以需要自己安装一下服务端。\n\n```\nsudo apt-get install openssh-server\n```\n\n在终端执行命令`ssh-keygen -t rsa`，然后一直回车，生成密钥。\n\n执行命令`ssh-copy-id localhost`，在提示信息中输入`yes`，然后输入本机密码\n\n执行命令`ssh localhost`，出现登录时间，说明ssh配置成功\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504234742.png)\n\n## 配置JAVA环境\n\n### 创建文件夹\n\n```bash\nsudo mkdir /usr/java\n```\n\n在/usr目录下创建文件夹java，我们将把JDK8解压到这个文件夹中\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430170954.png)\n\n### 解压JDK\n\n```bash\nsudo tar -zxvf ~/Downloads/jdk-8u251-linux-x64.tar.gz -C /usr/java\n```\n\n解压jdk8到/usr/java目录下\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430171614.png)\n\n### 配置环境变量\n\n执行`sudo gedit /etc/profile`命令打开配置文件，在末尾添加以下几行文字，注意自己的jdk版本号。\n\n```\n#set java env\nexport JAVA_HOME=/usr/java/jdk1.8.0_251\nexport JRE_HOME=${JAVA_HOME}/jre    \nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib    \nexport PATH=${JAVA_HOME}/bin:$PATH\n```\n\n执行`source /etc/profile`命令让配置文件生效\n\n执行`java -version`命令验证是否配置成功\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430173142.png)\n\n## 配置Hadoop环境\n\n### 解压Hadoop\n\n将我们下载的Hadoop解压到 /usr/local/ 中\n\n```\nsudo tar -zxvf ~/Downloads/hadoop-3.1.3.tar.gz -C /usr/local\n```\n\n利用`cd /usr/local/`命令切换操作空间，将文件夹名改为hadoop\n\n```\nsudo mv ./hadoop-3.1.3/ ./hadoop\n```\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430174115.png)\n\n### 配置Hadoop环境变量\n\n执行`sudo gedit /etc/profile`命令打开配置文件,添加下面的语句\n\n```\n#set Hadoop env\nHADOOP_HOME=/usr/local/hadoop\nexport PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH\n```\n\n执行`source /etc/profile`命令让配置文件生效\n\n### 修改Hadoop配置文件\n\n执行`sudo gedit hadoop-env.sh`命令打开配置文件，添加语句`export JAVA_HOME=/usr/java/jdk1.8.0_251`\n\n执行`hadoop version`命令验证是否配置成功\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430183459.png)\n\n到这儿 我们Hadoop的单机模式配置完成\n\n## Hadoop伪分布式安装配置\n\n>Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的 Java 进程来运行，节点既作为 NameNode也作为DataNode， 同时，读取的是 HDFS 中的文件\n>\n>Hadoop的配置文件位于$HADOOP_HOME/etc/hadoop/中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml\n>\n>Hadoop的配置文件是xml格式，每个配置以声明property的name和value的方式来实现\n\n### hadoop 目录说明\n\n>修改配置文件之前，先看一下hadoop下的目录：\n>\n>- bin：hadoop最基本的管理脚本和使用脚本所在目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用hadoop\n>- etc：配置文件存放的目录，包括core-site.xml,hdfs-site.xml,mapred-site.xml等从hadoop1.x继承而来的配置文件和yarn-site.xml等hadoop2.x新增的配置文件\n>- include：对外提供的编程库头文件（具体动态库和静态库在lib目录中，这些头文件军事用c++定义的，通常用于c++程序访问hdfs或者编写mapreduce程序）\n>- Lib：该目录包含了hadoop对外提供的才变成动态库和静态库，与include目录中的头文件结合使用\n>- libexec：各个服务对应的shell配置文件所在目录，可用于配置日志输出目录、启动参数等信息\n>- sbin：hadoop管理脚本所在目录，主要包含hdfs和yarn中各类服务的启动、关闭脚本\n>- share：hadoop各个模块编译后的jar包所在目录。\n\n### 修改配置文件\t\n\n在 `/usr/local/hadoop/etc/hadoop/`目录下，执行命令`sudo gedit core-site.xml`，修改配置文件core-site.xml，内容如下：\n\n```\n<configuration> \n <property>\n      <name>hadoop.tmp.dir</name> \n      <value>file:/usr/local/hadoop/tmp</value>\n      <description>Abase for other temporary directories.</description>\n </property> \n <property>\n   <name>fs.defaultFS</name>\n   <value>hdfs://localhost:9000</value> \n  </property>\n</configuration>\n```\n\n- hadoop.tmp.dir表示存放临时数据的目录，即包括NameNode的数据，也包 括DataNode的数据。该路径任意指定，只要实际存在该文件夹即可\n- name为fs.defaultFS的值，表示hdfs路径的逻辑名称\n\n在 `/usr/local/hadoop/etc/hadoop/`目录下，执行命令`sudo gedit hdfs-site.xml`，修改配置文件hdfs-site.xml，内容如下：\n\n```\n<configuration> \n   <property>\n       <name>dfs.replication</name>\n       <value>1</value> \n   </property> \n   <property>\n       <name>dfs.namenode.name.dir</name>\n       <value>file:/usr/local/hadoop/tmp/dfs/name</value> \n    </property>\n   <property>\n       <name>dfs.datanode.data.dir</name>         \n       <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n   </property>\n</configuration>\n```\n\n- dfs.replication表示副本的数量，伪分布式要设置为1\n- dfs.namenode.name.dir表示本地磁盘目录，是存储fsimage文件的地方\n- dfs.datanode.data.dir表示本地磁盘目录，HDFS数据存放block的地方\n\n### 启动HDFS\t\n\n第一次启动时需要执行 `hdfs namenode - format`格式化节点\n\n执行`start-all.sh`启动HDFS及相关服务，执行`jps`命令，出现以下6个线程说配置成功：\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504235929.png)\n\n进一步确认，可以浏览器访问`localhost:9870`和`localhost:8088`\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000709.png)\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000753.png)\n\n## 配置Hadoop集群\n\n先从master克隆两个虚拟机，分别命名为slave1和slave2。配置方案如下：\n\n|      | master                | slave1                         | slave2                          |\n| ---- | --------------------- | ------------------------------ | ------------------------------- |\n| HDFS | NameNode<br/>DataNode | SecondaryNameNode<br/>DataNode | DataNode                        |\n| YARN | NodeManager           | NodeManager                    | ResourceManager<br/>NodeManager |\n\n### IP，主机名，主机映射配置\n\n#### slave1和slave2配置\n\n执行`sudo gedit /etc/network/interfaces`命令打开网络配置文件，修改slave1的IP为192.168.79.130，修改slave2的IP为192.168.79.131\n\n执行`sudo gedit /etc/hostname`命令，修改slave1的hostname为slave1，修改slave2的hostname为slave2\n\n执行`sudo gedit /etc/hosts`配置主机映射，添加下列语句：\n\n```\n#192.168.79.129\tmaster#这条已经存在，不用添加\n192.168.79.130\tslave1\n192.168.79.131\tslave2\n```\n\n注意，上面的配置需要分别在slave1和slave2上执行，配置结束之后执行`reboot`重启主机\n\n#### master配置\n\n执行`sudo gedit /etc/hosts`配置主机映射，添加下列语句\n\n```\n192.168.79.130\tslave1\n192.168.79.131\tslave2\n```\n\n### 免密配置\n\n免密配置需要保证三台主机之间都能互相免密登录，**三台主机**都需要**执行**下面的命令\n\n```\nssh-keygen -t rsa    //前面配置过则不需要\nssh-copy-id master    //将公钥文件发送给包括自身在内的3台服务器\nssh-copy-id slave1\nssh-copy-id slave2\n\nssh master    //连接其他服务器看还是否需要密码，三台服务器之间都不需要则配置成功\nssh slave1\nssh slave2\n```\n\n### 配置Hadoop配置文件\n\n**在master中配置好后再分发给slave1和slave2**\n\n执行`cd /usr/local/hadoop/etc/hadoop/`进入配置文件所在的文件夹\n\n执行`sudo gedit core-site.xml`打开配置文件，配置如下：\n\n```\n<configuration> \n <property>\n      <name>hadoop.tmp.dir</name> \n      <value>file:/usr/local/hadoop/tmp</value>\n      <description>Abase for other temporary directories.</description>\n </property>\n<!-- 指定NameNode的地址 --> \n <property>\n   <name>fs.defaultFS</name>\n   <value>hdfs://master:9000</value> \n </property>\n</configuration>\n```\n\n执行`sudo gedit hdfs-site.xml`打开配置文件，配置如下：\n\n```\n<configuration> \n   <!-- 指定冗余度 -->\n   <property>\n       <name>dfs.replication</name>\n       <value>3</value> \n   </property>\n   <!-- 指定NameNode数据的存储目录 --> \n   <property>\n       <name>dfs.namenode.name.dir</name>\n       <value>file:/usr/local/hadoop/tmp/dfs/name</value> \n   </property>\n   <!-- 指定Datanode数据的存储目录 -->\n   <property>\n       <name>dfs.datanode.data.dir</name>         \n       <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n   </property>\n   <!-- 设置secondarynamenode -->\n   <property>\n        <name>dfs.namenode.secondary.http-address</name>\n        <value>slave1:50090</value>\n   </property>\n</configuration>\n```\n\n执行`sudo gedit yarn-site.xml`打开配置文件，配置如下：\n\n```\n<configuration>\n   <!--指定mapreduce走shuffle -->\n   <property>\n        <name>yarn.nodemanager.aux-services</name>\n        <value>mapreduce_shuffle</value>\n   </property>\n   <!-- 指定ResourceManager的地址-->\n   <property>\n        <name>yarn.resourcemanager.hostname</name>\n        <value>slave2</value>\n   </property>\n</configuration>\n```\n\n执行`sudo gedit mapred-site.xml`打开配置文件，配置如下：\n\n```\n<configuration>\n<!-- 指定mapreduce运行在yarn上 -->\n<property>\n        <name>mapreduce.framework.name</name>\n        <value>yarn</value>\n</property>\n</configuration>\n```\n\n执行`sudo gedit workers`打开配置文件，配置如下：\n\n```\nmaster\nslave1\nslave2\n```\n\n将配置好的文件分发给slave1和slave2\n\n```\nscp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/\n```\n\n### 启动集群\n\n首次运行之前需要格式化namenode，如果首次运行失败后又重新进行了部分配置，运行之前最好也格式化namenode，格式化namenode之前需要删除hadoop目录下的data,logs以及/tmp目录下的hadoop开头的文件（在没有数据的情况下）\n\n* 在master主机上执行`hadoop namenode -format`命令格式化namenode\n\n* 在master主机上执行`start-dfs.sh`命令启动HDFS，如果正常启动：\n\t* 在master上执行`jps`命令可以看到有namenode，datanode\n\t* 在slave1上执行`jps`命令可以看到有secondarynamenode，datanode\n\t* 在slave2上执行`jps`命令可以看到有datanode\n* 因为resourcemanager部署在slave2上，所以在slave2上执行`start-yarn.sh`命令启动YARN，成功则：\n\t* 在master上执行`jps`命令可以看到有namenode，datanode，nodemanager\n\t* 在slave1上执行`jps`命令可以看到有secondarynamenode，datanode，nodemanager\n\t* 在slave2上执行`jps`命令可以看到有datanode，resourcemanager，nodemanager\n\n至此完成了集群的搭建\n\n## 查看集群\n\n打开`http://master:9870/`观测是否有三分datanode\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505191607.png)\n\n## 测试集群\n\n\n\n## 编写集群启动脚本\n\n为了方便启动集群和关闭集群，编写一个脚本，在master机器上执行`mkdir bin`命令在用户目录下创建`bin`目录，执行`gedit mycluster`命令创建并打开文件`mycluster`,在文件中添加下面的内容：\n\n```\n#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo \"No Args Input Error!!!!!\"\n   exit\nfi\ncase $1 in \n\"start\")\n   echo \"======================== start hdfs ========================== \"\n   ssh master \"source /etc/profile;start-dfs.sh\"\n   echo \"======================== start yarn ========================== \"\n   ssh slave2 \"source /etc/profile;start-yarn.sh\"\n;;\n\"stop\")\n   echo \"======================== stop yarn ========================== \"\n   ssh slave2 \"source /etc/profile;stop-yarn.sh\"\n   echo \"======================== stop hdfs ========================== \"\n   ssh master \"source /etc/profile;stop-dfs.sh\"\n;;\n*)\n  echo \"Input Args Error!!!!!\"\n;;\nesac\n```\n\n在`bin`目录下执行`gedit myjps`命令创建并打开文件`myjps`,在文件中添加下面的内容：\n\n```\n#!/bin/bash\nfor i in master slave1 slave2\ndo\n   echo \"====================== $i JPS =======================\"\n   ssh $i \"source /etc/profile;jps\"\ndone\n```\n\n执行`chmod 777 mycluster`和`chmod 777 myjps`命令修改脚本权限，之后只需要执行`mycluster start`即可启动集群。\n\n## 问题解决\n\n由于JAVA，Hadoop等环境变量配置在/etc/profile文件中，导致每次新打开一个命令窗口都要重新输入 source /etc/profile 才能使jdk等配置文件生效：\n\n解决方法：\n\n打开~/.bashrc 文件\n\n```\nsudo gedit ~/.bashrc\n```\n\n加入下列语句\n\n```\nsource /etc/profile\n```\n\n","source":"_posts/ubuntu1604-搭建Hadoop集群.md","raw":"---\ntitle: ubuntu1604 搭建Hadoop集群\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2020-04-30 16:28:34\npassword:\nsummary:\ncategories: 大数据\nimg:\nkeywords: hadoop 集群\ntags:\n\t- hadoop\n\t- 集群\n---\n\n## 系统环境\n\n| 名称   | 版本                                                         |\n| ------ | ------------------------------------------------------------ |\n| Ununtu | 1604                                                         |\n| JDK    | [JDK8](https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html) |\n| Hadoop | [3.1.3](https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz) |\n\n下载JDK8和Hadoop3.1.3，放在ubuntu里Downloads文件夹下\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430165326.png)\n\n## 基本配置\n\n### 设置静态IP\n\n[ubuntu1604 设置静态IP](https://zhishuang.tk/2020/04/30/ubuntu1604-she-zhi-jing-tai-ip/)\n\n### 修改hostname\n\n执行命令`sudo gedit /etc/hostname`,修改hostname为master\n\n### 配置主机映射\n\n执行命令`ifconfig`获取IP地址\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504220459.png)\n\n执行命令`sudo gedit /etc/hosts`,添加映射关系，注意IP地址换成自己的\n\n```\n192.168.79.129\tmaster\n```\n\n### 关闭防火墙\n\n执行命名`sudo ufw disable`关闭防火墙\n\n### 配置SSH\n\n>Hadoop名称节点(NameNode)需要启动集群中所有机器的Hadoop守护进程，这个过 程需要通过SSH登录来实现。Hadoop并没有提供SSH输入密码登录的形式，因此，为 了能够顺利登录每台机器，需要将所有机器配置为名称节点可以无密码登录它们。\n\n#### 配置SSH的无密码登录\n\n安装openssh-server( 通常Linux系统会默认安装openssh的客户端软件openssh-client)，所以需要自己安装一下服务端。\n\n```\nsudo apt-get install openssh-server\n```\n\n在终端执行命令`ssh-keygen -t rsa`，然后一直回车，生成密钥。\n\n执行命令`ssh-copy-id localhost`，在提示信息中输入`yes`，然后输入本机密码\n\n执行命令`ssh localhost`，出现登录时间，说明ssh配置成功\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504234742.png)\n\n## 配置JAVA环境\n\n### 创建文件夹\n\n```bash\nsudo mkdir /usr/java\n```\n\n在/usr目录下创建文件夹java，我们将把JDK8解压到这个文件夹中\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430170954.png)\n\n### 解压JDK\n\n```bash\nsudo tar -zxvf ~/Downloads/jdk-8u251-linux-x64.tar.gz -C /usr/java\n```\n\n解压jdk8到/usr/java目录下\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430171614.png)\n\n### 配置环境变量\n\n执行`sudo gedit /etc/profile`命令打开配置文件，在末尾添加以下几行文字，注意自己的jdk版本号。\n\n```\n#set java env\nexport JAVA_HOME=/usr/java/jdk1.8.0_251\nexport JRE_HOME=${JAVA_HOME}/jre    \nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib    \nexport PATH=${JAVA_HOME}/bin:$PATH\n```\n\n执行`source /etc/profile`命令让配置文件生效\n\n执行`java -version`命令验证是否配置成功\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430173142.png)\n\n## 配置Hadoop环境\n\n### 解压Hadoop\n\n将我们下载的Hadoop解压到 /usr/local/ 中\n\n```\nsudo tar -zxvf ~/Downloads/hadoop-3.1.3.tar.gz -C /usr/local\n```\n\n利用`cd /usr/local/`命令切换操作空间，将文件夹名改为hadoop\n\n```\nsudo mv ./hadoop-3.1.3/ ./hadoop\n```\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430174115.png)\n\n### 配置Hadoop环境变量\n\n执行`sudo gedit /etc/profile`命令打开配置文件,添加下面的语句\n\n```\n#set Hadoop env\nHADOOP_HOME=/usr/local/hadoop\nexport PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH\n```\n\n执行`source /etc/profile`命令让配置文件生效\n\n### 修改Hadoop配置文件\n\n执行`sudo gedit hadoop-env.sh`命令打开配置文件，添加语句`export JAVA_HOME=/usr/java/jdk1.8.0_251`\n\n执行`hadoop version`命令验证是否配置成功\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430183459.png)\n\n到这儿 我们Hadoop的单机模式配置完成\n\n## Hadoop伪分布式安装配置\n\n>Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的 Java 进程来运行，节点既作为 NameNode也作为DataNode， 同时，读取的是 HDFS 中的文件\n>\n>Hadoop的配置文件位于$HADOOP_HOME/etc/hadoop/中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml\n>\n>Hadoop的配置文件是xml格式，每个配置以声明property的name和value的方式来实现\n\n### hadoop 目录说明\n\n>修改配置文件之前，先看一下hadoop下的目录：\n>\n>- bin：hadoop最基本的管理脚本和使用脚本所在目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用hadoop\n>- etc：配置文件存放的目录，包括core-site.xml,hdfs-site.xml,mapred-site.xml等从hadoop1.x继承而来的配置文件和yarn-site.xml等hadoop2.x新增的配置文件\n>- include：对外提供的编程库头文件（具体动态库和静态库在lib目录中，这些头文件军事用c++定义的，通常用于c++程序访问hdfs或者编写mapreduce程序）\n>- Lib：该目录包含了hadoop对外提供的才变成动态库和静态库，与include目录中的头文件结合使用\n>- libexec：各个服务对应的shell配置文件所在目录，可用于配置日志输出目录、启动参数等信息\n>- sbin：hadoop管理脚本所在目录，主要包含hdfs和yarn中各类服务的启动、关闭脚本\n>- share：hadoop各个模块编译后的jar包所在目录。\n\n### 修改配置文件\t\n\n在 `/usr/local/hadoop/etc/hadoop/`目录下，执行命令`sudo gedit core-site.xml`，修改配置文件core-site.xml，内容如下：\n\n```\n<configuration> \n <property>\n      <name>hadoop.tmp.dir</name> \n      <value>file:/usr/local/hadoop/tmp</value>\n      <description>Abase for other temporary directories.</description>\n </property> \n <property>\n   <name>fs.defaultFS</name>\n   <value>hdfs://localhost:9000</value> \n  </property>\n</configuration>\n```\n\n- hadoop.tmp.dir表示存放临时数据的目录，即包括NameNode的数据，也包 括DataNode的数据。该路径任意指定，只要实际存在该文件夹即可\n- name为fs.defaultFS的值，表示hdfs路径的逻辑名称\n\n在 `/usr/local/hadoop/etc/hadoop/`目录下，执行命令`sudo gedit hdfs-site.xml`，修改配置文件hdfs-site.xml，内容如下：\n\n```\n<configuration> \n   <property>\n       <name>dfs.replication</name>\n       <value>1</value> \n   </property> \n   <property>\n       <name>dfs.namenode.name.dir</name>\n       <value>file:/usr/local/hadoop/tmp/dfs/name</value> \n    </property>\n   <property>\n       <name>dfs.datanode.data.dir</name>         \n       <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n   </property>\n</configuration>\n```\n\n- dfs.replication表示副本的数量，伪分布式要设置为1\n- dfs.namenode.name.dir表示本地磁盘目录，是存储fsimage文件的地方\n- dfs.datanode.data.dir表示本地磁盘目录，HDFS数据存放block的地方\n\n### 启动HDFS\t\n\n第一次启动时需要执行 `hdfs namenode - format`格式化节点\n\n执行`start-all.sh`启动HDFS及相关服务，执行`jps`命令，出现以下6个线程说配置成功：\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504235929.png)\n\n进一步确认，可以浏览器访问`localhost:9870`和`localhost:8088`\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000709.png)\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000753.png)\n\n## 配置Hadoop集群\n\n先从master克隆两个虚拟机，分别命名为slave1和slave2。配置方案如下：\n\n|      | master                | slave1                         | slave2                          |\n| ---- | --------------------- | ------------------------------ | ------------------------------- |\n| HDFS | NameNode<br/>DataNode | SecondaryNameNode<br/>DataNode | DataNode                        |\n| YARN | NodeManager           | NodeManager                    | ResourceManager<br/>NodeManager |\n\n### IP，主机名，主机映射配置\n\n#### slave1和slave2配置\n\n执行`sudo gedit /etc/network/interfaces`命令打开网络配置文件，修改slave1的IP为192.168.79.130，修改slave2的IP为192.168.79.131\n\n执行`sudo gedit /etc/hostname`命令，修改slave1的hostname为slave1，修改slave2的hostname为slave2\n\n执行`sudo gedit /etc/hosts`配置主机映射，添加下列语句：\n\n```\n#192.168.79.129\tmaster#这条已经存在，不用添加\n192.168.79.130\tslave1\n192.168.79.131\tslave2\n```\n\n注意，上面的配置需要分别在slave1和slave2上执行，配置结束之后执行`reboot`重启主机\n\n#### master配置\n\n执行`sudo gedit /etc/hosts`配置主机映射，添加下列语句\n\n```\n192.168.79.130\tslave1\n192.168.79.131\tslave2\n```\n\n### 免密配置\n\n免密配置需要保证三台主机之间都能互相免密登录，**三台主机**都需要**执行**下面的命令\n\n```\nssh-keygen -t rsa    //前面配置过则不需要\nssh-copy-id master    //将公钥文件发送给包括自身在内的3台服务器\nssh-copy-id slave1\nssh-copy-id slave2\n\nssh master    //连接其他服务器看还是否需要密码，三台服务器之间都不需要则配置成功\nssh slave1\nssh slave2\n```\n\n### 配置Hadoop配置文件\n\n**在master中配置好后再分发给slave1和slave2**\n\n执行`cd /usr/local/hadoop/etc/hadoop/`进入配置文件所在的文件夹\n\n执行`sudo gedit core-site.xml`打开配置文件，配置如下：\n\n```\n<configuration> \n <property>\n      <name>hadoop.tmp.dir</name> \n      <value>file:/usr/local/hadoop/tmp</value>\n      <description>Abase for other temporary directories.</description>\n </property>\n<!-- 指定NameNode的地址 --> \n <property>\n   <name>fs.defaultFS</name>\n   <value>hdfs://master:9000</value> \n </property>\n</configuration>\n```\n\n执行`sudo gedit hdfs-site.xml`打开配置文件，配置如下：\n\n```\n<configuration> \n   <!-- 指定冗余度 -->\n   <property>\n       <name>dfs.replication</name>\n       <value>3</value> \n   </property>\n   <!-- 指定NameNode数据的存储目录 --> \n   <property>\n       <name>dfs.namenode.name.dir</name>\n       <value>file:/usr/local/hadoop/tmp/dfs/name</value> \n   </property>\n   <!-- 指定Datanode数据的存储目录 -->\n   <property>\n       <name>dfs.datanode.data.dir</name>         \n       <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n   </property>\n   <!-- 设置secondarynamenode -->\n   <property>\n        <name>dfs.namenode.secondary.http-address</name>\n        <value>slave1:50090</value>\n   </property>\n</configuration>\n```\n\n执行`sudo gedit yarn-site.xml`打开配置文件，配置如下：\n\n```\n<configuration>\n   <!--指定mapreduce走shuffle -->\n   <property>\n        <name>yarn.nodemanager.aux-services</name>\n        <value>mapreduce_shuffle</value>\n   </property>\n   <!-- 指定ResourceManager的地址-->\n   <property>\n        <name>yarn.resourcemanager.hostname</name>\n        <value>slave2</value>\n   </property>\n</configuration>\n```\n\n执行`sudo gedit mapred-site.xml`打开配置文件，配置如下：\n\n```\n<configuration>\n<!-- 指定mapreduce运行在yarn上 -->\n<property>\n        <name>mapreduce.framework.name</name>\n        <value>yarn</value>\n</property>\n</configuration>\n```\n\n执行`sudo gedit workers`打开配置文件，配置如下：\n\n```\nmaster\nslave1\nslave2\n```\n\n将配置好的文件分发给slave1和slave2\n\n```\nscp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/\n```\n\n### 启动集群\n\n首次运行之前需要格式化namenode，如果首次运行失败后又重新进行了部分配置，运行之前最好也格式化namenode，格式化namenode之前需要删除hadoop目录下的data,logs以及/tmp目录下的hadoop开头的文件（在没有数据的情况下）\n\n* 在master主机上执行`hadoop namenode -format`命令格式化namenode\n\n* 在master主机上执行`start-dfs.sh`命令启动HDFS，如果正常启动：\n\t* 在master上执行`jps`命令可以看到有namenode，datanode\n\t* 在slave1上执行`jps`命令可以看到有secondarynamenode，datanode\n\t* 在slave2上执行`jps`命令可以看到有datanode\n* 因为resourcemanager部署在slave2上，所以在slave2上执行`start-yarn.sh`命令启动YARN，成功则：\n\t* 在master上执行`jps`命令可以看到有namenode，datanode，nodemanager\n\t* 在slave1上执行`jps`命令可以看到有secondarynamenode，datanode，nodemanager\n\t* 在slave2上执行`jps`命令可以看到有datanode，resourcemanager，nodemanager\n\n至此完成了集群的搭建\n\n## 查看集群\n\n打开`http://master:9870/`观测是否有三分datanode\n\n![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505191607.png)\n\n## 测试集群\n\n\n\n## 编写集群启动脚本\n\n为了方便启动集群和关闭集群，编写一个脚本，在master机器上执行`mkdir bin`命令在用户目录下创建`bin`目录，执行`gedit mycluster`命令创建并打开文件`mycluster`,在文件中添加下面的内容：\n\n```\n#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo \"No Args Input Error!!!!!\"\n   exit\nfi\ncase $1 in \n\"start\")\n   echo \"======================== start hdfs ========================== \"\n   ssh master \"source /etc/profile;start-dfs.sh\"\n   echo \"======================== start yarn ========================== \"\n   ssh slave2 \"source /etc/profile;start-yarn.sh\"\n;;\n\"stop\")\n   echo \"======================== stop yarn ========================== \"\n   ssh slave2 \"source /etc/profile;stop-yarn.sh\"\n   echo \"======================== stop hdfs ========================== \"\n   ssh master \"source /etc/profile;stop-dfs.sh\"\n;;\n*)\n  echo \"Input Args Error!!!!!\"\n;;\nesac\n```\n\n在`bin`目录下执行`gedit myjps`命令创建并打开文件`myjps`,在文件中添加下面的内容：\n\n```\n#!/bin/bash\nfor i in master slave1 slave2\ndo\n   echo \"====================== $i JPS =======================\"\n   ssh $i \"source /etc/profile;jps\"\ndone\n```\n\n执行`chmod 777 mycluster`和`chmod 777 myjps`命令修改脚本权限，之后只需要执行`mycluster start`即可启动集群。\n\n## 问题解决\n\n由于JAVA，Hadoop等环境变量配置在/etc/profile文件中，导致每次新打开一个命令窗口都要重新输入 source /etc/profile 才能使jdk等配置文件生效：\n\n解决方法：\n\n打开~/.bashrc 文件\n\n```\nsudo gedit ~/.bashrc\n```\n\n加入下列语句\n\n```\nsource /etc/profile\n```\n\n","slug":"ubuntu1604-搭建Hadoop集群","published":1,"updated":"2020-05-17T13:32:52.233Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckab3rqyb000ugswjdfm41zck","content":"<h2 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h2><table>\n<thead>\n<tr>\n<th>名称</th>\n<th>版本</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Ununtu</td>\n<td>1604</td>\n</tr>\n<tr>\n<td>JDK</td>\n<td><a href=\"https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html\" target=\"_blank\" rel=\"noopener\">JDK8</a></td>\n</tr>\n<tr>\n<td>Hadoop</td>\n<td><a href=\"https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz\" target=\"_blank\" rel=\"noopener\">3.1.3</a></td>\n</tr>\n</tbody></table>\n<p>下载JDK8和Hadoop3.1.3，放在ubuntu里Downloads文件夹下</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430165326.png\" alt=\"\"></p>\n<h2 id=\"基本配置\"><a href=\"#基本配置\" class=\"headerlink\" title=\"基本配置\"></a>基本配置</h2><h3 id=\"设置静态IP\"><a href=\"#设置静态IP\" class=\"headerlink\" title=\"设置静态IP\"></a>设置静态IP</h3><p><a href=\"https://zhishuang.tk/2020/04/30/ubuntu1604-she-zhi-jing-tai-ip/\">ubuntu1604 设置静态IP</a></p>\n<h3 id=\"修改hostname\"><a href=\"#修改hostname\" class=\"headerlink\" title=\"修改hostname\"></a>修改hostname</h3><p>执行命令<code>sudo gedit /etc/hostname</code>,修改hostname为master</p>\n<h3 id=\"配置主机映射\"><a href=\"#配置主机映射\" class=\"headerlink\" title=\"配置主机映射\"></a>配置主机映射</h3><p>执行命令<code>ifconfig</code>获取IP地址</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504220459.png\" alt=\"\"></p>\n<p>执行命令<code>sudo gedit /etc/hosts</code>,添加映射关系，注意IP地址换成自己的</p>\n<pre><code>192.168.79.129    master</code></pre><h3 id=\"关闭防火墙\"><a href=\"#关闭防火墙\" class=\"headerlink\" title=\"关闭防火墙\"></a>关闭防火墙</h3><p>执行命名<code>sudo ufw disable</code>关闭防火墙</p>\n<h3 id=\"配置SSH\"><a href=\"#配置SSH\" class=\"headerlink\" title=\"配置SSH\"></a>配置SSH</h3><blockquote>\n<p>Hadoop名称节点(NameNode)需要启动集群中所有机器的Hadoop守护进程，这个过 程需要通过SSH登录来实现。Hadoop并没有提供SSH输入密码登录的形式，因此，为 了能够顺利登录每台机器，需要将所有机器配置为名称节点可以无密码登录它们。</p>\n</blockquote>\n<h4 id=\"配置SSH的无密码登录\"><a href=\"#配置SSH的无密码登录\" class=\"headerlink\" title=\"配置SSH的无密码登录\"></a>配置SSH的无密码登录</h4><p>安装openssh-server( 通常Linux系统会默认安装openssh的客户端软件openssh-client)，所以需要自己安装一下服务端。</p>\n<pre><code>sudo apt-get install openssh-server</code></pre><p>在终端执行命令<code>ssh-keygen -t rsa</code>，然后一直回车，生成密钥。</p>\n<p>执行命令<code>ssh-copy-id localhost</code>，在提示信息中输入<code>yes</code>，然后输入本机密码</p>\n<p>执行命令<code>ssh localhost</code>，出现登录时间，说明ssh配置成功</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504234742.png\" alt=\"\"></p>\n<h2 id=\"配置JAVA环境\"><a href=\"#配置JAVA环境\" class=\"headerlink\" title=\"配置JAVA环境\"></a>配置JAVA环境</h2><h3 id=\"创建文件夹\"><a href=\"#创建文件夹\" class=\"headerlink\" title=\"创建文件夹\"></a>创建文件夹</h3><pre><code class=\"bash\">sudo mkdir /usr/java</code></pre>\n<p>在/usr目录下创建文件夹java，我们将把JDK8解压到这个文件夹中</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430170954.png\" alt=\"\"></p>\n<h3 id=\"解压JDK\"><a href=\"#解压JDK\" class=\"headerlink\" title=\"解压JDK\"></a>解压JDK</h3><pre><code class=\"bash\">sudo tar -zxvf ~/Downloads/jdk-8u251-linux-x64.tar.gz -C /usr/java</code></pre>\n<p>解压jdk8到/usr/java目录下</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430171614.png\" alt=\"\"></p>\n<h3 id=\"配置环境变量\"><a href=\"#配置环境变量\" class=\"headerlink\" title=\"配置环境变量\"></a>配置环境变量</h3><p>执行<code>sudo gedit /etc/profile</code>命令打开配置文件，在末尾添加以下几行文字，注意自己的jdk版本号。</p>\n<pre><code>#set java env\nexport JAVA_HOME=/usr/java/jdk1.8.0_251\nexport JRE_HOME=${JAVA_HOME}/jre    \nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib    \nexport PATH=${JAVA_HOME}/bin:$PATH</code></pre><p>执行<code>source /etc/profile</code>命令让配置文件生效</p>\n<p>执行<code>java -version</code>命令验证是否配置成功</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430173142.png\" alt=\"\"></p>\n<h2 id=\"配置Hadoop环境\"><a href=\"#配置Hadoop环境\" class=\"headerlink\" title=\"配置Hadoop环境\"></a>配置Hadoop环境</h2><h3 id=\"解压Hadoop\"><a href=\"#解压Hadoop\" class=\"headerlink\" title=\"解压Hadoop\"></a>解压Hadoop</h3><p>将我们下载的Hadoop解压到 /usr/local/ 中</p>\n<pre><code>sudo tar -zxvf ~/Downloads/hadoop-3.1.3.tar.gz -C /usr/local</code></pre><p>利用<code>cd /usr/local/</code>命令切换操作空间，将文件夹名改为hadoop</p>\n<pre><code>sudo mv ./hadoop-3.1.3/ ./hadoop</code></pre><p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430174115.png\" alt=\"\"></p>\n<h3 id=\"配置Hadoop环境变量\"><a href=\"#配置Hadoop环境变量\" class=\"headerlink\" title=\"配置Hadoop环境变量\"></a>配置Hadoop环境变量</h3><p>执行<code>sudo gedit /etc/profile</code>命令打开配置文件,添加下面的语句</p>\n<pre><code>#set Hadoop env\nHADOOP_HOME=/usr/local/hadoop\nexport PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH</code></pre><p>执行<code>source /etc/profile</code>命令让配置文件生效</p>\n<h3 id=\"修改Hadoop配置文件\"><a href=\"#修改Hadoop配置文件\" class=\"headerlink\" title=\"修改Hadoop配置文件\"></a>修改Hadoop配置文件</h3><p>执行<code>sudo gedit hadoop-env.sh</code>命令打开配置文件，添加语句<code>export JAVA_HOME=/usr/java/jdk1.8.0_251</code></p>\n<p>执行<code>hadoop version</code>命令验证是否配置成功</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430183459.png\" alt=\"\"></p>\n<p>到这儿 我们Hadoop的单机模式配置完成</p>\n<h2 id=\"Hadoop伪分布式安装配置\"><a href=\"#Hadoop伪分布式安装配置\" class=\"headerlink\" title=\"Hadoop伪分布式安装配置\"></a>Hadoop伪分布式安装配置</h2><blockquote>\n<p>Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的 Java 进程来运行，节点既作为 NameNode也作为DataNode， 同时，读取的是 HDFS 中的文件</p>\n<p>Hadoop的配置文件位于$HADOOP_HOME/etc/hadoop/中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml</p>\n<p>Hadoop的配置文件是xml格式，每个配置以声明property的name和value的方式来实现</p>\n</blockquote>\n<h3 id=\"hadoop-目录说明\"><a href=\"#hadoop-目录说明\" class=\"headerlink\" title=\"hadoop 目录说明\"></a>hadoop 目录说明</h3><blockquote>\n<p>修改配置文件之前，先看一下hadoop下的目录：</p>\n<ul>\n<li>bin：hadoop最基本的管理脚本和使用脚本所在目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用hadoop</li>\n<li>etc：配置文件存放的目录，包括core-site.xml,hdfs-site.xml,mapred-site.xml等从hadoop1.x继承而来的配置文件和yarn-site.xml等hadoop2.x新增的配置文件</li>\n<li>include：对外提供的编程库头文件（具体动态库和静态库在lib目录中，这些头文件军事用c++定义的，通常用于c++程序访问hdfs或者编写mapreduce程序）</li>\n<li>Lib：该目录包含了hadoop对外提供的才变成动态库和静态库，与include目录中的头文件结合使用</li>\n<li>libexec：各个服务对应的shell配置文件所在目录，可用于配置日志输出目录、启动参数等信息</li>\n<li>sbin：hadoop管理脚本所在目录，主要包含hdfs和yarn中各类服务的启动、关闭脚本</li>\n<li>share：hadoop各个模块编译后的jar包所在目录。</li>\n</ul>\n</blockquote>\n<h3 id=\"修改配置文件\"><a href=\"#修改配置文件\" class=\"headerlink\" title=\"修改配置文件\"></a>修改配置文件</h3><p>在 <code>/usr/local/hadoop/etc/hadoop/</code>目录下，执行命令<code>sudo gedit core-site.xml</code>，修改配置文件core-site.xml，内容如下：</p>\n<pre><code>&lt;configuration&gt; \n &lt;property&gt;\n      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; \n      &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;\n      &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;\n &lt;/property&gt; \n &lt;property&gt;\n   &lt;name&gt;fs.defaultFS&lt;/name&gt;\n   &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; \n  &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>hadoop.tmp.dir表示存放临时数据的目录，即包括NameNode的数据，也包 括DataNode的数据。该路径任意指定，只要实际存在该文件夹即可</li>\n<li>name为fs.defaultFS的值，表示hdfs路径的逻辑名称</li>\n</ul>\n<p>在 <code>/usr/local/hadoop/etc/hadoop/</code>目录下，执行命令<code>sudo gedit hdfs-site.xml</code>，修改配置文件hdfs-site.xml，内容如下：</p>\n<pre><code>&lt;configuration&gt; \n   &lt;property&gt;\n       &lt;name&gt;dfs.replication&lt;/name&gt;\n       &lt;value&gt;1&lt;/value&gt; \n   &lt;/property&gt; \n   &lt;property&gt;\n       &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; \n    &lt;/property&gt;\n   &lt;property&gt;\n       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;         \n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>dfs.replication表示副本的数量，伪分布式要设置为1</li>\n<li>dfs.namenode.name.dir表示本地磁盘目录，是存储fsimage文件的地方</li>\n<li>dfs.datanode.data.dir表示本地磁盘目录，HDFS数据存放block的地方</li>\n</ul>\n<h3 id=\"启动HDFS\"><a href=\"#启动HDFS\" class=\"headerlink\" title=\"启动HDFS\"></a>启动HDFS</h3><p>第一次启动时需要执行 <code>hdfs namenode - format</code>格式化节点</p>\n<p>执行<code>start-all.sh</code>启动HDFS及相关服务，执行<code>jps</code>命令，出现以下6个线程说配置成功：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504235929.png\" alt=\"\"></p>\n<p>进一步确认，可以浏览器访问<code>localhost:9870</code>和<code>localhost:8088</code></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000709.png\" alt=\"\"></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000753.png\" alt=\"\"></p>\n<h2 id=\"配置Hadoop集群\"><a href=\"#配置Hadoop集群\" class=\"headerlink\" title=\"配置Hadoop集群\"></a>配置Hadoop集群</h2><p>先从master克隆两个虚拟机，分别命名为slave1和slave2。配置方案如下：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>master</th>\n<th>slave1</th>\n<th>slave2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HDFS</td>\n<td>NameNode<br/>DataNode</td>\n<td>SecondaryNameNode<br/>DataNode</td>\n<td>DataNode</td>\n</tr>\n<tr>\n<td>YARN</td>\n<td>NodeManager</td>\n<td>NodeManager</td>\n<td>ResourceManager<br/>NodeManager</td>\n</tr>\n</tbody></table>\n<h3 id=\"IP，主机名，主机映射配置\"><a href=\"#IP，主机名，主机映射配置\" class=\"headerlink\" title=\"IP，主机名，主机映射配置\"></a>IP，主机名，主机映射配置</h3><h4 id=\"slave1和slave2配置\"><a href=\"#slave1和slave2配置\" class=\"headerlink\" title=\"slave1和slave2配置\"></a>slave1和slave2配置</h4><p>执行<code>sudo gedit /etc/network/interfaces</code>命令打开网络配置文件，修改slave1的IP为192.168.79.130，修改slave2的IP为192.168.79.131</p>\n<p>执行<code>sudo gedit /etc/hostname</code>命令，修改slave1的hostname为slave1，修改slave2的hostname为slave2</p>\n<p>执行<code>sudo gedit /etc/hosts</code>配置主机映射，添加下列语句：</p>\n<pre><code>#192.168.79.129    master#这条已经存在，不用添加\n192.168.79.130    slave1\n192.168.79.131    slave2</code></pre><p>注意，上面的配置需要分别在slave1和slave2上执行，配置结束之后执行<code>reboot</code>重启主机</p>\n<h4 id=\"master配置\"><a href=\"#master配置\" class=\"headerlink\" title=\"master配置\"></a>master配置</h4><p>执行<code>sudo gedit /etc/hosts</code>配置主机映射，添加下列语句</p>\n<pre><code>192.168.79.130    slave1\n192.168.79.131    slave2</code></pre><h3 id=\"免密配置\"><a href=\"#免密配置\" class=\"headerlink\" title=\"免密配置\"></a>免密配置</h3><p>免密配置需要保证三台主机之间都能互相免密登录，<strong>三台主机</strong>都需要<strong>执行</strong>下面的命令</p>\n<pre><code>ssh-keygen -t rsa    //前面配置过则不需要\nssh-copy-id master    //将公钥文件发送给包括自身在内的3台服务器\nssh-copy-id slave1\nssh-copy-id slave2\n\nssh master    //连接其他服务器看还是否需要密码，三台服务器之间都不需要则配置成功\nssh slave1\nssh slave2</code></pre><h3 id=\"配置Hadoop配置文件\"><a href=\"#配置Hadoop配置文件\" class=\"headerlink\" title=\"配置Hadoop配置文件\"></a>配置Hadoop配置文件</h3><p><strong>在master中配置好后再分发给slave1和slave2</strong></p>\n<p>执行<code>cd /usr/local/hadoop/etc/hadoop/</code>进入配置文件所在的文件夹</p>\n<p>执行<code>sudo gedit core-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt; \n &lt;property&gt;\n      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; \n      &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;\n      &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;\n &lt;/property&gt;\n&lt;!-- 指定NameNode的地址 --&gt; \n &lt;property&gt;\n   &lt;name&gt;fs.defaultFS&lt;/name&gt;\n   &lt;value&gt;hdfs://master:9000&lt;/value&gt; \n &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit hdfs-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt; \n   &lt;!-- 指定冗余度 --&gt;\n   &lt;property&gt;\n       &lt;name&gt;dfs.replication&lt;/name&gt;\n       &lt;value&gt;3&lt;/value&gt; \n   &lt;/property&gt;\n   &lt;!-- 指定NameNode数据的存储目录 --&gt; \n   &lt;property&gt;\n       &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; \n   &lt;/property&gt;\n   &lt;!-- 指定Datanode数据的存储目录 --&gt;\n   &lt;property&gt;\n       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;         \n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;\n   &lt;/property&gt;\n   &lt;!-- 设置secondarynamenode --&gt;\n   &lt;property&gt;\n        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n        &lt;value&gt;slave1:50090&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit yarn-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt;\n   &lt;!--指定mapreduce走shuffle --&gt;\n   &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n   &lt;/property&gt;\n   &lt;!-- 指定ResourceManager的地址--&gt;\n   &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n        &lt;value&gt;slave2&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit mapred-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt;\n&lt;!-- 指定mapreduce运行在yarn上 --&gt;\n&lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n        &lt;value&gt;yarn&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit workers</code>打开配置文件，配置如下：</p>\n<pre><code>master\nslave1\nslave2</code></pre><p>将配置好的文件分发给slave1和slave2</p>\n<pre><code>scp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/</code></pre><h3 id=\"启动集群\"><a href=\"#启动集群\" class=\"headerlink\" title=\"启动集群\"></a>启动集群</h3><p>首次运行之前需要格式化namenode，如果首次运行失败后又重新进行了部分配置，运行之前最好也格式化namenode，格式化namenode之前需要删除hadoop目录下的data,logs以及/tmp目录下的hadoop开头的文件（在没有数据的情况下）</p>\n<ul>\n<li><p>在master主机上执行<code>hadoop namenode -format</code>命令格式化namenode</p>\n</li>\n<li><p>在master主机上执行<code>start-dfs.sh</code>命令启动HDFS，如果正常启动：</p>\n<ul>\n<li>在master上执行<code>jps</code>命令可以看到有namenode，datanode</li>\n<li>在slave1上执行<code>jps</code>命令可以看到有secondarynamenode，datanode</li>\n<li>在slave2上执行<code>jps</code>命令可以看到有datanode</li>\n</ul>\n</li>\n<li><p>因为resourcemanager部署在slave2上，所以在slave2上执行<code>start-yarn.sh</code>命令启动YARN，成功则：</p>\n<ul>\n<li>在master上执行<code>jps</code>命令可以看到有namenode，datanode，nodemanager</li>\n<li>在slave1上执行<code>jps</code>命令可以看到有secondarynamenode，datanode，nodemanager</li>\n<li>在slave2上执行<code>jps</code>命令可以看到有datanode，resourcemanager，nodemanager</li>\n</ul>\n</li>\n</ul>\n<p>至此完成了集群的搭建</p>\n<h2 id=\"查看集群\"><a href=\"#查看集群\" class=\"headerlink\" title=\"查看集群\"></a>查看集群</h2><p>打开<code>http://master:9870/</code>观测是否有三分datanode</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505191607.png\" alt=\"\"></p>\n<h2 id=\"测试集群\"><a href=\"#测试集群\" class=\"headerlink\" title=\"测试集群\"></a>测试集群</h2><h2 id=\"编写集群启动脚本\"><a href=\"#编写集群启动脚本\" class=\"headerlink\" title=\"编写集群启动脚本\"></a>编写集群启动脚本</h2><p>为了方便启动集群和关闭集群，编写一个脚本，在master机器上执行<code>mkdir bin</code>命令在用户目录下创建<code>bin</code>目录，执行<code>gedit mycluster</code>命令创建并打开文件<code>mycluster</code>,在文件中添加下面的内容：</p>\n<pre><code>#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo &quot;No Args Input Error!!!!!&quot;\n   exit\nfi\ncase $1 in \n&quot;start&quot;)\n   echo &quot;======================== start hdfs ========================== &quot;\n   ssh master &quot;source /etc/profile;start-dfs.sh&quot;\n   echo &quot;======================== start yarn ========================== &quot;\n   ssh slave2 &quot;source /etc/profile;start-yarn.sh&quot;\n;;\n&quot;stop&quot;)\n   echo &quot;======================== stop yarn ========================== &quot;\n   ssh slave2 &quot;source /etc/profile;stop-yarn.sh&quot;\n   echo &quot;======================== stop hdfs ========================== &quot;\n   ssh master &quot;source /etc/profile;stop-dfs.sh&quot;\n;;\n*)\n  echo &quot;Input Args Error!!!!!&quot;\n;;\nesac</code></pre><p>在<code>bin</code>目录下执行<code>gedit myjps</code>命令创建并打开文件<code>myjps</code>,在文件中添加下面的内容：</p>\n<pre><code>#!/bin/bash\nfor i in master slave1 slave2\ndo\n   echo &quot;====================== $i JPS =======================&quot;\n   ssh $i &quot;source /etc/profile;jps&quot;\ndone</code></pre><p>执行<code>chmod 777 mycluster</code>和<code>chmod 777 myjps</code>命令修改脚本权限，之后只需要执行<code>mycluster start</code>即可启动集群。</p>\n<h2 id=\"问题解决\"><a href=\"#问题解决\" class=\"headerlink\" title=\"问题解决\"></a>问题解决</h2><p>由于JAVA，Hadoop等环境变量配置在/etc/profile文件中，导致每次新打开一个命令窗口都要重新输入 source /etc/profile 才能使jdk等配置文件生效：</p>\n<p>解决方法：</p>\n<p>打开~/.bashrc 文件</p>\n<pre><code>sudo gedit ~/.bashrc</code></pre><p>加入下列语句</p>\n<pre><code>source /etc/profile</code></pre>","site":{"data":{"friends":[{"name":"AntNLP","url":"https://antnlp.org","title":"访问主页","introduction":"华东师范大学自然语言处理实验室欢迎您的加入！","avatar":"/medias/avatars/antnlp.ico"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"系统环境\"><a href=\"#系统环境\" class=\"headerlink\" title=\"系统环境\"></a>系统环境</h2><table>\n<thead>\n<tr>\n<th>名称</th>\n<th>版本</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Ununtu</td>\n<td>1604</td>\n</tr>\n<tr>\n<td>JDK</td>\n<td><a href=\"https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html\" target=\"_blank\" rel=\"noopener\">JDK8</a></td>\n</tr>\n<tr>\n<td>Hadoop</td>\n<td><a href=\"https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz\" target=\"_blank\" rel=\"noopener\">3.1.3</a></td>\n</tr>\n</tbody></table>\n<p>下载JDK8和Hadoop3.1.3，放在ubuntu里Downloads文件夹下</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430165326.png\" alt=\"\"></p>\n<h2 id=\"基本配置\"><a href=\"#基本配置\" class=\"headerlink\" title=\"基本配置\"></a>基本配置</h2><h3 id=\"设置静态IP\"><a href=\"#设置静态IP\" class=\"headerlink\" title=\"设置静态IP\"></a>设置静态IP</h3><p><a href=\"https://zhishuang.tk/2020/04/30/ubuntu1604-she-zhi-jing-tai-ip/\">ubuntu1604 设置静态IP</a></p>\n<h3 id=\"修改hostname\"><a href=\"#修改hostname\" class=\"headerlink\" title=\"修改hostname\"></a>修改hostname</h3><p>执行命令<code>sudo gedit /etc/hostname</code>,修改hostname为master</p>\n<h3 id=\"配置主机映射\"><a href=\"#配置主机映射\" class=\"headerlink\" title=\"配置主机映射\"></a>配置主机映射</h3><p>执行命令<code>ifconfig</code>获取IP地址</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504220459.png\" alt=\"\"></p>\n<p>执行命令<code>sudo gedit /etc/hosts</code>,添加映射关系，注意IP地址换成自己的</p>\n<pre><code>192.168.79.129    master</code></pre><h3 id=\"关闭防火墙\"><a href=\"#关闭防火墙\" class=\"headerlink\" title=\"关闭防火墙\"></a>关闭防火墙</h3><p>执行命名<code>sudo ufw disable</code>关闭防火墙</p>\n<h3 id=\"配置SSH\"><a href=\"#配置SSH\" class=\"headerlink\" title=\"配置SSH\"></a>配置SSH</h3><blockquote>\n<p>Hadoop名称节点(NameNode)需要启动集群中所有机器的Hadoop守护进程，这个过 程需要通过SSH登录来实现。Hadoop并没有提供SSH输入密码登录的形式，因此，为 了能够顺利登录每台机器，需要将所有机器配置为名称节点可以无密码登录它们。</p>\n</blockquote>\n<h4 id=\"配置SSH的无密码登录\"><a href=\"#配置SSH的无密码登录\" class=\"headerlink\" title=\"配置SSH的无密码登录\"></a>配置SSH的无密码登录</h4><p>安装openssh-server( 通常Linux系统会默认安装openssh的客户端软件openssh-client)，所以需要自己安装一下服务端。</p>\n<pre><code>sudo apt-get install openssh-server</code></pre><p>在终端执行命令<code>ssh-keygen -t rsa</code>，然后一直回车，生成密钥。</p>\n<p>执行命令<code>ssh-copy-id localhost</code>，在提示信息中输入<code>yes</code>，然后输入本机密码</p>\n<p>执行命令<code>ssh localhost</code>，出现登录时间，说明ssh配置成功</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504234742.png\" alt=\"\"></p>\n<h2 id=\"配置JAVA环境\"><a href=\"#配置JAVA环境\" class=\"headerlink\" title=\"配置JAVA环境\"></a>配置JAVA环境</h2><h3 id=\"创建文件夹\"><a href=\"#创建文件夹\" class=\"headerlink\" title=\"创建文件夹\"></a>创建文件夹</h3><pre><code class=\"bash\">sudo mkdir /usr/java</code></pre>\n<p>在/usr目录下创建文件夹java，我们将把JDK8解压到这个文件夹中</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430170954.png\" alt=\"\"></p>\n<h3 id=\"解压JDK\"><a href=\"#解压JDK\" class=\"headerlink\" title=\"解压JDK\"></a>解压JDK</h3><pre><code class=\"bash\">sudo tar -zxvf ~/Downloads/jdk-8u251-linux-x64.tar.gz -C /usr/java</code></pre>\n<p>解压jdk8到/usr/java目录下</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430171614.png\" alt=\"\"></p>\n<h3 id=\"配置环境变量\"><a href=\"#配置环境变量\" class=\"headerlink\" title=\"配置环境变量\"></a>配置环境变量</h3><p>执行<code>sudo gedit /etc/profile</code>命令打开配置文件，在末尾添加以下几行文字，注意自己的jdk版本号。</p>\n<pre><code>#set java env\nexport JAVA_HOME=/usr/java/jdk1.8.0_251\nexport JRE_HOME=${JAVA_HOME}/jre    \nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib    \nexport PATH=${JAVA_HOME}/bin:$PATH</code></pre><p>执行<code>source /etc/profile</code>命令让配置文件生效</p>\n<p>执行<code>java -version</code>命令验证是否配置成功</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430173142.png\" alt=\"\"></p>\n<h2 id=\"配置Hadoop环境\"><a href=\"#配置Hadoop环境\" class=\"headerlink\" title=\"配置Hadoop环境\"></a>配置Hadoop环境</h2><h3 id=\"解压Hadoop\"><a href=\"#解压Hadoop\" class=\"headerlink\" title=\"解压Hadoop\"></a>解压Hadoop</h3><p>将我们下载的Hadoop解压到 /usr/local/ 中</p>\n<pre><code>sudo tar -zxvf ~/Downloads/hadoop-3.1.3.tar.gz -C /usr/local</code></pre><p>利用<code>cd /usr/local/</code>命令切换操作空间，将文件夹名改为hadoop</p>\n<pre><code>sudo mv ./hadoop-3.1.3/ ./hadoop</code></pre><p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430174115.png\" alt=\"\"></p>\n<h3 id=\"配置Hadoop环境变量\"><a href=\"#配置Hadoop环境变量\" class=\"headerlink\" title=\"配置Hadoop环境变量\"></a>配置Hadoop环境变量</h3><p>执行<code>sudo gedit /etc/profile</code>命令打开配置文件,添加下面的语句</p>\n<pre><code>#set Hadoop env\nHADOOP_HOME=/usr/local/hadoop\nexport PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH</code></pre><p>执行<code>source /etc/profile</code>命令让配置文件生效</p>\n<h3 id=\"修改Hadoop配置文件\"><a href=\"#修改Hadoop配置文件\" class=\"headerlink\" title=\"修改Hadoop配置文件\"></a>修改Hadoop配置文件</h3><p>执行<code>sudo gedit hadoop-env.sh</code>命令打开配置文件，添加语句<code>export JAVA_HOME=/usr/java/jdk1.8.0_251</code></p>\n<p>执行<code>hadoop version</code>命令验证是否配置成功</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200430183459.png\" alt=\"\"></p>\n<p>到这儿 我们Hadoop的单机模式配置完成</p>\n<h2 id=\"Hadoop伪分布式安装配置\"><a href=\"#Hadoop伪分布式安装配置\" class=\"headerlink\" title=\"Hadoop伪分布式安装配置\"></a>Hadoop伪分布式安装配置</h2><blockquote>\n<p>Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的 Java 进程来运行，节点既作为 NameNode也作为DataNode， 同时，读取的是 HDFS 中的文件</p>\n<p>Hadoop的配置文件位于$HADOOP_HOME/etc/hadoop/中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml</p>\n<p>Hadoop的配置文件是xml格式，每个配置以声明property的name和value的方式来实现</p>\n</blockquote>\n<h3 id=\"hadoop-目录说明\"><a href=\"#hadoop-目录说明\" class=\"headerlink\" title=\"hadoop 目录说明\"></a>hadoop 目录说明</h3><blockquote>\n<p>修改配置文件之前，先看一下hadoop下的目录：</p>\n<ul>\n<li>bin：hadoop最基本的管理脚本和使用脚本所在目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用hadoop</li>\n<li>etc：配置文件存放的目录，包括core-site.xml,hdfs-site.xml,mapred-site.xml等从hadoop1.x继承而来的配置文件和yarn-site.xml等hadoop2.x新增的配置文件</li>\n<li>include：对外提供的编程库头文件（具体动态库和静态库在lib目录中，这些头文件军事用c++定义的，通常用于c++程序访问hdfs或者编写mapreduce程序）</li>\n<li>Lib：该目录包含了hadoop对外提供的才变成动态库和静态库，与include目录中的头文件结合使用</li>\n<li>libexec：各个服务对应的shell配置文件所在目录，可用于配置日志输出目录、启动参数等信息</li>\n<li>sbin：hadoop管理脚本所在目录，主要包含hdfs和yarn中各类服务的启动、关闭脚本</li>\n<li>share：hadoop各个模块编译后的jar包所在目录。</li>\n</ul>\n</blockquote>\n<h3 id=\"修改配置文件\"><a href=\"#修改配置文件\" class=\"headerlink\" title=\"修改配置文件\"></a>修改配置文件</h3><p>在 <code>/usr/local/hadoop/etc/hadoop/</code>目录下，执行命令<code>sudo gedit core-site.xml</code>，修改配置文件core-site.xml，内容如下：</p>\n<pre><code>&lt;configuration&gt; \n &lt;property&gt;\n      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; \n      &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;\n      &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;\n &lt;/property&gt; \n &lt;property&gt;\n   &lt;name&gt;fs.defaultFS&lt;/name&gt;\n   &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; \n  &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>hadoop.tmp.dir表示存放临时数据的目录，即包括NameNode的数据，也包 括DataNode的数据。该路径任意指定，只要实际存在该文件夹即可</li>\n<li>name为fs.defaultFS的值，表示hdfs路径的逻辑名称</li>\n</ul>\n<p>在 <code>/usr/local/hadoop/etc/hadoop/</code>目录下，执行命令<code>sudo gedit hdfs-site.xml</code>，修改配置文件hdfs-site.xml，内容如下：</p>\n<pre><code>&lt;configuration&gt; \n   &lt;property&gt;\n       &lt;name&gt;dfs.replication&lt;/name&gt;\n       &lt;value&gt;1&lt;/value&gt; \n   &lt;/property&gt; \n   &lt;property&gt;\n       &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; \n    &lt;/property&gt;\n   &lt;property&gt;\n       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;         \n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><ul>\n<li>dfs.replication表示副本的数量，伪分布式要设置为1</li>\n<li>dfs.namenode.name.dir表示本地磁盘目录，是存储fsimage文件的地方</li>\n<li>dfs.datanode.data.dir表示本地磁盘目录，HDFS数据存放block的地方</li>\n</ul>\n<h3 id=\"启动HDFS\"><a href=\"#启动HDFS\" class=\"headerlink\" title=\"启动HDFS\"></a>启动HDFS</h3><p>第一次启动时需要执行 <code>hdfs namenode - format</code>格式化节点</p>\n<p>执行<code>start-all.sh</code>启动HDFS及相关服务，执行<code>jps</code>命令，出现以下6个线程说配置成功：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200504235929.png\" alt=\"\"></p>\n<p>进一步确认，可以浏览器访问<code>localhost:9870</code>和<code>localhost:8088</code></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000709.png\" alt=\"\"></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505000753.png\" alt=\"\"></p>\n<h2 id=\"配置Hadoop集群\"><a href=\"#配置Hadoop集群\" class=\"headerlink\" title=\"配置Hadoop集群\"></a>配置Hadoop集群</h2><p>先从master克隆两个虚拟机，分别命名为slave1和slave2。配置方案如下：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>master</th>\n<th>slave1</th>\n<th>slave2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HDFS</td>\n<td>NameNode<br/>DataNode</td>\n<td>SecondaryNameNode<br/>DataNode</td>\n<td>DataNode</td>\n</tr>\n<tr>\n<td>YARN</td>\n<td>NodeManager</td>\n<td>NodeManager</td>\n<td>ResourceManager<br/>NodeManager</td>\n</tr>\n</tbody></table>\n<h3 id=\"IP，主机名，主机映射配置\"><a href=\"#IP，主机名，主机映射配置\" class=\"headerlink\" title=\"IP，主机名，主机映射配置\"></a>IP，主机名，主机映射配置</h3><h4 id=\"slave1和slave2配置\"><a href=\"#slave1和slave2配置\" class=\"headerlink\" title=\"slave1和slave2配置\"></a>slave1和slave2配置</h4><p>执行<code>sudo gedit /etc/network/interfaces</code>命令打开网络配置文件，修改slave1的IP为192.168.79.130，修改slave2的IP为192.168.79.131</p>\n<p>执行<code>sudo gedit /etc/hostname</code>命令，修改slave1的hostname为slave1，修改slave2的hostname为slave2</p>\n<p>执行<code>sudo gedit /etc/hosts</code>配置主机映射，添加下列语句：</p>\n<pre><code>#192.168.79.129    master#这条已经存在，不用添加\n192.168.79.130    slave1\n192.168.79.131    slave2</code></pre><p>注意，上面的配置需要分别在slave1和slave2上执行，配置结束之后执行<code>reboot</code>重启主机</p>\n<h4 id=\"master配置\"><a href=\"#master配置\" class=\"headerlink\" title=\"master配置\"></a>master配置</h4><p>执行<code>sudo gedit /etc/hosts</code>配置主机映射，添加下列语句</p>\n<pre><code>192.168.79.130    slave1\n192.168.79.131    slave2</code></pre><h3 id=\"免密配置\"><a href=\"#免密配置\" class=\"headerlink\" title=\"免密配置\"></a>免密配置</h3><p>免密配置需要保证三台主机之间都能互相免密登录，<strong>三台主机</strong>都需要<strong>执行</strong>下面的命令</p>\n<pre><code>ssh-keygen -t rsa    //前面配置过则不需要\nssh-copy-id master    //将公钥文件发送给包括自身在内的3台服务器\nssh-copy-id slave1\nssh-copy-id slave2\n\nssh master    //连接其他服务器看还是否需要密码，三台服务器之间都不需要则配置成功\nssh slave1\nssh slave2</code></pre><h3 id=\"配置Hadoop配置文件\"><a href=\"#配置Hadoop配置文件\" class=\"headerlink\" title=\"配置Hadoop配置文件\"></a>配置Hadoop配置文件</h3><p><strong>在master中配置好后再分发给slave1和slave2</strong></p>\n<p>执行<code>cd /usr/local/hadoop/etc/hadoop/</code>进入配置文件所在的文件夹</p>\n<p>执行<code>sudo gedit core-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt; \n &lt;property&gt;\n      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; \n      &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;\n      &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;\n &lt;/property&gt;\n&lt;!-- 指定NameNode的地址 --&gt; \n &lt;property&gt;\n   &lt;name&gt;fs.defaultFS&lt;/name&gt;\n   &lt;value&gt;hdfs://master:9000&lt;/value&gt; \n &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit hdfs-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt; \n   &lt;!-- 指定冗余度 --&gt;\n   &lt;property&gt;\n       &lt;name&gt;dfs.replication&lt;/name&gt;\n       &lt;value&gt;3&lt;/value&gt; \n   &lt;/property&gt;\n   &lt;!-- 指定NameNode数据的存储目录 --&gt; \n   &lt;property&gt;\n       &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; \n   &lt;/property&gt;\n   &lt;!-- 指定Datanode数据的存储目录 --&gt;\n   &lt;property&gt;\n       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;         \n       &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;\n   &lt;/property&gt;\n   &lt;!-- 设置secondarynamenode --&gt;\n   &lt;property&gt;\n        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n        &lt;value&gt;slave1:50090&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit yarn-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt;\n   &lt;!--指定mapreduce走shuffle --&gt;\n   &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n   &lt;/property&gt;\n   &lt;!-- 指定ResourceManager的地址--&gt;\n   &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n        &lt;value&gt;slave2&lt;/value&gt;\n   &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit mapred-site.xml</code>打开配置文件，配置如下：</p>\n<pre><code>&lt;configuration&gt;\n&lt;!-- 指定mapreduce运行在yarn上 --&gt;\n&lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n        &lt;value&gt;yarn&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>执行<code>sudo gedit workers</code>打开配置文件，配置如下：</p>\n<pre><code>master\nslave1\nslave2</code></pre><p>将配置好的文件分发给slave1和slave2</p>\n<pre><code>scp -r /usr/local/hadoop/etc/hadoop/ slave1:/usr/local/hadoop/etc/\nscp -r /usr/local/hadoop/etc/hadoop/ slave2:/usr/local/hadoop/etc/</code></pre><h3 id=\"启动集群\"><a href=\"#启动集群\" class=\"headerlink\" title=\"启动集群\"></a>启动集群</h3><p>首次运行之前需要格式化namenode，如果首次运行失败后又重新进行了部分配置，运行之前最好也格式化namenode，格式化namenode之前需要删除hadoop目录下的data,logs以及/tmp目录下的hadoop开头的文件（在没有数据的情况下）</p>\n<ul>\n<li><p>在master主机上执行<code>hadoop namenode -format</code>命令格式化namenode</p>\n</li>\n<li><p>在master主机上执行<code>start-dfs.sh</code>命令启动HDFS，如果正常启动：</p>\n<ul>\n<li>在master上执行<code>jps</code>命令可以看到有namenode，datanode</li>\n<li>在slave1上执行<code>jps</code>命令可以看到有secondarynamenode，datanode</li>\n<li>在slave2上执行<code>jps</code>命令可以看到有datanode</li>\n</ul>\n</li>\n<li><p>因为resourcemanager部署在slave2上，所以在slave2上执行<code>start-yarn.sh</code>命令启动YARN，成功则：</p>\n<ul>\n<li>在master上执行<code>jps</code>命令可以看到有namenode，datanode，nodemanager</li>\n<li>在slave1上执行<code>jps</code>命令可以看到有secondarynamenode，datanode，nodemanager</li>\n<li>在slave2上执行<code>jps</code>命令可以看到有datanode，resourcemanager，nodemanager</li>\n</ul>\n</li>\n</ul>\n<p>至此完成了集群的搭建</p>\n<h2 id=\"查看集群\"><a href=\"#查看集群\" class=\"headerlink\" title=\"查看集群\"></a>查看集群</h2><p>打开<code>http://master:9870/</code>观测是否有三分datanode</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200505191607.png\" alt=\"\"></p>\n<h2 id=\"测试集群\"><a href=\"#测试集群\" class=\"headerlink\" title=\"测试集群\"></a>测试集群</h2><h2 id=\"编写集群启动脚本\"><a href=\"#编写集群启动脚本\" class=\"headerlink\" title=\"编写集群启动脚本\"></a>编写集群启动脚本</h2><p>为了方便启动集群和关闭集群，编写一个脚本，在master机器上执行<code>mkdir bin</code>命令在用户目录下创建<code>bin</code>目录，执行<code>gedit mycluster</code>命令创建并打开文件<code>mycluster</code>,在文件中添加下面的内容：</p>\n<pre><code>#!/bin/bash\nif [ $# -lt 1 ]\n then \n   echo &quot;No Args Input Error!!!!!&quot;\n   exit\nfi\ncase $1 in \n&quot;start&quot;)\n   echo &quot;======================== start hdfs ========================== &quot;\n   ssh master &quot;source /etc/profile;start-dfs.sh&quot;\n   echo &quot;======================== start yarn ========================== &quot;\n   ssh slave2 &quot;source /etc/profile;start-yarn.sh&quot;\n;;\n&quot;stop&quot;)\n   echo &quot;======================== stop yarn ========================== &quot;\n   ssh slave2 &quot;source /etc/profile;stop-yarn.sh&quot;\n   echo &quot;======================== stop hdfs ========================== &quot;\n   ssh master &quot;source /etc/profile;stop-dfs.sh&quot;\n;;\n*)\n  echo &quot;Input Args Error!!!!!&quot;\n;;\nesac</code></pre><p>在<code>bin</code>目录下执行<code>gedit myjps</code>命令创建并打开文件<code>myjps</code>,在文件中添加下面的内容：</p>\n<pre><code>#!/bin/bash\nfor i in master slave1 slave2\ndo\n   echo &quot;====================== $i JPS =======================&quot;\n   ssh $i &quot;source /etc/profile;jps&quot;\ndone</code></pre><p>执行<code>chmod 777 mycluster</code>和<code>chmod 777 myjps</code>命令修改脚本权限，之后只需要执行<code>mycluster start</code>即可启动集群。</p>\n<h2 id=\"问题解决\"><a href=\"#问题解决\" class=\"headerlink\" title=\"问题解决\"></a>问题解决</h2><p>由于JAVA，Hadoop等环境变量配置在/etc/profile文件中，导致每次新打开一个命令窗口都要重新输入 source /etc/profile 才能使jdk等配置文件生效：</p>\n<p>解决方法：</p>\n<p>打开~/.bashrc 文件</p>\n<pre><code>sudo gedit ~/.bashrc</code></pre><p>加入下列语句</p>\n<pre><code>source /etc/profile</code></pre>"}],"PostAsset":[],"PostCategory":[{"post_id":"ckab3rqxl0008gswjav6k0giu","category_id":"ckab3rqxf0004gswj95aicjcj","_id":"ckab3rqy2000hgswj21wtc238"},{"post_id":"ckab3rqx20000gswj8f9n8nma","category_id":"ckab3rqxf0004gswj95aicjcj","_id":"ckab3rqy6000lgswj7cy286gq"},{"post_id":"ckab3rqxc0002gswj3z0r6abj","category_id":"ckab3rqxw000bgswjcwshgehe","_id":"ckab3rqy9000qgswj079yhxl4"},{"post_id":"ckab3rqxi0006gswjhtho0t53","category_id":"ckab3rqxf0004gswj95aicjcj","_id":"ckab3rqyd000vgswjdw2bbws4"},{"post_id":"ckab3rqxu000agswjhwa00yoj","category_id":"ckab3rqy8000pgswj9wx10bkp","_id":"ckab3rqye000ygswj9iae0cis"},{"post_id":"ckab3rqyb000ugswjdfm41zck","category_id":"ckab3rqxf0004gswj95aicjcj","_id":"ckab3rqyf0011gswj6s9whnq1"},{"post_id":"ckab3rqxy000egswj7sm67lmv","category_id":"ckab3rqyd000wgswj1lqsc51g","_id":"ckab3rqyf0012gswj3v320h5q"},{"post_id":"ckab3rqy1000ggswjfctxgld4","category_id":"ckab3rqye000zgswjfxtld10t","_id":"ckab3rqyh0015gswja0rk4599"},{"post_id":"ckab3rqy5000kgswjfxvsh49k","category_id":"ckab3rqyg0013gswjegrab8cp","_id":"ckab3rqyi001agswjcggs38z0"},{"post_id":"ckab3rqy7000ngswj0zsedcbi","category_id":"ckab3rqyh0016gswj0ws8c2so","_id":"ckab3rqyn001fgswjapi55kir"},{"post_id":"ckab3rqya000sgswjem3tfp1u","category_id":"ckab3rqyi001bgswjafha9j3i","_id":"ckab3rqyp001hgswj56yr6i2n"}],"PostTag":[{"post_id":"ckab3rqx20000gswj8f9n8nma","tag_id":"ckab3rqxh0005gswjceho336i","_id":"ckab3rqy6000mgswjgmcfb7xo"},{"post_id":"ckab3rqx20000gswj8f9n8nma","tag_id":"ckab3rqxw000cgswj7chz8u34","_id":"ckab3rqy8000ogswj5t6h4vou"},{"post_id":"ckab3rqxc0002gswj3z0r6abj","tag_id":"ckab3rqy3000jgswj0gl382y6","_id":"ckab3rqyb000tgswj885sfgl3"},{"post_id":"ckab3rqxi0006gswjhtho0t53","tag_id":"ckab3rqy9000rgswj9dx24mnr","_id":"ckab3rqyi0018gswj3z6ser0r"},{"post_id":"ckab3rqxi0006gswjhtho0t53","tag_id":"ckab3rqyd000xgswjaasocwk7","_id":"ckab3rqyi0019gswj26w0b3cw"},{"post_id":"ckab3rqxi0006gswjhtho0t53","tag_id":"ckab3rqyf0010gswj96068fwo","_id":"ckab3rqym001dgswjeaytawgf"},{"post_id":"ckab3rqxi0006gswjhtho0t53","tag_id":"ckab3rqxw000cgswj7chz8u34","_id":"ckab3rqyn001egswj0syzaxly"},{"post_id":"ckab3rqxl0008gswjav6k0giu","tag_id":"ckab3rqyh0017gswj31madvh5","_id":"ckab3rqyr001kgswj1fh20nl0"},{"post_id":"ckab3rqxl0008gswjav6k0giu","tag_id":"ckab3rqyj001cgswj6npj31fb","_id":"ckab3rqyr001lgswja71wgjod"},{"post_id":"ckab3rqxl0008gswjav6k0giu","tag_id":"ckab3rqy9000rgswj9dx24mnr","_id":"ckab3rqys001ngswje9b69gcp"},{"post_id":"ckab3rqxl0008gswjav6k0giu","tag_id":"ckab3rqxw000cgswj7chz8u34","_id":"ckab3rqys001ogswj5a0y4fpy"},{"post_id":"ckab3rqxu000agswjhwa00yoj","tag_id":"ckab3rqyq001jgswj61arhme1","_id":"ckab3rqyu001rgswj6wl36eda"},{"post_id":"ckab3rqxu000agswjhwa00yoj","tag_id":"ckab3rqyr001mgswj68sf04bm","_id":"ckab3rqyu001sgswj8cj3gt45"},{"post_id":"ckab3rqxu000agswjhwa00yoj","tag_id":"ckab3rqyt001pgswj4e5f27d9","_id":"ckab3rqyv001ugswj206cesv0"},{"post_id":"ckab3rqxy000egswj7sm67lmv","tag_id":"ckab3rqyt001qgswj8ozwacvj","_id":"ckab3rqyv001vgswjh25u0ajg"},{"post_id":"ckab3rqy1000ggswjfctxgld4","tag_id":"ckab3rqyv001tgswjdquqbazq","_id":"ckab3rqyw001xgswjfymzcgz9"},{"post_id":"ckab3rqy5000kgswjfxvsh49k","tag_id":"ckab3rqyw001wgswjfgiac4ux","_id":"ckab3rqyz0021gswj0z115rf9"},{"post_id":"ckab3rqy5000kgswjfxvsh49k","tag_id":"ckab3rqyx001ygswj14ov6cyj","_id":"ckab3rqyz0022gswj4v521peo"},{"post_id":"ckab3rqy5000kgswjfxvsh49k","tag_id":"ckab3rqyx001zgswjhnv5fr76","_id":"ckab3rqz00024gswj2ef0fauh"},{"post_id":"ckab3rqy7000ngswj0zsedcbi","tag_id":"ckab3rqyy0020gswj5yhfbv8q","_id":"ckab3rqz10026gswj1zg5dfuh"},{"post_id":"ckab3rqy7000ngswj0zsedcbi","tag_id":"ckab3rqyz0023gswj3p5y5pf3","_id":"ckab3rqz10027gswj931xaaxc"},{"post_id":"ckab3rqya000sgswjem3tfp1u","tag_id":"ckab3rqz00025gswj68dwhh3b","_id":"ckab3rqz20029gswjh8wggg1b"},{"post_id":"ckab3rqyb000ugswjdfm41zck","tag_id":"ckab3rqy9000rgswj9dx24mnr","_id":"ckab3rqz3002agswjg0mxbvp7"},{"post_id":"ckab3rqyb000ugswjdfm41zck","tag_id":"ckab3rqz10028gswj7emn1kfr","_id":"ckab3rqz3002bgswj3ci9h4rw"}],"Tag":[{"name":"hbsse","_id":"ckab3rqxh0005gswjceho336i"},{"name":"大数据","_id":"ckab3rqxw000cgswj7chz8u34"},{"name":"todo list","_id":"ckab3rqy3000jgswj0gl382y6"},{"name":"hadoop","_id":"ckab3rqy9000rgswj9dx24mnr"},{"name":"zookeeper","_id":"ckab3rqyd000xgswjaasocwk7"},{"name":"hbase","_id":"ckab3rqyf0010gswj96068fwo"},{"name":"高可用","_id":"ckab3rqyh0017gswj31madvh5"},{"name":"HA","_id":"ckab3rqyj001cgswj6npj31fb"},{"name":"IP","_id":"ckab3rqyq001jgswj61arhme1"},{"name":"静态IP","_id":"ckab3rqyr001mgswj68sf04bm"},{"name":"Ubuntu","_id":"ckab3rqyt001pgswj4e5f27d9"},{"name":"可持续性发展","_id":"ckab3rqyt001qgswj8ozwacvj"},{"name":"-求甚解","_id":"ckab3rqyv001tgswjdquqbazq"},{"name":"文本分类","_id":"ckab3rqyw001wgswjfgiac4ux"},{"name":"综述","_id":"ckab3rqyx001ygswj14ov6cyj"},{"name":"文献翻译","_id":"ckab3rqyx001zgswjhnv5fr76"},{"name":"胶囊网络","_id":"ckab3rqyy0020gswj5yhfbv8q"},{"name":"Capsule Networks","_id":"ckab3rqyz0023gswj3p5y5pf3"},{"name":"影评","_id":"ckab3rqz00025gswj68dwhh3b"},{"name":"集群","_id":"ckab3rqz10028gswj7emn1kfr"}]}}