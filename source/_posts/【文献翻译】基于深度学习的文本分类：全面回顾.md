---
title: 【文献翻译】基于深度学习的文本分类：全面回顾
top: false
cover: false
toc: true
mathjax: true
date: 2020-04-27 20:42:51
password:
summary:
tags:
categories:
img:
keywords:
---

### 摘要

基于深度学习的模型已经在各种文本分类任务中超过了经典的基于机器学的方法，例如情感分析，新闻分类，问答以及自然语言处理。在这次工作中，我们对近些年开发的150多种基于深度学习的文本分类模型进行了详尽的回顾，讨论了他们的技术贡献，相似点以及优点。我们还对广泛应用于文本分类的40多个流行数据集进行了总结。最后，我们对不同的深度学习模型在**流行基准**上的性能进行了定量分析。

### Introduction

文本分类是自然语言处理中的一个经典问题，旨在为文本单元（例如句子，**询问**，段落和文档）分配标签。文本分类有十分广泛的应用，例如问答，垃圾邮件检测，情感分析，新闻分类，用户意图识别，内容审核等等。文本数据可以来自不同的数据源，例如网页数据，邮件，聊天，社交媒体，机票，保险理赔，用户评论，客户服务中的问题和解答等等。文本中含有极其丰富的信息，但由于它的非结构化特征，想要从中提取信息便极具挑战和耗时。

文本分类可以通过人工标注和自动标注两种方式进行，随着工业应用中文本数据规模不断增大，自动文本分类变得越来越重要。自动文本分类的方法可以被分为3类：

* 基于规则的方法
* 基于机器学习的方法（数据驱动）
* 混合方法

基于规则的方法使用一组预定义的规则将文本分为不同的类别。例如，所有包含“足球”，”篮球“或者”棒球“的文档都被标记为”运动“标签。

### 2 用于文本分类的深度学习模型

在这个部分，我们回顾了针对各种文本分类问题提出的150多种深度学习框架。为了更易于遵循，我们根据模型的主要架构贡献将其分为以下类别：

* 基于前馈网络的模型，该模型将文本视为一堆单词（a bag of words）（第2.1节）
* 基于RNN的模型，该模型将文本视为单词序列，旨在捕获单词相关性和文本结构（第2.2节）
* 基于CNN的模型，经过训练可识别文本中的模式（例如关键短语）以进行分类（第2.3节）
* 胶囊网络(Capsule networks)解决了CNN的池化操作所带来的信息丢失问题，最近已应用于文本分类（第2.4节）
* 注意机制(Attention mechanism)可有效识别文本中的相关单词，并已成为开发深度学习模型的有用工具（第2.5节）
* 记忆增强网络(Memory-augmented networks)，将神经网络与外部记忆形式结合在一起，模型可以从中读取和写入（第2.6节）
* Transformers，允许比RNN更多的并行化，因此可以使用GPU集群有效地（预）训练非常大的语言模型（第2.7节）
* 图神经网络(Graph neural networks)，旨在捕获自然语言的内部图结构，例如句法和语义解析树（第2.8节）
* 孪生神经网络(Siamese Neural Networks)，用于文本匹配，文本匹配是文本分类的一种特殊情况（第2.9节）
* 混合模型(Hybrid models)，结合注意力，RNN，CNN等模型来捕获句子和文档的局部和全局特征（第2.10节）
* 最后，在2.11节中，我们回顾了有监督学习之外的建模技术，包括使用自动编码器(Autoencoder)和对抗训练(Adversarial training)的无监督学习(Unsupervised learning)，以及强化学习(Reinforcement learning)

### 2.1 前馈神经网络

前馈网络是用于文本表示的最简单的深度学习模型之一。但是，它们已经在许多文本分类基准上达到了很高的准确性。 这些模型将文本视为一堆单词。对于每个单词，他们使用诸如word2vec [8]或Glove [9]之类的嵌入模型学习向量表示，将嵌入向量的和或平均值作为文本的表示，将其通过一个或多个前馈层，称为多层感知器（MLP），然后使用诸如逻辑回归、朴素贝叶斯或SVM等分类器对最终层的表示进行分类[10]。一个例子如深度平均网络（Deep Average Network，DAN）[10]，其体系结构如图1所示。尽管简单，但DAN却胜过了其他更复杂的模型，这些模型旨在显式地学习文本的组成。例如，DAN在语法差异较大的数据集上的表现优于语法模型。Joulin等[11]提出了一种简单而有效的文本分类器，称为fastText。 像DAN一样，fastText将文本视为一堆单词，与DAN不同的是，fastText使用n-gram作为附加特征来捕获局部单词顺序信息。 事实证明，这在实践中非常有效，同时可达到与显式使用单词顺序的方法[12]相当的结果。

![](https://cdn.jsdelivr.net/gh/zhishuangR/myImg@master/md/20200428171503.png)

Le和Mikolov [13]提出了doc2vec，它使用一种无监督算法来学习可变长度文本（例如句子，段落和文档）的定长特征表示。如图2所示，doc2vec的体系结构类似于连续词袋（CBOW）模型的体系结构[8，14]。唯一的区别是附加的段落标记通过矩阵D映射到段落向量。在doc2vec中，此向量与三个单词的上下文的连接或平均值用于预测第四个单词。 段落向量表示当前上下文中丢失的信息，可以用作该段落的主题记忆。